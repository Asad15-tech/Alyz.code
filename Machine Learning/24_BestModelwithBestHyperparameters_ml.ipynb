{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2552c948",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e5ea79",
   "metadata": {},
   "source": [
    "# Best Model with Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90c1867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Importing Classification Models\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Importing Classification Metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e05f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignoring Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54c5a2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
      "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
      "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
      "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
      "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
      "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
      "\n",
      "   body_mass_g     sex  \n",
      "0       3750.0    Male  \n",
      "1       3800.0  Female  \n",
      "2       3250.0  Female  \n",
      "3          NaN     NaN  \n",
      "4       3450.0  Female  \n"
     ]
    }
   ],
   "source": [
    "# Loading the Dataset\n",
    "df = sns.load_dataset(\"penguins\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "817c7863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                  11\n",
      "bill_depth_mm         2\n",
      "bill_length_mm        2\n",
      "flipper_length_mm     2\n",
      "body_mass_g           2\n",
      "island                0\n",
      "species               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# To check missing values in our dataset\n",
    "print(df.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2e59681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species              0\n",
      "island               0\n",
      "bill_length_mm       0\n",
      "bill_depth_mm        0\n",
      "flipper_length_mm    0\n",
      "body_mass_g          0\n",
      "sex                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Let's fill the missing values in our dataset\n",
    "df[\"sex\"] = df[\"sex\"].fillna(df[\"sex\"].mode()[0])\n",
    "df[\"bill_depth_mm\"] = df[\"bill_depth_mm\"].fillna(df[\"bill_depth_mm\"].mean())\n",
    "df[\"bill_length_mm\"] = df[\"bill_length_mm\"].fillna(df[\"bill_length_mm\"].mean())\n",
    "df[\"flipper_length_mm\"] = df[\"flipper_length_mm\"].fillna(df[\"flipper_length_mm\"].mean())\n",
    "df[\"body_mass_g\"] = df[\"body_mass_g\"].fillna(df[\"body_mass_g\"].mean())\n",
    "# To again check for missing values in our dataset\n",
    "print(df.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e27423c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 344 entries, 0 to 343\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            344 non-null    object \n",
      " 1   island             344 non-null    object \n",
      " 2   bill_length_mm     344 non-null    float64\n",
      " 3   bill_depth_mm      344 non-null    float64\n",
      " 4   flipper_length_mm  344 non-null    float64\n",
      " 5   body_mass_g        344 non-null    float64\n",
      " 6   sex                344 non-null    object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 18.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Let's getting info of our dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "651aee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LabelEncoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode all categorical columns in the DataFrame\n",
    "for col in df.select_dtypes(include=['object', 'category']).columns:\n",
    "    df[col] = le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "92da4fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Features and Target Variable\n",
    "X = df.drop(\"island\", axis=1)\n",
    "y = df[\"island\"]\n",
    "# Splitting the Dataset using Train-Test-Split by 80/20 ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16f23a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Model  Accuracy\n",
      "      K Neighbors Classifier  0.579710\n",
      "    Random Forest Classifier  0.652174\n",
      "   Support Vector Classifier  0.652174\n",
      "              XGB Classifier  0.666667\n",
      "         Logistic Regression  0.710145\n",
      "Gradient Boosting Classifier  0.710145\n",
      "\n",
      "Best Model: Gradient Boosting Classifier with Accuracy: 0.7101\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary of models to evaluate\n",
    "models = { \n",
    "    'XGB Classifier': XGBClassifier(),  # XGBoost classifier\n",
    "    'Logistic Regression': LogisticRegression(),  # Logistic Regression\n",
    "    'Random Forest Classifier': RandomForestClassifier(),  # Random Forest\n",
    "    'Support Vector Classifier': SVC(),  # Support Vector Machine\n",
    "    'K Neighbors Classifier': KNeighborsClassifier(),  # KNN Classifier\n",
    "    'Gradient Boosting Classifier': GradientBoostingClassifier()  # Gradient Boosting\n",
    "}\n",
    "\n",
    "model_scores = []  # List to store model names and their accuracy\n",
    "\n",
    "# Loop through each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)  # Train the model on training data\n",
    "    y_pred = model.predict(X_test)  # Predict on test data\n",
    "    acc = accuracy_score(y_test, y_pred)  # Calculate accuracy\n",
    "    model_scores.append((name, acc))  # Append model name and accuracy to list\n",
    "\n",
    "# Sort the models by accuracy in ascending order\n",
    "model_scores_sorted = sorted(model_scores, key=lambda x: x[1])\n",
    "\n",
    "# Create a DataFrame for results\n",
    "results_df = pd.DataFrame(model_scores_sorted, columns=['Model', 'Accuracy'])\n",
    "\n",
    "# Print the results table\n",
    "print(results_df.to_string(index=False))  # Display as a table\n",
    "\n",
    "# Get the best model\n",
    "best_model = results_df.iloc[-1]  # Last row contains the best model\n",
    "print(f\"\\nBest Model: {best_model['Model']} with Accuracy: {best_model['Accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa87a97c",
   "metadata": {},
   "source": [
    "## Let's do Hyperparameter Tunning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d7b00ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Model  Accuracy\n",
      "      K Neighbors Classifier  0.579710\n",
      "              XGB Classifier  0.652174\n",
      "   Support Vector Classifier  0.652174\n",
      "    Random Forest Classifier  0.666667\n",
      "Gradient Boosting Classifier  0.666667\n",
      "         Logistic Regression  0.710145\n",
      "\n",
      "Best Model: Logistic Regression with Accuracy: 0.7101\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grids for each model\n",
    "param_grids = {\n",
    "    'XGB Classifier': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 1.0]\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.1, 1.0, 10.0],\n",
    "        'penalty': ['l1', 'l2']\n",
    "    },\n",
    "    'Random Forest Classifier': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5]\n",
    "    },\n",
    "    'Support Vector Classifier': {\n",
    "        'C': [0.1, 1.0, 10.0],\n",
    "        'kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    'K Neighbors Classifier': {\n",
    "        'n_neighbors': [3, 5, 7],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'Gradient Boosting Classifier': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 5]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning and model training\n",
    "best_models = {}\n",
    "model_scores = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grids[name], cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    y_pred = best_models[name].predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Append scores only if the model name is unique\n",
    "    if (name, acc) not in model_scores:\n",
    "        model_scores.append((name, acc))\n",
    "\n",
    "# Sort the models by accuracy in ascending order\n",
    "model_scores_sorted = sorted(model_scores, key=lambda x: x[1])\n",
    "\n",
    "# Create a DataFrame for results\n",
    "results_df = pd.DataFrame(model_scores_sorted, columns=['Model', 'Accuracy'])\n",
    "\n",
    "# Print the results table\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Get the best model\n",
    "best_model = results_df.iloc[-1]\n",
    "print(f\"\\nBest Model: {best_model['Model']} with Accuracy: {best_model['Accuracy']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas_pratice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
