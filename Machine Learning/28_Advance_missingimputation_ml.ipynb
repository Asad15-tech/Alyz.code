{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc8813b4",
   "metadata": {},
   "source": [
    "# **Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcddb2c2",
   "metadata": {},
   "source": [
    "# Simple to Advance Methods to Handle Missing values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e291edd8",
   "metadata": {},
   "source": [
    "# Mean Imputation\n",
    "\n",
    "> **Definition**: Mean imputation replaces missing values with the mean (average) of the available values in a feature.\n",
    ">\n",
    "> **Use Case**: Best used for continuous data without outliers, as outliers can skew the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "34e7e762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "01c49601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
      "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
      "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
      "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
      "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
      "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
      "\n",
      "   body_mass_g     sex  \n",
      "0       3750.0    Male  \n",
      "1       3800.0  Female  \n",
      "2       3250.0  Female  \n",
      "3          NaN     NaN  \n",
      "4       3450.0  Female  \n"
     ]
    }
   ],
   "source": [
    "# Let's Load the Penguins Dataset using Seaborn.\n",
    "df = sns.load_dataset(\"penguins\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "072a0b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                  11\n",
      "bill_depth_mm         2\n",
      "bill_length_mm        2\n",
      "flipper_length_mm     2\n",
      "body_mass_g           2\n",
      "island                0\n",
      "species               0\n",
      "dtype: int64\n",
      "Percentage of Missing Values\n",
      "sex                  3.197674\n",
      "bill_depth_mm        0.581395\n",
      "bill_length_mm       0.581395\n",
      "flipper_length_mm    0.581395\n",
      "body_mass_g          0.581395\n",
      "island               0.000000\n",
      "species              0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Let's First check for missing values and thier percentage  in the Dataset\n",
    "print(df.isnull().sum().sort_values(ascending=False))\n",
    "print(\"Percentage of Missing Values\")\n",
    "print(df.isnull().sum().sort_values(ascending=False) / len(df) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ef2da783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values after Imputation\n",
      "sex                  11\n",
      "flipper_length_mm     2\n",
      "body_mass_g           2\n",
      "bill_length_mm        0\n",
      "island                0\n",
      "species               0\n",
      "bill_depth_mm         0\n",
      "dtype: int64\n",
      "Percentage of Missing Values after Imputation\n",
      "sex                  3.197674\n",
      "flipper_length_mm    0.581395\n",
      "body_mass_g          0.581395\n",
      "bill_length_mm       0.000000\n",
      "island               0.000000\n",
      "species              0.000000\n",
      "bill_depth_mm        0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Let's impute bill_depth_mm, bill_length_mm using mean of them\n",
    "df[\"bill_depth_mm\"] = df[\"bill_depth_mm\"].fillna(df[\"bill_depth_mm\"].mean()) \n",
    "df[\"bill_length_mm\"] = df[\"bill_length_mm\"].fillna(df[\"bill_length_mm\"].mean())\n",
    "# Let's again check for missing values after imputation\n",
    "print(\"Missing Values after Imputation\")\n",
    "print(df.isnull().sum().sort_values(ascending=False))\n",
    "print(\"Percentage of Missing Values after Imputation\")\n",
    "print(df.isnull().sum().sort_values(ascending=False) / len(df) * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce92538",
   "metadata": {},
   "source": [
    "# Median Imputation\n",
    "\n",
    "> **Definition**: Median imputation replaces missing values with the median (the middle value) of the available values in a feature.\n",
    ">\n",
    "> **Use Case**: Ideal for continuous data with outliers, as the median is less affected by extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5f86de23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values after Imputation\n",
      "sex                  11\n",
      "island                0\n",
      "species               0\n",
      "bill_length_mm        0\n",
      "bill_depth_mm         0\n",
      "flipper_length_mm     0\n",
      "body_mass_g           0\n",
      "dtype: int64\n",
      "Percentage of Missing Values after Imputation\n",
      "sex                  3.197674\n",
      "island               0.000000\n",
      "species              0.000000\n",
      "bill_length_mm       0.000000\n",
      "bill_depth_mm        0.000000\n",
      "flipper_length_mm    0.000000\n",
      "body_mass_g          0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Let's impute flipper_length_mm, body_mass_g using median of them\n",
    "df[\"flipper_length_mm\"] = df[\"flipper_length_mm\"].fillna(df[\"flipper_length_mm\"].median())\n",
    "df[\"body_mass_g\"] = df[\"body_mass_g\"].fillna(df[\"body_mass_g\"].median())\n",
    "# Let's again check for missing values after imputation\n",
    "print(\"Missing Values after Imputation\")\n",
    "print(df.isnull().sum().sort_values(ascending=False))\n",
    "print(\"Percentage of Missing Values after Imputation\")\n",
    "print(df.isnull().sum().sort_values(ascending=False) / len(df) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5459fec",
   "metadata": {},
   "source": [
    "# Mode Imputation\n",
    "\n",
    "> **Definition**: Mode imputation replaces missing values with the mode (the most frequently occurring value) of the available values in a feature.\n",
    "> \n",
    "> **Use Case**: Commonly used for categorical data, where the most common category is substituted for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3855c56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values after Imputation\n",
      "species              0\n",
      "island               0\n",
      "bill_length_mm       0\n",
      "bill_depth_mm        0\n",
      "flipper_length_mm    0\n",
      "body_mass_g          0\n",
      "sex                  0\n",
      "dtype: int64\n",
      "Percentage of Missing Values after Imputation\n",
      "species              0.0\n",
      "island               0.0\n",
      "bill_length_mm       0.0\n",
      "bill_depth_mm        0.0\n",
      "flipper_length_mm    0.0\n",
      "body_mass_g          0.0\n",
      "sex                  0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Let's Impute missing values of sex column using mode\n",
    "df[\"sex\"] = df[\"sex\"].fillna(df[\"sex\"].mode()[0])\n",
    "# Let's again check for missing values after imputation\n",
    "print(\"Missing Values after Imputation\")\n",
    "print(df.isnull().sum().sort_values(ascending=False))\n",
    "print(\"Percentage of Missing Values after Imputation\")\n",
    "print(df.isnull().sum().sort_values(ascending=False) / len(df) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6974fba7",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7230c6ee",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN) Imputer\n",
    "\n",
    "> **Definition**: KNN imputation uses the K-Nearest Neighbors algorithm to fill in missing values by looking at the *k* closest instances in the dataset.\n",
    "\n",
    "> **How It Works**:\n",
    "> 1. **Identify Neighbors**: For a data point with missing values, the algorithm finds the *k* nearest neighbors ? > based on available features.\n",
    "> 2. **Impute Values**: The missing values are replaced with the average (for continuous data) or the mode (for categorical data) of the neighbors' corresponding values.\n",
    ">\n",
    "> **Justification:**  \n",
    "> - For continuous (numeric) data, the average of the nearest neighbors provides a reasonable estimate that maintains the overall distribution.  \n",
    "> - For categorical data, using the mode ensures the imputed value is the most common among similar records, preserving the categorical nature and reducing bias from rare categories.\n",
    "\n",
    "> **Advantages**:\n",
    "> - **Contextual Imputation**: Takes into account the relationships between features, potentially leading to more ?accurate imputations.\n",
    "> - **Flexibility**: Can handle both continuous and categorical data.\n",
    "> \n",
    "> **Disadvantages**:\n",
    "> - **Computationally Intensive**: Can be slow for large datasets, as it requires calculating distances to all other points.\n",
    "> - **Sensitivity to Noise**: Performance can be affected by irrelevant features and outliers.\n",
    "\n",
    "> **Use Case**: KNN imputation is particularly useful in datasets where the missing values are related to the values of other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "73681023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n"
     ]
    }
   ],
   "source": [
    "# Load the titanic dataset using seaborn library\n",
    "df = sns.load_dataset(\"titanic\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8eda874e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values\n",
      "deck           688\n",
      "age            177\n",
      "embarked         2\n",
      "embark_town      2\n",
      "sex              0\n",
      "pclass           0\n",
      "survived         0\n",
      "fare             0\n",
      "parch            0\n",
      "sibsp            0\n",
      "class            0\n",
      "adult_male       0\n",
      "who              0\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "Percentage of Missing Values\n",
      "deck           77.216611\n",
      "age            19.865320\n",
      "embarked        0.224467\n",
      "embark_town     0.224467\n",
      "sex             0.000000\n",
      "pclass          0.000000\n",
      "survived        0.000000\n",
      "fare            0.000000\n",
      "parch           0.000000\n",
      "sibsp           0.000000\n",
      "class           0.000000\n",
      "adult_male      0.000000\n",
      "who             0.000000\n",
      "alive           0.000000\n",
      "alone           0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Let's First check for missing values and thier percentage  in the Dataset\n",
    "print(\"Missing Values\")\n",
    "print(df.isnull().sum().sort_values(ascending=False))\n",
    "print(\"Percentage of Missing Values\")\n",
    "print(df.isnull().sum().sort_values(ascending=False) / len(df) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6c6aea83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values after Imputation\n",
      "deck           688\n",
      "embarked         2\n",
      "embark_town      2\n",
      "age              0\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "fare             0\n",
      "parch            0\n",
      "sibsp            0\n",
      "class            0\n",
      "adult_male       0\n",
      "who              0\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "Percentage of Missing Values after Imputation\n",
      "deck           77.216611\n",
      "embarked        0.224467\n",
      "embark_town     0.224467\n",
      "age             0.000000\n",
      "survived        0.000000\n",
      "pclass          0.000000\n",
      "sex             0.000000\n",
      "fare            0.000000\n",
      "parch           0.000000\n",
      "sibsp           0.000000\n",
      "class           0.000000\n",
      "adult_male      0.000000\n",
      "who             0.000000\n",
      "alive           0.000000\n",
      "alone           0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Import KNN Imputer from sklearn\n",
    "from sklearn.impute import KNNImputer\n",
    "# Initialize KNN Imputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "# Impute missing values of age and embarked using KNNImputer\n",
    "df[\"age\"] = imputer.fit_transform(df[[\"age\"]])\n",
    "# Let's again check for missing values after imputation\n",
    "print(\"Missing Values after Imputation\")\n",
    "print(df.isnull().sum().sort_values(ascending=False))\n",
    "print(\"Percentage of Missing Values after Imputation\")\n",
    "print(df.isnull().sum().sort_values(ascending=False) / len(df) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b3972d",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ecf1b2",
   "metadata": {},
   "source": [
    "# Regression Imputer for Imputation\n",
    "\n",
    "> **Definition**: A Regression Imputer fills in missing values by predicting them based on other features using a regression model.\n",
    ">\n",
    "> **How It Works**:\n",
    "> 1. **Train a Regression Model**: Use available data to train a regression model where the target is the feature with missing values.\n",
    "> 2. **Predict Missing Values**: Apply the model to predict and fill in the missing values based on other features.\n",
    ">\n",
    "\n",
    "> **Advantages**:\n",
    "> - Utilizes relationships in the data for more accurate imputations.\n",
    ">\n",
    "> **Disadvantages**:\n",
    "> - Assumes linearity and can be complex to implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bc083bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values\n",
      "deck           688\n",
      "age            177\n",
      "embarked         2\n",
      "embark_town      2\n",
      "sex              0\n",
      "pclass           0\n",
      "survived         0\n",
      "fare             0\n",
      "parch            0\n",
      "sibsp            0\n",
      "class            0\n",
      "adult_male       0\n",
      "who              0\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "Percentage of Missing Values\n",
      "deck           77.216611\n",
      "age            19.865320\n",
      "embarked        0.224467\n",
      "embark_town     0.224467\n",
      "sex             0.000000\n",
      "pclass          0.000000\n",
      "survived        0.000000\n",
      "fare            0.000000\n",
      "parch           0.000000\n",
      "sibsp           0.000000\n",
      "class           0.000000\n",
      "adult_male      0.000000\n",
      "who             0.000000\n",
      "alive           0.000000\n",
      "alone           0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load the titanic dataset using seaborn library\n",
    "df = sns.load_dataset(\"titanic\")\n",
    "# Let's First check for missing values and thier percentage  in the Dataset\n",
    "print(\"Missing Values\")\n",
    "print(df.isnull().sum().sort_values(ascending=False))\n",
    "print(\"Percentage of Missing Values\")\n",
    "print(df.isnull().sum().sort_values(ascending=False) / len(df) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c76d2758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values after Imputation\n",
      "deck           688\n",
      "embarked         2\n",
      "embark_town      2\n",
      "age              0\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "fare             0\n",
      "parch            0\n",
      "sibsp            0\n",
      "class            0\n",
      "adult_male       0\n",
      "who              0\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import Regression imputer to impute missing values\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# call the IterativeImputer class with max_iter = 20\n",
    "imputer = IterativeImputer(max_iter=20, random_state=42)\n",
    "\n",
    "#impute missing values with regression imputer\n",
    "df['age'] = imputer.fit_transform(df[['age']])\n",
    "\n",
    "# check the number of missing values in each columnm after imputation\n",
    "print(\"Missing Values after Imputation\")\n",
    "print(df.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aa8ba7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd70275",
   "metadata": {},
   "source": [
    "# Random Forest Imputer for Imputation\n",
    "\n",
    "> **Definition**: A Random Forest Imputer fills in missing values by using a Random Forest model to predict them based on other features.\n",
    ">\n",
    "> **How It Works**:\n",
    "> 1. **Train a Random Forest Model**: A Random Forest is trained on the dataset, using the feature with missing values as the target variable.\n",
    "> 2. **Impute Missing Values**: The model predicts the missing values by aggregating predictions from multiple decision trees within the forest.\n",
    "\n",
    "> **Advantages**:\n",
    "> - **Handles Non-Linearity**: Effectively captures complex relationships in the data.\n",
    "> - **Robust to Overfitting**: The ensemble approach helps mitigate overfitting, making it reliable for imputation.\n",
    ">\n",
    "> **Disadvantages**:\n",
    "> - **Computationally Intensive**: Requires more resources and time compared to simpler imputation methods.\n",
    "> - **Complexity**: More challenging to implement and tune than basic imputation techniques.\n",
    ">\n",
    "> **Use Case**: Suitable for datasets with complex interactions between features and when high accuracy in imputation is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "85744f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import important libraries for advanced imputation techniques\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4d4ba41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            method  number  orbital_period   mass  distance  year\n",
      "0  Radial Velocity       1         269.300   7.10     77.40  2006\n",
      "1  Radial Velocity       1         874.774   2.21     56.95  2008\n",
      "2  Radial Velocity       1         763.000   2.60     19.84  2011\n",
      "3  Radial Velocity       1         326.030  19.40    110.62  2007\n",
      "4  Radial Velocity       1         516.220  10.50    119.47  2009\n"
     ]
    }
   ],
   "source": [
    "# Let's Load the Diamond Dataset using Seaborn\n",
    "df = sns.load_dataset(\"planets\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e16f6c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values\n",
      "mass              522\n",
      "distance          227\n",
      "orbital_period     43\n",
      "method              0\n",
      "number              0\n",
      "year                0\n",
      "dtype: int64\n",
      "Percentage of Missing Values\n",
      "mass              50.434783\n",
      "distance          21.932367\n",
      "orbital_period     4.154589\n",
      "method             0.000000\n",
      "number             0.000000\n",
      "year               0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Let's First check for missing values and thier percentage  in the Dataset\n",
    "print(\"Missing Values\")\n",
    "print(df.isnull().sum().sort_values(ascending=False))\n",
    "print(\"Percentage of Missing Values\")\n",
    "print(df.isnull().sum().sort_values(ascending=False) / len(df) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "abc18ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Dataset: (1035, 6)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of Dataset\n",
    "print(\"Shape of Dataset:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ffce8ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info of Dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1035 entries, 0 to 1034\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   method          1035 non-null   object \n",
      " 1   number          1035 non-null   int64  \n",
      " 2   orbital_period  992 non-null    float64\n",
      " 3   mass            513 non-null    float64\n",
      " 4   distance        808 non-null    float64\n",
      " 5   year            1035 non-null   int64  \n",
      "dtypes: float64(3), int64(2), object(1)\n",
      "memory usage: 48.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Getting info of our dataset\n",
    "print(\"Info of Dataset:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "723dca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode and store encoders for each object column\n",
    "encoders = {}\n",
    "for col in obj_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "24393888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   method  number  orbital_period   mass  distance  year\n",
      "0       7       1         269.300   7.10     77.40  2006\n",
      "1       7       1         874.774   2.21     56.95  2008\n",
      "2       7       1         763.000   2.60     19.84  2011\n",
      "3       7       1         326.030  19.40    110.62  2007\n",
      "4       7       1         516.220  10.50    119.47  2009\n"
     ]
    }
   ],
   "source": [
    "# Dataset after Encoding\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dbe08713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original Dataset: (1035, 6)\n",
      "Shape of Dataset with Missing Values: (522, 6)\n",
      "Shape of Dataset without Missing Values: (498, 6)\n"
     ]
    }
   ],
   "source": [
    "# Let's split the dataset into two parts one with missing values and the other one without missing values\n",
    "df_with_missing = df[df[\"mass\"].isna()]\n",
    "df_without_missing = df.dropna()\n",
    "# Let's check the shape of both datasets\n",
    "print(\"Shape of original Dataset:\", df.shape)\n",
    "print(\"Shape of Dataset with Missing Values:\", df_with_missing.shape)\n",
    "print(\"Shape of Dataset without Missing Values:\", df_without_missing.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2e7b23a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    method  number  orbital_period  mass  distance  year\n",
      "7        7       1       798.50000   NaN     21.41  1996\n",
      "20       7       5         0.73654   NaN     12.53  2011\n",
      "25       7       1       116.68840   NaN     18.11  1996\n",
      "26       7       1       691.90000   NaN     81.50  2012\n",
      "29       2       1             NaN   NaN     45.52  2005\n"
     ]
    }
   ],
   "source": [
    "# Let's have a look on the df_with_missing dataset\n",
    "print(df_with_missing.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d2e0a00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   method  number  orbital_period   mass  distance  year\n",
      "0       7       1         269.300   7.10     77.40  2006\n",
      "1       7       1         874.774   2.21     56.95  2008\n",
      "2       7       1         763.000   2.60     19.84  2011\n",
      "3       7       1         326.030  19.40    110.62  2007\n",
      "4       7       1         516.220  10.50    119.47  2009\n"
     ]
    }
   ],
   "source": [
    "# Let's have a look on the df_without_missing dataset\n",
    "print(df_without_missing.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3cb4e6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.3118523032875506\n",
      "R2 Score: 0.08624307992542535\n",
      "MAE: 1.7529973770270268\n"
     ]
    }
   ],
   "source": [
    "# Find and remove outliers in the mass column of dataset\n",
    "outliers = df_without_missing[(df_without_missing['mass'] < 0.1) | (df_without_missing['mass'] > 10)]\n",
    "df_without_missing = df_without_missing[~df_without_missing.index.isin(outliers.index)]\n",
    "# Prepare features and target, using only columns without missing values\n",
    "features = df_without_missing.drop(columns=['mass'])\n",
    "target = df_without_missing['mass']\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "# Train Random Forest Regressor for imputation\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "# Predict and evaluate\n",
    "predictions = rf.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "r2 = r2_score(y_test, predictions)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R2 Score: {r2}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5d4a7256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Final Dataset after Imputation: (889, 6)\n",
      "Missing Values in Final Dataset:\n",
      "distance          212\n",
      "orbital_period     43\n",
      "number              0\n",
      "method              0\n",
      "mass                0\n",
      "year                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ignoring the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Predict missing values\n",
    "y_pred = rf.predict(df_with_missing.drop(['mass'], axis=1))\n",
    "# Add the predicted values to the df_with_missing DataFrame\n",
    "df_with_missing['mass'] = y_pred\n",
    "# Combine the datasets back together\n",
    "df_imputed = pd.concat([df_without_missing, df_with_missing], ignore_index=True)\n",
    "# Let's check the shape of the final dataset\n",
    "print(\"Shape of Final Dataset after Imputation:\", df_imputed.shape)\n",
    "# Let's check for missing values in the final dataset\n",
    "print(\"Missing Values in Final Dataset:\")\n",
    "print(df_imputed.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "74769a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Imputed Dataset:\n",
      "            method  number  orbital_period  mass  distance  year\n",
      "0  Radial Velocity       1         269.300  7.10     77.40  2006\n",
      "1  Radial Velocity       1         874.774  2.21     56.95  2008\n",
      "2  Radial Velocity       1         763.000  2.60     19.84  2011\n",
      "3  Radial Velocity       1         185.840  4.80     76.39  2008\n",
      "4  Radial Velocity       1        1773.400  4.64     18.15  2002\n"
     ]
    }
   ],
   "source": [
    "# Let's decode the encoded columns back to their original values\n",
    "for col in obj_cols:\n",
    "    df_imputed[col] = encoders[col].inverse_transform(df_imputed[col])\n",
    "\n",
    "print(\"Final Imputed Dataset:\")\n",
    "print(df_imputed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1252b3",
   "metadata": {},
   "source": [
    "# MICE (Multiple Imputation by Chained Equations) for Imputation\n",
    "\n",
    "> **Definition**: MICE is an advanced statistical method that performs multiple imputations by modeling each feature with missing values as a function of other features in the dataset.\n",
    ">\n",
    "> **How It Works**:\n",
    "> 1. **Iterative Process**: MICE creates multiple datasets by imputing missing values several times, iteratively updating the imputations.\n",
    "> 2. **Chained Equations**: Each feature with missing values is modeled using regression or other methods, conditioned on the other features.\n",
    "> 3. **Multiple Datasets**: Generates several complete datasets, allowing for variability in the imputations.\n",
    "\n",
    "> **Advantages**:\n",
    "> - **Captures Uncertainty**: Produces multiple imputations, reflecting the uncertainty around missing values.\n",
    "> - **Flexible**: Can handle different types of variables (continuous, categorical) and relationships.\n",
    ">\n",
    "> **Disadvantages**:\n",
    "> - **Complex Implementation**: More complicated to set up and requires careful tuning.\n",
    "> - **Computationally Intensive**: Can be resource-heavy, especially with large datasets.\n",
    ">\n",
    "> **Use Case**: Ideal for datasets with significant missing values and where the > relationships between variables are complex and important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0ddbe088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import important libraries for advanced imputation techniques\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "37d9041e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            method  number  orbital_period   mass  distance  year\n",
      "0  Radial Velocity       1         269.300   7.10     77.40  2006\n",
      "1  Radial Velocity       1         874.774   2.21     56.95  2008\n",
      "2  Radial Velocity       1         763.000   2.60     19.84  2011\n",
      "3  Radial Velocity       1         326.030  19.40    110.62  2007\n",
      "4  Radial Velocity       1         516.220  10.50    119.47  2009\n"
     ]
    }
   ],
   "source": [
    "# Load the Planet Dataset using Seaborn\n",
    "df = sns.load_dataset(\"planets\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2a18c054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values\n",
      "mass              522\n",
      "distance          227\n",
      "orbital_period     43\n",
      "method              0\n",
      "number              0\n",
      "year                0\n",
      "dtype: int64\n",
      "Percentage of Missing Values\n",
      "mass              50.434783\n",
      "distance          21.932367\n",
      "orbital_period     4.154589\n",
      "method             0.000000\n",
      "number             0.000000\n",
      "year               0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Let's First check for missing values and thier percentage  in the Dataset\n",
    "print(\"Missing Values\")\n",
    "print(df.isnull().sum().sort_values(ascending=False))\n",
    "print(\"Percentage of Missing Values\")\n",
    "print(df.isnull().sum().sort_values(ascending=False) / len(df) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0d956ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info of Dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1035 entries, 0 to 1034\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   method          1035 non-null   object \n",
      " 1   number          1035 non-null   int64  \n",
      " 2   orbital_period  992 non-null    float64\n",
      " 3   mass            513 non-null    float64\n",
      " 4   distance        808 non-null    float64\n",
      " 5   year            1035 non-null   int64  \n",
      "dtypes: float64(3), int64(2), object(1)\n",
      "memory usage: 48.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Getting the info of our dataset\n",
    "print(\"Info of Dataset:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4a840216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   method  number  orbital_period   mass  distance  year\n",
      "0       7       1         269.300   7.10     77.40  2006\n",
      "1       7       1         874.774   2.21     56.95  2008\n",
      "2       7       1         763.000   2.60     19.84  2011\n",
      "3       7       1         326.030  19.40    110.62  2007\n",
      "4       7       1         516.220  10.50    119.47  2009\n"
     ]
    }
   ],
   "source": [
    "# Columns to Encode\n",
    "obj_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "# Encode and store encoders for each object column\n",
    "encoders = {}\n",
    "for col in obj_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    encoders[col] = le\n",
    "# Dataset after Encoding\n",
    "print(df.head())    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "53650f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasert after Imputation:\n",
      "method            0\n",
      "number            0\n",
      "orbital_period    0\n",
      "mass              0\n",
      "distance          0\n",
      "year              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Call the IterativeImputer class with max_iter = 20\n",
    "imputer = IterativeImputer(max_iter=20, random_state=42)\n",
    "# Columns to Impute\n",
    "obj_cols = df[[\"mass\", \"distance\", \"orbital_period\"]]\n",
    "# Impute missing values for each column\n",
    "for col in obj_cols:\n",
    "    df[col] = imputer.fit_transform(df[[col]])\n",
    "# Dataset after imputation\n",
    "print(\"Datasert after Imputation:\")\n",
    "print(df.isnull().sum().sort_values(ascending=False))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "55ef853f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Imputed Dataset:\n",
      "            method  number  orbital_period   mass  distance  year\n",
      "0  Radial Velocity       1         269.300   7.10     77.40  2006\n",
      "1  Radial Velocity       1         874.774   2.21     56.95  2008\n",
      "2  Radial Velocity       1         763.000   2.60     19.84  2011\n",
      "3  Radial Velocity       1         326.030  19.40    110.62  2007\n",
      "4  Radial Velocity       1         516.220  10.50    119.47  2009\n"
     ]
    }
   ],
   "source": [
    "# Let's Decode the encoded columns back to their original values\n",
    "for col in encoders.keys():\n",
    "    df[col] = encoders[col].inverse_transform(df[col])\n",
    "print(\"Final Imputed Dataset:\")\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas_pratice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
