{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e30072d3",
   "metadata": {},
   "source": [
    "# Machine Learning Classification Algorithms\n",
    "\n",
    "Yahan kuch mashhoor machine learning classifiers ke baare mein bataya gaya hai:\n",
    "\n",
    "## 1. XGBoost Classifier\n",
    "\n",
    "### Kam\n",
    "XGBoost ek powerful gradient boosting framework hai jo classification aur regression ke liye istemal hota hai.\n",
    "\n",
    "### Parameters\n",
    "- **n_estimators**: Yeh number of trees batata hai jo model mein shamil honge.  \n",
    "  **Example**: Agar aap 100 trees ka istemal karte hain, to model zyada accurate hota hai. 🌳\n",
    "  \n",
    "- **learning_rate**: Yeh model ki learning speed ko control karta hai.  \n",
    "  **Example**: 0.1 learning rate se model dheere seekhta hai, lekin zyada samay leta hai. ⏳\n",
    "  \n",
    "- **max_depth**: Yeh har tree ki gehraai ko set karta hai.  \n",
    "  **Example**: Agar max_depth 3 hai, to tree sirf 3 levels tak ja sakta hai. 📏\n",
    "  \n",
    "- **subsample**: Yeh data ka percentage hai jo har tree ke liye istemal hota hai.  \n",
    "  **Example**: Agar aap 0.8 set karte hain, to har tree 80% data par train hota hai. 📊\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Logistic Regression\n",
    "\n",
    "### Kam\n",
    "Logistic Regression classification problems ko solve karne ke liye istemal hota hai, khas taur pe binary classification ke liye.\n",
    "\n",
    "### Parameters\n",
    "- **C**: Regularization strength, chhoti value overfitting ko reduce karti hai.  \n",
    "  **Example**: C = 0.01 se model simple rahega. ⚖️\n",
    "  \n",
    "- **solver**: Optimization algorithm ka naam (e.g., 'lbfgs', 'liblinear').  \n",
    "  **Example**: 'lbfgs' fast convergence deta hai. 🚀\n",
    "  \n",
    "- **max_iter**: Iterations ki maximum ginti jab tak convergence nahi hota.  \n",
    "  **Example**: Agar max_iter 1000 hai, to model 1000 iterations tak chalega. 🔄\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Random Forest Classifier\n",
    "\n",
    "### Kam\n",
    "Random Forest multiple decision trees ka ensemble hai jo accuracy badhata hai aur overfitting ko kam karta hai.\n",
    "\n",
    "### Parameters\n",
    "- **n_estimators**: Total trees ki ginti.  \n",
    "  **Example**: 200 trees se model zyada robust hota hai. 🌲\n",
    "  \n",
    "- **max_features**: Har tree ke liye features ka selection.  \n",
    "  **Example**: Agar max_features = 'sqrt', to har tree sqrt(features) ka istemal karega. 🧩\n",
    "  \n",
    "- **min_samples_split**: Ek node ko split karne ke liye minimum samples ki ginti.  \n",
    "  **Example**: Agar min_samples_split = 10 hai, to node tab tak nahi split hoga jab tak 10 samples nahi hain. 🔍\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Support Vector Classifier (SVC)\n",
    "\n",
    "### Kam\n",
    "SVC boundary banata hai jo classes ko separate karta hai, ye high dimensional space mein bhi kaam karta hai.\n",
    "\n",
    "### Parameters\n",
    "- **C**: Regularization parameter, jo margin ko control karta hai.  \n",
    "  **Example**: C = 1 se margin flexible hota hai. ⚔️\n",
    "  \n",
    "- **kernel**: Kernel function ka type (e.g., 'linear', 'rbf').  \n",
    "  **Example**: RBF kernel complex boundaries create karta hai. 🎨\n",
    "  \n",
    "- **gamma**: RBF kernel mein kiya jaata hai, yeh influence karta hai kaise points ko boundary ke kareeb laana hai.  \n",
    "  **Example**: Agar gamma = 0.1 hai, to points ka influence door tak hota hai. 🌌\n",
    "\n",
    "---\n",
    "\n",
    "## 5. K-Neighbors Classifier\n",
    "\n",
    "### Kam\n",
    "K-Neighbors Classifier distance-based approach istemal karta hai, jahan neighbors ki voting ke zariye prediction kiya jata hai.\n",
    "\n",
    "### Parameters\n",
    "- **n_neighbors**: Neighbors ki ginti jo prediction mein shamil hoti hai.  \n",
    "  **Example**: Agar n_neighbors = 5 hai, to model 5 sabse kareeb neighbors ki voting karta hai. 👥\n",
    "  \n",
    "- **weights**: Weighting method (uniform ya distance).  \n",
    "  **Example**: Distance weights se kareeb neighbors zyada impact rakhte hain. ⚖️\n",
    "  \n",
    "- **metric**: Distance ko measure karne ka tareeqa (e.g., 'euclidean').  \n",
    "  **Example**: Euclidean distance use karne se points ka distance seedha measure hota hai. 📏\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Decision Tree Classifier\n",
    "\n",
    "### Kam\n",
    "Decision Tree simple rules ka istemal karke predictions karta hai, ye easily interpretable hota hai.\n",
    "\n",
    "### Parameters\n",
    "- **criterion**: Splitting criteria (e.g., 'gini', 'entropy').  \n",
    "  **Example**: Gini impurity zyada popular hai classification tasks ke liye. ⚙️\n",
    "  \n",
    "- **max_depth**: Tree ki maximum gehraai.  \n",
    "  **Example**: Agar max_depth = 5 hai, to tree sirf 5 levels tak ja sakta hai. 🌲\n",
    "  \n",
    "- **min_samples_leaf**: Ek leaf node mein minimum samples ki ginti.  \n",
    "  **Example**: Agar min_samples_leaf = 2 hai, to har leaf mein kam se kam 2 samples hone chahiye. 🍃\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Gradient Boosting Classifier\n",
    "\n",
    "### Kam\n",
    "Gradient Boosting sequentially trees ko build karta hai jo pehle se existing trees ke errors ko correct karte hain.\n",
    "\n",
    "### Parameters\n",
    "- **n_estimators**: Number of boosting stages.  \n",
    "  **Example**: Agar n_estimators = 100 hai, to 100 boosting stages honge. 🔢\n",
    "  \n",
    "- **learning_rate**: Model ki learning speed.  \n",
    "  **Example**: Learning rate 0.05 se model dheere seekhta hai. 🐢\n",
    "  \n",
    "- **max_depth**: Har tree ki gehraai.  \n",
    "  **Example**: Agar max_depth = 3 hai, to tree ki gehraai 3 levels tak hoti hai. 📏\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f757e4",
   "metadata": {},
   "source": [
    "# Classification Metrics\n",
    "\n",
    "Classification models ki performance ko evaluate karne ke liye kuch important metrics hain:\n",
    "\n",
    "## 1. Accuracy\n",
    "\n",
    "### Kam\n",
    "Accuracy total predictions ka percentage hai jo sahi hain.\n",
    "\n",
    "### Formula\n",
    "- **Accuracy** = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "### Example\n",
    "Agar ek model ne 80 out of 100 predictions sahi kiye hain, to accuracy 80% hogi. ✅\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Precision\n",
    "\n",
    "### Kam\n",
    "Precision batata hai ki jitne positive predictions kiye gaye, unmein se kitne sach mein positive hain.\n",
    "\n",
    "### Formula\n",
    "- **Precision** = TP / (TP + FP)\n",
    "\n",
    "### Example\n",
    "Agar model ne 30 positive predictions kiye aur unmein se 20 sach mein positive hain, to precision 66.67% hogi. 🎯\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Recall (Sensitivity)\n",
    "\n",
    "### Kam\n",
    "Recall batata hai ki kitne actual positive samples ko model ne sahi identify kiya.\n",
    "\n",
    "### Formula\n",
    "- **Recall** = TP / (TP + FN)\n",
    "\n",
    "### Example\n",
    "Agar model ne 25 out of 30 actual positives ko sahi identify kiya, to recall 83.33% hogi. 🕵️‍♂️\n",
    "\n",
    "---\n",
    "\n",
    "## 4. F1 Score\n",
    "\n",
    "### Kam\n",
    "F1 Score precision aur recall ka harmonic mean hai, jo un dono metrics ka balance dikhata hai.\n",
    "\n",
    "### Formula\n",
    "- **F1 Score** = 2 × (Precision × Recall) / (Precision + Recall)\n",
    "\n",
    "### Example\n",
    "Agar precision 66.67% aur recall 83.33% hai, to F1 Score 74.99% hogi. ⚖️\n",
    "\n",
    "---\n",
    "\n",
    "## 5. ROC-AUC Score\n",
    "\n",
    "### Kam\n",
    "ROC-AUC score model ki ability ko measure karta hai ki wo positive classes ko negative classes se kitna achhe se separate karta hai.\n",
    "\n",
    "### Range\n",
    "- Score 0 se 1 ke beech hota hai; 1 ka matlab perfect separation hai.\n",
    "\n",
    "### Example\n",
    "Agar ROC-AUC score 0.85 hai, to model achha perform kar raha hai. 📈\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Confusion Matrix\n",
    "\n",
    "### Kam\n",
    "Confusion Matrix actual aur predicted classes ke beech ka comparison hai, jo model ki performance ko visualize karne mein madad karta hai.\n",
    "\n",
    "# **All the Best**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas_pratice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
