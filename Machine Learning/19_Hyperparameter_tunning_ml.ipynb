{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08c7db05",
   "metadata": {},
   "source": [
    "# Machine Learning           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532f133b",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3456d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split , GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "864428ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
      "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
      "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
      "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
      "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
      "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
      "\n",
      "   body_mass_g     sex  \n",
      "0       3750.0    Male  \n",
      "1       3800.0  Female  \n",
      "2       3250.0  Female  \n",
      "3          NaN     NaN  \n",
      "4       3450.0  Female  \n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "df = sns.load_dataset(\"penguins\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f91dd8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 344 entries, 0 to 343\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            344 non-null    object \n",
      " 1   island             344 non-null    object \n",
      " 2   bill_length_mm     342 non-null    float64\n",
      " 3   bill_depth_mm      342 non-null    float64\n",
      " 4   flipper_length_mm  342 non-null    float64\n",
      " 5   body_mass_g        342 non-null    float64\n",
      " 6   sex                333 non-null    object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 18.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc2020a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                  11\n",
      "bill_depth_mm         2\n",
      "bill_length_mm        2\n",
      "flipper_length_mm     2\n",
      "body_mass_g           2\n",
      "island                0\n",
      "species               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Let's check for missing values in our dataset\n",
    "print(df.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf19a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SimpleImputer instances\n",
    "imputers = {\n",
    "    'bill_depth_mm': SimpleImputer(strategy='mean'),\n",
    "    'bill_length_mm': SimpleImputer(strategy='mean'),  # Removed extra space\n",
    "    'flipper_length_mm': SimpleImputer(strategy='mean'),\n",
    "    'body_mass_g': SimpleImputer(strategy='mean'),\n",
    "    'sex': SimpleImputer(strategy='most_frequent')\n",
    "}\n",
    "\n",
    "# Impute missing values using a for loop\n",
    "for column, imputer in imputers.items():\n",
    "    df[column] = imputer.fit_transform(df[[column]]).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71ff9834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species              0\n",
      "island               0\n",
      "bill_length_mm       0\n",
      "bill_depth_mm        0\n",
      "flipper_length_mm    0\n",
      "body_mass_g          0\n",
      "sex                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Let's check for missing values in our dataset\n",
    "print(df.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce05fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's encode the object column in our dataset using LabelEncoder in For Loop\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Loop through categorical columns and encode them\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76d2272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data to Test and Train.\n",
    "X = df.drop('species', axis=1)\n",
    "y = df['species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcebd574",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caefb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of best model: 0.99\n",
      "Best Model Parameters:\n",
      "{'bootstrap': True, 'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "     Actual  Predicted\n",
      "194       1          1\n",
      "157       1          1\n",
      "225       2          2\n",
      "208       1          1\n",
      "318       2          2\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],         # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],       # Maximum depth of each tree\n",
    "    'min_samples_split': [2, 5, 10],       # Minimum samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],         # Minimum samples required to be at a leaf node\n",
    "    'max_features': ['sqrt', 'log2'],      # Number of features to consider when looking for the best split\n",
    "    'bootstrap': [True, False]             # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# Setup GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, \n",
    "                           scoring='accuracy', cv=5)  # 5-fold cross-validation\n",
    "\n",
    "# Fit the model using the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from the grid search\n",
    " best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions using the test data\n",
    " y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy of the best model\n",
    " accuracy = accuracy_score(y_test, y_pred)\n",
    " print(f'Accuracy of best model: {accuracy:.2f}')\n",
    "\n",
    "# Print the best model parameters found during tuning\n",
    " print(\"Best Model Parameters:\")\n",
    " print(grid_search.best_params_)\n",
    "\n",
    "# Create a DataFrame to compare actual and predicted values\n",
    " results = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred})\n",
    " print(results.head(5))  # Display the first 5 rows of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f21b987",
   "metadata": {},
   "source": [
    "## Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2288d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Accuracy of best model: 1.00\n",
      "Best Model Parameters:\n",
      "{'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 30, 'bootstrap': False}\n",
      "     Actual  Predicted\n",
      "194       1          1\n",
      "157       1          1\n",
      "225       2          2\n",
      "208       1          1\n",
      "318       2          2\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Define the hyperparameter distribution for tuning\n",
    "param_dist = {\n",
    "    'n_estimators': [10, 50, 100],         # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],       # Maximum depth of each tree\n",
    "    'min_samples_split': [2, 5, 10],       # Minimum samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],         # Minimum samples required to be at a leaf node\n",
    "    'max_features': ['sqrt', 'log2'],      # Number of features to consider when looking for the best split\n",
    "    'bootstrap': [True, False]             # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# Setup RandomizedSearchCV for hyperparameter tuning\n",
    "rand_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, \n",
    "                                 scoring='accuracy', cv=5, n_iter=100, verbose=1)  # 100 iterations\n",
    "\n",
    "# Fit the model using the training data\n",
    " rand_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from the random search\n",
    " best_model = rand_search.best_estimator_\n",
    "\n",
    "# Make predictions using the test data\n",
    " y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy of the best model\n",
    " accuracy = accuracy_score(y_test, y_pred)\n",
    " print(f'Accuracy of best model: {accuracy:.2f}')\n",
    "\n",
    "# Print the best model parameters found during tuning\n",
    " print(\"Best Model Parameters:\")\n",
    " print(rand_search.best_params_)\n",
    "\n",
    "# Create a DataFrame to compare actual and predicted values\n",
    " results = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred})\n",
    " print(results.head(5))  # Display the first 5 rows of the results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas_pratice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
