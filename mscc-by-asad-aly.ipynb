{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":87331,"databundleVersionId":10191418,"sourceType":"competition"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ======================================\n# Snippet 1: Data Loading + MFCC Features + Basic Missing Data Analysis\n# ======================================\n\n# -----------------------------\n# IMPORTS\n# -----------------------------\nimport os\nimport librosa\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\n\n\nprint(\"ğŸš€ Loading competition data... / Competition data load kar rahe hain...\")\n\n# -----------------------------\n# DATA LOADING\n# -----------------------------\ntrain_csv = \"/kaggle/input/airs-ai-in-respiratory-sounds/train.csv\"\naudio_path = \"/kaggle/input/airs-ai-in-respiratory-sounds/sounds/sounds\"\n\ntrain_df = pd.read_csv(train_csv)\nprint(f\"âœ… Training data loaded: {train_df.shape} / Training data ka size\")\n\n# -----------------------------\n# TABULAR FEATURES\n# -----------------------------\ntab_features = ['age', 'gender', 'tbContactHistory', 'wheezingHistory', 'phlegmCough',\n                'familyAsthmaHistory', 'feverHistory', 'coldPresent', 'packYears']\n\n# -----------------------------\n# AUDIO FILE MAPPING\n# -----------------------------\nfile_map = {}\nfor folder in os.listdir(audio_path):\n    fpath = os.path.join(audio_path, folder)\n    if os.path.isdir(fpath):\n        wavs = [f for f in os.listdir(fpath) if f.endswith(\".wav\")]\n        if wavs:\n            file_map[folder] = os.path.join(fpath, wavs[0])\n\nprint(f\"âœ… Audio files mapped: {len(file_map)} / Total audio files mapped\")\n\n# -----------------------------\n# MFCC FEATURE EXTRACTION FUNCTION\n# -----------------------------\ndef extract_mfcc_features(file_path, n_mfcc=40, duration=5, sr=22050):\n    \"\"\"Extract MFCC + chroma + mel features / MFCC aur extra features extract karte hain\"\"\"\n    try:\n        y, sr = librosa.load(file_path, sr=sr, duration=duration)\n        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n        mfcc_scaled = np.mean(mfcc.T, axis=0)\n\n        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n        chroma_scaled = np.mean(chroma.T, axis=0)\n\n        mel = librosa.feature.melspectrogram(y=y, sr=sr)\n        mel_scaled = np.mean(mel.T, axis=0)\n\n        features = np.hstack([mfcc_scaled, chroma_scaled, mel_scaled])\n        return features\n    except Exception as e:\n        print(f\"Error processing {file_path}: {e}\")\n        return np.zeros(n_mfcc + 12 + 128)  # Fallback\n\nprint(\"ğŸµ Extracting MFCC features for all audio files...\")\n\nX_audio = []\nvalid_ids = []\nfor i, cid in enumerate(train_df['candidateID']):\n    if cid in file_map:\n        features = extract_mfcc_features(file_map[cid])\n        X_audio.append(features)\n        valid_ids.append(cid)\n    if (i + 1) % 100 == 0:\n        print(f\"Processed {i + 1} files... / {i+1} files process ho chuki hain\")\n\nX_audio = np.array(X_audio)\n\n# -----------------------------\n# FILTER TABULAR & TARGET DATA\n# -----------------------------\ndf = train_df[train_df['candidateID'].isin(valid_ids)]\nX_tab = df[tab_features].values\ny = df['disease'].values\n\nprint(f\"âœ… MFCC features shape: {X_audio.shape}\")\nprint(f\"âœ… Dataset size after filtering: {len(df)}\")\nprint(f\"âœ… Unique classes: {len(np.unique(y))}\")\n\n# -----------------------------\n# BASIC MISSING DATA ANALYSIS\n# -----------------------------\nmissing_data = df[tab_features].isnull().sum()\nmissing_percent = (missing_data / len(df)) * 100\nmissing_summary = pd.DataFrame({\n    'Feature': tab_features,\n    'Missing_Count': missing_data,\n    'Missing_Percent': missing_percent\n})\nprint(\"\\nğŸ” Basic Missing Data Analysis / Missing data summary\")\nprint(missing_summary)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T11:43:34.823412Z","iopub.execute_input":"2025-12-01T11:43:34.824282Z","iopub.status.idle":"2025-12-01T11:43:57.184527Z","shell.execute_reply.started":"2025-12-01T11:43:34.824254Z","shell.execute_reply":"2025-12-01T11:43:57.183708Z"}},"outputs":[{"name":"stdout","text":"ğŸš€ Loading competition data... / Competition data load kar rahe hain...\nâœ… Training data loaded: (546, 11) / Training data ka size\nâœ… Audio files mapped: 882 / Total audio files mapped\nğŸµ Extracting MFCC features for all audio files...\nProcessed 100 files... / 100 files process ho chuki hain\nProcessed 200 files... / 200 files process ho chuki hain\nProcessed 300 files... / 300 files process ho chuki hain\nProcessed 400 files... / 400 files process ho chuki hain\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/librosa/core/pitch.py:103: UserWarning: Trying to estimate tuning from empty frequency set.\n  return pitch_tuning(\n","output_type":"stream"},{"name":"stdout","text":"Processed 500 files... / 500 files process ho chuki hain\nâœ… MFCC features shape: (546, 180)\nâœ… Dataset size after filtering: 546\nâœ… Unique classes: 3\n\nğŸ” Basic Missing Data Analysis / Missing data summary\n                                 Feature  Missing_Count  Missing_Percent\nage                                  age              0         0.000000\ngender                            gender              0         0.000000\ntbContactHistory        tbContactHistory              0         0.000000\nwheezingHistory          wheezingHistory              0         0.000000\nphlegmCough                  phlegmCough              0         0.000000\nfamilyAsthmaHistory  familyAsthmaHistory              0         0.000000\nfeverHistory                feverHistory              0         0.000000\ncoldPresent                  coldPresent            148        27.106227\npackYears                      packYears              0         0.000000\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# ======================================\n# Snippet 2: Advanced Imputation (Iterative) + Tabular Preprocessing + Scaling\n# ======================================\n\nprint(\"ğŸ”„ Applying Iterative Imputation (MICE) / Iterative imputation apply kar rahe hain...\")\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\n# Original tabular data\nX_tab_original = X_tab.copy()\ny_original = y.copy()\n\n# -----------------------------\n# 1ï¸âƒ£ Iterative Imputation (MICE) for all missing values\n# -----------------------------\niterative_imputer = IterativeImputer(\n    max_iter=10,\n    random_state=42,\n    estimator=RandomForestClassifier(n_estimators=50, random_state=42)\n)\n\nX_tab_iterative = iterative_imputer.fit_transform(X_tab_original)\nprint(\"âœ… Iterative imputation applied / Iterative imputation complete\")\n\n# -----------------------------\n# 2ï¸âƒ£ Select Iterative Imputation as final dataset\n# -----------------------------\nX_tab_best = X_tab_iterative\nprint(\"âœ… Using Iterative Imputation for final dataset / Iterative imputation final dataset ke liye select kiya\")\n\n# -----------------------------\n# 3ï¸âƒ£ Scale Tabular Features\n# -----------------------------\nscaler_tab = StandardScaler()\nX_tab_scaled = scaler_tab.fit_transform(X_tab_best)\nprint(\"âœ… Tabular features scaled / Tabular features scaling complete\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T11:43:57.186099Z","iopub.execute_input":"2025-12-01T11:43:57.186359Z","iopub.status.idle":"2025-12-01T11:43:58.448186Z","shell.execute_reply.started":"2025-12-01T11:43:57.186343Z","shell.execute_reply":"2025-12-01T11:43:58.447347Z"}},"outputs":[{"name":"stdout","text":"ğŸ”„ Applying Iterative Imputation (MICE) / Iterative imputation apply kar rahe hain...\nâœ… Iterative imputation applied / Iterative imputation complete\nâœ… Using Iterative Imputation for final dataset / Iterative imputation final dataset ke liye select kiya\nâœ… Tabular features scaled / Tabular features scaling complete\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"# ======================================\n# Snippet 3: Train-Validation Split + MFCC reshaping + Class Weights\n# ======================================\n\nprint(\"ğŸš€ Creating train-validation split / Train-validation split bana rahe hain...\")\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\n\n# Filter to cases with available audio data\nvalid_indices = [i for i, cid in enumerate(train_df[\"candidateID\"]) if cid in file_map]\n\nX_tab_final_scaled = X_tab_scaled[valid_indices]  # Tabular features\nX_audio_final = X_audio[valid_indices]           # MFCC / Audio features\ny_final = y_original[valid_indices]              # Target labels\n\nprint(f\"âœ… Final dataset: {len(X_tab_final_scaled)} samples / Final dataset samples count\")\n\n# -----------------------------\n# 1ï¸âƒ£ Train-Validation Split\n# -----------------------------\nX_tab_train, X_tab_val, X_audio_train, X_audio_val, y_train, y_val = train_test_split(\n    X_tab_final_scaled, X_audio_final, y_final,\n    test_size=0.15,\n    stratify=y_final,\n    random_state=42\n)\n\nprint(\"âœ… Train-validation split done / Train-validation split complete\")\n\n# -----------------------------\n# 2ï¸âƒ£ Reshape Audio for CNN Input\n# -----------------------------\nX_audio_train = X_audio_train.reshape(X_audio_train.shape[0], X_audio_train.shape[1], 1)\nX_audio_val = X_audio_val.reshape(X_audio_val.shape[0], X_audio_val.shape[1], 1)\n\nprint(f\"Audio train shape: {X_audio_train.shape} / Audio validation shape: {X_audio_val.shape}\")\n\n# -----------------------------\n# 3ï¸âƒ£ Compute Class Weights for Imbalanced Data\n# -----------------------------\nclass_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(y_train),\n    y=y_train\n)\n\nclass_weight_dict = dict(enumerate(class_weights))\nprint(f\"âœ… Class weights computed / Class weights: {class_weight_dict}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T11:43:58.449068Z","iopub.execute_input":"2025-12-01T11:43:58.449351Z","iopub.status.idle":"2025-12-01T11:43:58.461630Z","shell.execute_reply.started":"2025-12-01T11:43:58.449332Z","shell.execute_reply":"2025-12-01T11:43:58.460828Z"}},"outputs":[{"name":"stdout","text":"ğŸš€ Creating train-validation split / Train-validation split bana rahe hain...\nâœ… Final dataset: 546 samples / Final dataset samples count\nâœ… Train-validation split done / Train-validation split complete\nAudio train shape: (464, 180, 1) / Audio validation shape: (82, 180, 1)\nâœ… Class weights computed / Class weights: {0: 1.2997198879551821, 1: 0.7656765676567657, 2: 1.0815850815850816}\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"# Advanced augmentation for 1D flattened MFCC/Mel\ndef advanced_flat_augmentation(feature_vector):\n    augmented = feature_vector.copy()\n    \n    # Random noise\n    if np.random.random() > 0.5:\n        noise = np.random.normal(0, 0.01, augmented.shape)\n        augmented += noise\n    \n    # Random shift\n    if np.random.random() > 0.5:\n        shift = np.random.randint(-5, 5)\n        augmented = np.roll(augmented, shift)\n    \n    return augmented\n\n# Augmented dataset\nX_mel_augmented = []\nX_tab_augmented = []\ny_augmented = []\n\n# Original data\nX_mel_augmented.extend(X_mel_2d)\nX_tab_augmented.extend(X_tab_mel)\ny_augmented.extend(y_mel)\n\n# Augmented data (3x augmentation)\nfor i in range(len(X_mel_2d)):\n    for _ in range(3):\n        aug_mel = advanced_flat_augmentation(X_mel_2d[i])\n        X_mel_augmented.append(aug_mel)\n        X_tab_augmented.append(X_tab_mel[i])\n        y_augmented.append(y_mel[i])\n\nX_mel_augmented = np.array(X_mel_augmented)\nX_tab_augmented = np.array(X_tab_augmented)\ny_augmented = np.array(y_augmented)\n\nprint(f\"âœ… Augmented dataset: {len(X_mel_augmented)} samples (original: {len(X_mel_2d)})\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T11:43:58.462561Z","iopub.execute_input":"2025-12-01T11:43:58.462836Z","iopub.status.idle":"2025-12-01T11:43:58.506701Z","shell.execute_reply.started":"2025-12-01T11:43:58.462817Z","shell.execute_reply":"2025-12-01T11:43:58.505896Z"}},"outputs":[{"name":"stdout","text":"âœ… Augmented dataset: 1856 samples (original: 464)\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"# ======================================\n# 3ï¸âƒ£4.5ï¸âƒ£ SPLIT AUGMENTED DATA\n# ======================================\n\nprint(\"ğŸ“Š Splitting augmented dataset into train and validation / Train aur val split kar rahe hain...\")\n\nfrom sklearn.model_selection import train_test_split\n\nX_tab_aug_train, X_tab_aug_val, X_mel_aug_train, X_mel_aug_val, y_aug_train, y_aug_val = train_test_split(\n    X_tab_augmented, X_mel_augmented, y_augmented,\n    test_size=0.15, stratify=y_augmented, random_state=42\n)\n\nprint(f\"âœ… Train set: {len(X_tab_aug_train)} samples, Validation set: {len(X_tab_aug_val)} samples\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T11:43:58.508517Z","iopub.execute_input":"2025-12-01T11:43:58.509017Z","iopub.status.idle":"2025-12-01T11:43:58.516459Z","shell.execute_reply.started":"2025-12-01T11:43:58.508998Z","shell.execute_reply":"2025-12-01T11:43:58.515737Z"}},"outputs":[{"name":"stdout","text":"ğŸ“Š Splitting augmented dataset into train and validation / Train aur val split kar rahe hain...\nâœ… Train set: 1577 samples, Validation set: 279 samples\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"# ======================================\n# 3ï¸âƒ£5ï¸âƒ£ FIXED SUPER ADVANCED MODEL\n# ======================================\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, Model\n\nprint(\"ğŸ”„ Creating Fixed Super Advanced Model / Super advanced model create kar rahe hain...\")\nnum_classes = 3\n\ndef create_fixed_super_advanced_model(tabular_dim, pretrained_dim, num_classes):\n    \"\"\"Fixed super advanced model for 90%+ accuracy\"\"\"\n    \n    # Pre-trained features input\n    pretrained_input = tf.keras.Input(shape=(pretrained_dim,), name='pretrained_features')\n    \n    x_pretrained = layers.Dense(1024, activation='relu')(pretrained_input)\n    x_pretrained = layers.BatchNormalization()(x_pretrained)\n    x_pretrained = layers.Dropout(0.4)(x_pretrained)\n    \n    x_pretrained = layers.Dense(512, activation='relu')(x_pretrained)\n    x_pretrained = layers.BatchNormalization()(x_pretrained)\n    x_pretrained = layers.Dropout(0.3)(x_pretrained)\n    \n    x_pretrained = layers.Dense(256, activation='relu')(x_pretrained)\n    x_pretrained = layers.BatchNormalization()(x_pretrained)\n    x_pretrained = layers.Dropout(0.2)(x_pretrained)\n    \n    # Tabular input\n    tabular_input = tf.keras.Input(shape=(tabular_dim,), name='tabular_input')\n    \n    x_tab = layers.Dense(256, activation='relu')(tabular_input)\n    x_tab = layers.BatchNormalization()(x_tab)\n    x_tab = layers.Dropout(0.3)(x_tab)\n    \n    x_tab = layers.Dense(128, activation='relu')(x_tab)\n    x_tab = layers.BatchNormalization()(x_tab)\n    x_tab = layers.Dropout(0.2)(x_tab)\n    \n    x_tab = layers.Dense(64, activation='relu')(x_tab)\n    \n    # Combine\n    combined = layers.concatenate([x_pretrained, x_tab])\n    \n    # Advanced classification\n    x = layers.Dense(512, activation='relu')(combined)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.5)(x)\n    \n    # Residual block 1\n    residual1 = layers.Dense(512, activation='relu')(x)\n    residual1 = layers.BatchNormalization()(residual1)\n    x = layers.add([x, residual1])\n    x = layers.Dropout(0.4)(x)\n    \n    # Residual block 2\n    x = layers.Dense(256, activation='relu')(x)\n    x = layers.BatchNormalization()(x)\n    residual2 = layers.Dense(256, activation='relu')(x)\n    residual2 = layers.BatchNormalization()(residual2)\n    x = layers.add([x, residual2])\n    x = layers.Dropout(0.3)(x)\n    \n    x = layers.Dense(128, activation='relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.2)(x)\n    \n    x = layers.Dense(64, activation='relu')(x)\n    \n    output = layers.Dense(num_classes, activation='softmax')(x)\n    \n    model = Model(\n        inputs=[tabular_input, pretrained_input],\n        outputs=output,\n        name='fixed_super_advanced_model'\n    )\n    \n    return model\n\n# âœ… Create model\nsuper_model = create_fixed_super_advanced_model(\n    tabular_dim=X_tab_aug_train.shape[1],\n    pretrained_dim=X_mel_aug_train.shape[1],  # MFCC / flattened features\n    num_classes=num_classes\n)\n\nsuper_model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nprint(\"âœ… Fixed super advanced model created!\")\nsuper_model.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T11:43:58.517281Z","iopub.execute_input":"2025-12-01T11:43:58.517552Z","iopub.status.idle":"2025-12-01T11:43:58.740106Z","shell.execute_reply.started":"2025-12-01T11:43:58.517527Z","shell.execute_reply":"2025-12-01T11:43:58.739351Z"}},"outputs":[{"name":"stdout","text":"ğŸ”„ Creating Fixed Super Advanced Model / Super advanced model create kar rahe hain...\nâœ… Fixed super advanced model created!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"fixed_super_advanced_model\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"fixed_super_advanced_model\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ pretrained_features â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\nâ”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_65 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      â”‚    \u001b[38;5;34m185,344\u001b[0m â”‚ pretrained_featuâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      â”‚      \u001b[38;5;34m4,096\u001b[0m â”‚ dense_65[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ tabular_input       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\nâ”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_45          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_68 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚      \u001b[38;5;34m2,560\u001b[0m â”‚ tabular_input[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_66 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚    \u001b[38;5;34m524,800\u001b[0m â”‚ dropout_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ dense_68[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ dense_66[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_48          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_46          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_69 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚     \u001b[38;5;34m32,896\u001b[0m â”‚ dropout_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_67 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚    \u001b[38;5;34m131,328\u001b[0m â”‚ dropout_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m512\u001b[0m â”‚ dense_69[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ dense_67[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_49          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_47          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_70 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m8,256\u001b[0m â”‚ dropout_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ concatenate_5       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dropout_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], â”‚\nâ”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ dense_70[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_71 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚    \u001b[38;5;34m164,352\u001b[0m â”‚ concatenate_5[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ dense_71[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_50          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_72 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚    \u001b[38;5;34m262,656\u001b[0m â”‚ dropout_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ dense_72[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add_10 (\u001b[38;5;33mAdd\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dropout_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], â”‚\nâ”‚                     â”‚                   â”‚            â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_51          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ add_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\nâ”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_73 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚    \u001b[38;5;34m131,328\u001b[0m â”‚ dropout_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ dense_73[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_74 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚     \u001b[38;5;34m65,792\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ dense_74[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add_11 (\u001b[38;5;33mAdd\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_52          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ add_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\nâ”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_75 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚     \u001b[38;5;34m32,896\u001b[0m â”‚ dropout_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m512\u001b[0m â”‚ dense_75[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_53          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_76 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m8,256\u001b[0m â”‚ dropout_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_77 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         â”‚        \u001b[38;5;34m195\u001b[0m â”‚ dense_76[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ pretrained_features â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">185,344</span> â”‚ pretrained_featuâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚ dense_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ tabular_input       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_45          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560</span> â”‚ tabular_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> â”‚ dropout_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ dense_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ dense_66[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_48          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_46          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚ dropout_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> â”‚ dropout_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ dense_69[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ dense_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_49          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_47          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚ dropout_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ concatenate_5       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dropout_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ dense_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> â”‚ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ dense_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_50          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> â”‚ dropout_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ dense_72[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dropout_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], â”‚\nâ”‚                     â”‚                   â”‚            â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_51          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ add_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> â”‚ dropout_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ dense_73[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ dense_74[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_52          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ add_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚ dropout_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ dense_75[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_53          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚ dropout_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_77 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> â”‚ dense_76[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,566,019\u001b[0m (5.97 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,566,019</span> (5.97 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,558,339\u001b[0m (5.94 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,558,339</span> (5.94 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,680\u001b[0m (30.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> (30.00 KB)\n</pre>\n"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"# ======================================\n# 3ï¸âƒ£6ï¸âƒ£ FIXED SUPER ADVANCED MODEL TRAINING WITH PCA REDUCED MFCC\n# ======================================\n\nprint(\"ğŸ¯ Preparing data and training Fixed Super Advanced Model with PCA-reduced MFCC...\")\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.utils.class_weight import compute_class_weight\n\n# --- 1. Flatten MFCC / Mel-spectrograms ---\nX_mel_aug_train_flat = X_mel_aug_train.reshape(X_mel_aug_train.shape[0], -1)\nX_mel_aug_val_flat   = X_mel_aug_val.reshape(X_mel_aug_val.shape[0], -1)\n\n# --- 2. Reduce dimensionality to 128 features using PCA ---\npca = PCA(n_components=128, random_state=42)\nX_mel_aug_train_pca = pca.fit_transform(X_mel_aug_train_flat)\nX_mel_aug_val_pca   = pca.transform(X_mel_aug_val_flat)\n\nprint(f\"âœ… MFCC features reduced: Train {X_mel_aug_train_pca.shape}, Val {X_mel_aug_val_pca.shape}\")\n\n# --- 3. Create super advanced model ---\nsuper_model = create_fixed_super_advanced_model(\n    tabular_dim=X_tab_aug_train.shape[1],\n    pretrained_dim=128,  # Matches PCA output\n    num_classes=num_classes\n)\n\nsuper_model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nprint(\"âœ… Super advanced model created and compiled!\")\n\n# --- 4. Class weights ---\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_aug_train), y=y_aug_train)\nclass_weight_dict = dict(enumerate(class_weights))\nprint(f\"âœ… Class weights: {class_weight_dict}\")\n\n# --- 5. Callbacks ---\nenhanced_callbacks = [\n    tf.keras.callbacks.EarlyStopping(\n        monitor='val_accuracy',\n        patience=40,\n        restore_best_weights=True,\n        verbose=1\n    ),\n    tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_accuracy',\n        factor=0.5,\n        patience=20,\n        min_lr=1e-8,\n        verbose=1\n    ),\n    tf.keras.callbacks.ModelCheckpoint(\n        'fixed_super_advanced_model.h5',\n        monitor='val_accuracy',\n        save_best_only=True,\n        verbose=1\n    )\n]\n\n# --- 6. Train the model ---\nprint(\"ğŸš€ Training fixed super advanced model with PCA-reduced MFCC...\")\nsuper_history = super_model.fit(\n    [X_tab_aug_train, X_mel_aug_train_pca],\n    y_aug_train,\n    batch_size=16,\n    epochs=300,\n    validation_data=([X_tab_aug_val, X_mel_aug_val_pca], y_aug_val),\n    callbacks=enhanced_callbacks,\n    class_weight=class_weight_dict,\n    verbose=1\n)\n\nprint(\"âœ… Fixed super advanced training completed!\")\n\n# --- 7. Load best weights and evaluate ---\nsuper_model.load_weights('fixed_super_advanced_model.h5')\n\nsuper_pred = super_model.predict([X_tab_aug_val, X_mel_aug_val_pca], verbose=0)\nsuper_accuracy = accuracy_score(y_aug_val, np.argmax(super_pred, axis=1))\n\nprint(f\"\\nğŸ¯ FIXED SUPER ADVANCED MODEL ACCURACY: {super_accuracy:.4f}\")\n\n# --- 8. Performance check ---\nprevious_best = 0.8780\nimprovement = super_accuracy - previous_best\n\nif super_accuracy >= 0.90:\n    print(f\"ğŸ‰ ğŸ‰ ğŸ‰ UNBELIEVABLE! 90%+ ACHIEVED! ğŸ‰ ğŸ‰ ğŸ‰\")\n    print(f\"ğŸš€ BREAKTHROUGH! +{improvement:.4f} improvement!\")\nelif super_accuracy >= 0.88:\n    print(f\"ğŸ”¥ EXCELLENT! {super_accuracy:.4f} accuracy!\")\n    print(f\"ğŸ’ª Very close to 90%!\")\nelse:\n    print(f\"ğŸ’ª Good progress: {super_accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T11:43:58.741096Z","iopub.execute_input":"2025-12-01T11:43:58.741456Z","iopub.status.idle":"2025-12-01T11:46:19.652736Z","shell.execute_reply.started":"2025-12-01T11:43:58.741432Z","shell.execute_reply":"2025-12-01T11:46:19.652019Z"}},"outputs":[{"name":"stdout","text":"ğŸ¯ Preparing data and training Fixed Super Advanced Model with PCA-reduced MFCC...\nâœ… MFCC features reduced: Train (1577, 128), Val (279, 128)\nâœ… Super advanced model created and compiled!\nâœ… Class weights: {0: 1.301155115511551, 1: 0.7651625424551188, 2: 1.0816186556927299}\nğŸš€ Training fixed super advanced model with PCA-reduced MFCC...\nEpoch 1/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.3740 - loss: 1.5097\nEpoch 1: val_accuracy improved from -inf to 0.43728, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 80ms/step - accuracy: 0.3740 - loss: 1.5095 - val_accuracy: 0.4373 - val_loss: 1.1392 - learning_rate: 1.0000e-04\nEpoch 2/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3755 - loss: 1.3449\nEpoch 2: val_accuracy did not improve from 0.43728\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3756 - loss: 1.3449 - val_accuracy: 0.4373 - val_loss: 1.1513 - learning_rate: 1.0000e-04\nEpoch 3/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4014 - loss: 1.2712\nEpoch 3: val_accuracy improved from 0.43728 to 0.46237, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4010 - loss: 1.2713 - val_accuracy: 0.4624 - val_loss: 1.1281 - learning_rate: 1.0000e-04\nEpoch 4/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4010 - loss: 1.2930\nEpoch 4: val_accuracy improved from 0.46237 to 0.52688, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4015 - loss: 1.2909 - val_accuracy: 0.5269 - val_loss: 1.0635 - learning_rate: 1.0000e-04\nEpoch 5/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3854 - loss: 1.2211\nEpoch 5: val_accuracy improved from 0.52688 to 0.54122, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3857 - loss: 1.2206 - val_accuracy: 0.5412 - val_loss: 1.0138 - learning_rate: 1.0000e-04\nEpoch 6/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4070 - loss: 1.2069\nEpoch 6: val_accuracy improved from 0.54122 to 0.59498, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4078 - loss: 1.2057 - val_accuracy: 0.5950 - val_loss: 0.9892 - learning_rate: 1.0000e-04\nEpoch 7/300\n\u001b[1m94/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4372 - loss: 1.1499\nEpoch 7: val_accuracy did not improve from 0.59498\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4382 - loss: 1.1479 - val_accuracy: 0.5950 - val_loss: 0.9325 - learning_rate: 1.0000e-04\nEpoch 8/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4912 - loss: 1.0529\nEpoch 8: val_accuracy improved from 0.59498 to 0.62007, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4911 - loss: 1.0530 - val_accuracy: 0.6201 - val_loss: 0.8814 - learning_rate: 1.0000e-04\nEpoch 9/300\n\u001b[1m90/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5192 - loss: 0.9997\nEpoch 9: val_accuracy improved from 0.62007 to 0.63799, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5177 - loss: 0.9997 - val_accuracy: 0.6380 - val_loss: 0.8304 - learning_rate: 1.0000e-04\nEpoch 10/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4978 - loss: 1.0039\nEpoch 10: val_accuracy improved from 0.63799 to 0.65950, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4984 - loss: 1.0031 - val_accuracy: 0.6595 - val_loss: 0.7942 - learning_rate: 1.0000e-04\nEpoch 11/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5131 - loss: 0.9700\nEpoch 11: val_accuracy improved from 0.65950 to 0.67742, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5135 - loss: 0.9696 - val_accuracy: 0.6774 - val_loss: 0.7629 - learning_rate: 1.0000e-04\nEpoch 12/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5333 - loss: 0.9261\nEpoch 12: val_accuracy did not improve from 0.67742\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5334 - loss: 0.9260 - val_accuracy: 0.6667 - val_loss: 0.7547 - learning_rate: 1.0000e-04\nEpoch 13/300\n\u001b[1m95/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5856 - loss: 0.8937\nEpoch 13: val_accuracy improved from 0.67742 to 0.70968, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5852 - loss: 0.8938 - val_accuracy: 0.7097 - val_loss: 0.7223 - learning_rate: 1.0000e-04\nEpoch 14/300\n\u001b[1m95/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5710 - loss: 0.8766\nEpoch 14: val_accuracy improved from 0.70968 to 0.74552, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5713 - loss: 0.8771 - val_accuracy: 0.7455 - val_loss: 0.6754 - learning_rate: 1.0000e-04\nEpoch 15/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6216 - loss: 0.8114\nEpoch 15: val_accuracy improved from 0.74552 to 0.76344, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6210 - loss: 0.8143 - val_accuracy: 0.7634 - val_loss: 0.6515 - learning_rate: 1.0000e-04\nEpoch 16/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6005 - loss: 0.8692\nEpoch 16: val_accuracy improved from 0.76344 to 0.76703, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6015 - loss: 0.8679 - val_accuracy: 0.7670 - val_loss: 0.6288 - learning_rate: 1.0000e-04\nEpoch 17/300\n\u001b[1m89/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6352 - loss: 0.8136\nEpoch 17: val_accuracy improved from 0.76703 to 0.78853, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6383 - loss: 0.8113 - val_accuracy: 0.7885 - val_loss: 0.5997 - learning_rate: 1.0000e-04\nEpoch 18/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6417 - loss: 0.8017\nEpoch 18: val_accuracy improved from 0.78853 to 0.79211, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6434 - loss: 0.7996 - val_accuracy: 0.7921 - val_loss: 0.5867 - learning_rate: 1.0000e-04\nEpoch 19/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6864 - loss: 0.7341\nEpoch 19: val_accuracy improved from 0.79211 to 0.79928, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6863 - loss: 0.7356 - val_accuracy: 0.7993 - val_loss: 0.5682 - learning_rate: 1.0000e-04\nEpoch 20/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6800 - loss: 0.7515\nEpoch 20: val_accuracy improved from 0.79928 to 0.80645, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6805 - loss: 0.7500 - val_accuracy: 0.8065 - val_loss: 0.5495 - learning_rate: 1.0000e-04\nEpoch 21/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7339 - loss: 0.7170\nEpoch 21: val_accuracy did not improve from 0.80645\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7327 - loss: 0.7148 - val_accuracy: 0.8029 - val_loss: 0.5424 - learning_rate: 1.0000e-04\nEpoch 22/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7028 - loss: 0.7251\nEpoch 22: val_accuracy did not improve from 0.80645\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7024 - loss: 0.7248 - val_accuracy: 0.8029 - val_loss: 0.5292 - learning_rate: 1.0000e-04\nEpoch 23/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7368 - loss: 0.6616\nEpoch 23: val_accuracy did not improve from 0.80645\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7359 - loss: 0.6626 - val_accuracy: 0.8029 - val_loss: 0.5283 - learning_rate: 1.0000e-04\nEpoch 24/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7647 - loss: 0.6286\nEpoch 24: val_accuracy did not improve from 0.80645\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7622 - loss: 0.6336 - val_accuracy: 0.8029 - val_loss: 0.5234 - learning_rate: 1.0000e-04\nEpoch 25/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7488 - loss: 0.6253\nEpoch 25: val_accuracy did not improve from 0.80645\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7484 - loss: 0.6264 - val_accuracy: 0.8029 - val_loss: 0.5251 - learning_rate: 1.0000e-04\nEpoch 26/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7343 - loss: 0.6870\nEpoch 26: val_accuracy did not improve from 0.80645\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7347 - loss: 0.6851 - val_accuracy: 0.8029 - val_loss: 0.5183 - learning_rate: 1.0000e-04\nEpoch 27/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7162 - loss: 0.6568\nEpoch 27: val_accuracy did not improve from 0.80645\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7175 - loss: 0.6559 - val_accuracy: 0.8065 - val_loss: 0.5072 - learning_rate: 1.0000e-04\nEpoch 28/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7270 - loss: 0.6675\nEpoch 28: val_accuracy improved from 0.80645 to 0.82079, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7281 - loss: 0.6674 - val_accuracy: 0.8208 - val_loss: 0.5075 - learning_rate: 1.0000e-04\nEpoch 29/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7569 - loss: 0.6386\nEpoch 29: val_accuracy did not improve from 0.82079\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7573 - loss: 0.6365 - val_accuracy: 0.8136 - val_loss: 0.5018 - learning_rate: 1.0000e-04\nEpoch 30/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7698 - loss: 0.6072\nEpoch 30: val_accuracy did not improve from 0.82079\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7691 - loss: 0.6082 - val_accuracy: 0.8208 - val_loss: 0.4947 - learning_rate: 1.0000e-04\nEpoch 31/300\n\u001b[1m87/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7740 - loss: 0.5805\nEpoch 31: val_accuracy did not improve from 0.82079\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7733 - loss: 0.5857 - val_accuracy: 0.8208 - val_loss: 0.4920 - learning_rate: 1.0000e-04\nEpoch 32/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7450 - loss: 0.6458\nEpoch 32: val_accuracy improved from 0.82079 to 0.82437, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7451 - loss: 0.6456 - val_accuracy: 0.8244 - val_loss: 0.4885 - learning_rate: 1.0000e-04\nEpoch 33/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7731 - loss: 0.5973\nEpoch 33: val_accuracy improved from 0.82437 to 0.82796, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7730 - loss: 0.5972 - val_accuracy: 0.8280 - val_loss: 0.4777 - learning_rate: 1.0000e-04\nEpoch 34/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7508 - loss: 0.6195\nEpoch 34: val_accuracy did not improve from 0.82796\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7512 - loss: 0.6189 - val_accuracy: 0.8172 - val_loss: 0.4760 - learning_rate: 1.0000e-04\nEpoch 35/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7943 - loss: 0.5607\nEpoch 35: val_accuracy improved from 0.82796 to 0.83154, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7941 - loss: 0.5614 - val_accuracy: 0.8315 - val_loss: 0.4771 - learning_rate: 1.0000e-04\nEpoch 36/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7667 - loss: 0.5696\nEpoch 36: val_accuracy did not improve from 0.83154\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7672 - loss: 0.5691 - val_accuracy: 0.8244 - val_loss: 0.4690 - learning_rate: 1.0000e-04\nEpoch 37/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7661 - loss: 0.5797\nEpoch 37: val_accuracy did not improve from 0.83154\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7661 - loss: 0.5797 - val_accuracy: 0.8280 - val_loss: 0.4655 - learning_rate: 1.0000e-04\nEpoch 38/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7835 - loss: 0.5847\nEpoch 38: val_accuracy did not improve from 0.83154\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7836 - loss: 0.5846 - val_accuracy: 0.8280 - val_loss: 0.4673 - learning_rate: 1.0000e-04\nEpoch 39/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7922 - loss: 0.5535\nEpoch 39: val_accuracy did not improve from 0.83154\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7916 - loss: 0.5529 - val_accuracy: 0.8315 - val_loss: 0.4603 - learning_rate: 1.0000e-04\nEpoch 40/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7981 - loss: 0.5606\nEpoch 40: val_accuracy did not improve from 0.83154\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7981 - loss: 0.5605 - val_accuracy: 0.8315 - val_loss: 0.4650 - learning_rate: 1.0000e-04\nEpoch 41/300\n\u001b[1m90/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7865 - loss: 0.5382\nEpoch 41: val_accuracy did not improve from 0.83154\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7861 - loss: 0.5396 - val_accuracy: 0.8315 - val_loss: 0.4627 - learning_rate: 1.0000e-04\nEpoch 42/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7933 - loss: 0.5482\nEpoch 42: val_accuracy did not improve from 0.83154\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.5483 - val_accuracy: 0.8280 - val_loss: 0.4599 - learning_rate: 1.0000e-04\nEpoch 43/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7596 - loss: 0.6040\nEpoch 43: val_accuracy did not improve from 0.83154\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6029 - val_accuracy: 0.8315 - val_loss: 0.4595 - learning_rate: 1.0000e-04\nEpoch 44/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7953 - loss: 0.5292\nEpoch 44: val_accuracy improved from 0.83154 to 0.83871, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7952 - loss: 0.5295 - val_accuracy: 0.8387 - val_loss: 0.4565 - learning_rate: 1.0000e-04\nEpoch 45/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8020 - loss: 0.5227\nEpoch 45: val_accuracy did not improve from 0.83871\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8019 - loss: 0.5228 - val_accuracy: 0.8315 - val_loss: 0.4502 - learning_rate: 1.0000e-04\nEpoch 46/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8054 - loss: 0.5330\nEpoch 46: val_accuracy did not improve from 0.83871\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8050 - loss: 0.5335 - val_accuracy: 0.8351 - val_loss: 0.4494 - learning_rate: 1.0000e-04\nEpoch 47/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7903 - loss: 0.5479\nEpoch 47: val_accuracy did not improve from 0.83871\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7906 - loss: 0.5472 - val_accuracy: 0.8387 - val_loss: 0.4521 - learning_rate: 1.0000e-04\nEpoch 48/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7905 - loss: 0.5496\nEpoch 48: val_accuracy did not improve from 0.83871\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7905 - loss: 0.5490 - val_accuracy: 0.8244 - val_loss: 0.4461 - learning_rate: 1.0000e-04\nEpoch 49/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8038 - loss: 0.5291\nEpoch 49: val_accuracy did not improve from 0.83871\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8040 - loss: 0.5287 - val_accuracy: 0.8280 - val_loss: 0.4453 - learning_rate: 1.0000e-04\nEpoch 50/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8111 - loss: 0.5212\nEpoch 50: val_accuracy improved from 0.83871 to 0.84229, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8109 - loss: 0.5214 - val_accuracy: 0.8423 - val_loss: 0.4440 - learning_rate: 1.0000e-04\nEpoch 51/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7998 - loss: 0.5293\nEpoch 51: val_accuracy did not improve from 0.84229\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7999 - loss: 0.5292 - val_accuracy: 0.8387 - val_loss: 0.4428 - learning_rate: 1.0000e-04\nEpoch 52/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7984 - loss: 0.5557\nEpoch 52: val_accuracy did not improve from 0.84229\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7985 - loss: 0.5553 - val_accuracy: 0.8280 - val_loss: 0.4407 - learning_rate: 1.0000e-04\nEpoch 53/300\n\u001b[1m87/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8241 - loss: 0.5083\nEpoch 53: val_accuracy did not improve from 0.84229\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8218 - loss: 0.5112 - val_accuracy: 0.8387 - val_loss: 0.4353 - learning_rate: 1.0000e-04\nEpoch 54/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8071 - loss: 0.5118\nEpoch 54: val_accuracy improved from 0.84229 to 0.84588, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8071 - loss: 0.5115 - val_accuracy: 0.8459 - val_loss: 0.4362 - learning_rate: 1.0000e-04\nEpoch 55/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8115 - loss: 0.4681\nEpoch 55: val_accuracy improved from 0.84588 to 0.84946, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8113 - loss: 0.4695 - val_accuracy: 0.8495 - val_loss: 0.4330 - learning_rate: 1.0000e-04\nEpoch 56/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8028 - loss: 0.4882\nEpoch 56: val_accuracy did not improve from 0.84946\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8030 - loss: 0.4889 - val_accuracy: 0.8459 - val_loss: 0.4339 - learning_rate: 1.0000e-04\nEpoch 57/300\n\u001b[1m95/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7868 - loss: 0.5155\nEpoch 57: val_accuracy improved from 0.84946 to 0.85305, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7874 - loss: 0.5143 - val_accuracy: 0.8530 - val_loss: 0.4316 - learning_rate: 1.0000e-04\nEpoch 58/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8075 - loss: 0.4798\nEpoch 58: val_accuracy did not improve from 0.85305\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8075 - loss: 0.4800 - val_accuracy: 0.8459 - val_loss: 0.4329 - learning_rate: 1.0000e-04\nEpoch 59/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8148 - loss: 0.4784\nEpoch 59: val_accuracy did not improve from 0.85305\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8146 - loss: 0.4790 - val_accuracy: 0.8351 - val_loss: 0.4347 - learning_rate: 1.0000e-04\nEpoch 60/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7953 - loss: 0.5312\nEpoch 60: val_accuracy did not improve from 0.85305\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7956 - loss: 0.5307 - val_accuracy: 0.8387 - val_loss: 0.4312 - learning_rate: 1.0000e-04\nEpoch 61/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8020 - loss: 0.5019\nEpoch 61: val_accuracy did not improve from 0.85305\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8021 - loss: 0.5011 - val_accuracy: 0.8459 - val_loss: 0.4273 - learning_rate: 1.0000e-04\nEpoch 62/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8189 - loss: 0.4427\nEpoch 62: val_accuracy did not improve from 0.85305\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8187 - loss: 0.4439 - val_accuracy: 0.8495 - val_loss: 0.4223 - learning_rate: 1.0000e-04\nEpoch 63/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8166 - loss: 0.4401\nEpoch 63: val_accuracy did not improve from 0.85305\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8166 - loss: 0.4407 - val_accuracy: 0.8459 - val_loss: 0.4193 - learning_rate: 1.0000e-04\nEpoch 64/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8275 - loss: 0.4379\nEpoch 64: val_accuracy did not improve from 0.85305\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8275 - loss: 0.4380 - val_accuracy: 0.8459 - val_loss: 0.4129 - learning_rate: 1.0000e-04\nEpoch 65/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8227 - loss: 0.4472\nEpoch 65: val_accuracy did not improve from 0.85305\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8227 - loss: 0.4476 - val_accuracy: 0.8423 - val_loss: 0.4091 - learning_rate: 1.0000e-04\nEpoch 66/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8277 - loss: 0.4288\nEpoch 66: val_accuracy did not improve from 0.85305\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8275 - loss: 0.4300 - val_accuracy: 0.8459 - val_loss: 0.4138 - learning_rate: 1.0000e-04\nEpoch 67/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8201 - loss: 0.4931\nEpoch 67: val_accuracy improved from 0.85305 to 0.85663, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8201 - loss: 0.4929 - val_accuracy: 0.8566 - val_loss: 0.4136 - learning_rate: 1.0000e-04\nEpoch 68/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8440 - loss: 0.4421\nEpoch 68: val_accuracy did not improve from 0.85663\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8435 - loss: 0.4431 - val_accuracy: 0.8530 - val_loss: 0.4082 - learning_rate: 1.0000e-04\nEpoch 69/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8145 - loss: 0.4458\nEpoch 69: val_accuracy did not improve from 0.85663\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8149 - loss: 0.4459 - val_accuracy: 0.8495 - val_loss: 0.4082 - learning_rate: 1.0000e-04\nEpoch 70/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8240 - loss: 0.4504\nEpoch 70: val_accuracy did not improve from 0.85663\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8239 - loss: 0.4501 - val_accuracy: 0.8495 - val_loss: 0.4034 - learning_rate: 1.0000e-04\nEpoch 71/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8253 - loss: 0.4320\nEpoch 71: val_accuracy did not improve from 0.85663\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8253 - loss: 0.4327 - val_accuracy: 0.8566 - val_loss: 0.3958 - learning_rate: 1.0000e-04\nEpoch 72/300\n\u001b[1m95/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8117 - loss: 0.4543\nEpoch 72: val_accuracy did not improve from 0.85663\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8125 - loss: 0.4531 - val_accuracy: 0.8566 - val_loss: 0.3926 - learning_rate: 1.0000e-04\nEpoch 73/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8264 - loss: 0.4198\nEpoch 73: val_accuracy did not improve from 0.85663\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8267 - loss: 0.4197 - val_accuracy: 0.8530 - val_loss: 0.3917 - learning_rate: 1.0000e-04\nEpoch 74/300\n\u001b[1m95/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8494 - loss: 0.4011\nEpoch 74: val_accuracy did not improve from 0.85663\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8485 - loss: 0.4026 - val_accuracy: 0.8530 - val_loss: 0.3849 - learning_rate: 1.0000e-04\nEpoch 75/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8352 - loss: 0.4045\nEpoch 75: val_accuracy did not improve from 0.85663\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8350 - loss: 0.4055 - val_accuracy: 0.8566 - val_loss: 0.3819 - learning_rate: 1.0000e-04\nEpoch 76/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8089 - loss: 0.4411\nEpoch 76: val_accuracy did not improve from 0.85663\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8089 - loss: 0.4414 - val_accuracy: 0.8530 - val_loss: 0.3761 - learning_rate: 1.0000e-04\nEpoch 77/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8282 - loss: 0.4603\nEpoch 77: val_accuracy did not improve from 0.85663\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8278 - loss: 0.4605 - val_accuracy: 0.8566 - val_loss: 0.3693 - learning_rate: 1.0000e-04\nEpoch 78/300\n\u001b[1m95/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8469 - loss: 0.4004\nEpoch 78: val_accuracy did not improve from 0.85663\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8467 - loss: 0.4010 - val_accuracy: 0.8566 - val_loss: 0.3741 - learning_rate: 1.0000e-04\nEpoch 79/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8454 - loss: 0.3903\nEpoch 79: val_accuracy did not improve from 0.85663\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8449 - loss: 0.3910 - val_accuracy: 0.8495 - val_loss: 0.3747 - learning_rate: 1.0000e-04\nEpoch 80/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8240 - loss: 0.4285\nEpoch 80: val_accuracy did not improve from 0.85663\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8243 - loss: 0.4280 - val_accuracy: 0.8530 - val_loss: 0.3754 - learning_rate: 1.0000e-04\nEpoch 81/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8381 - loss: 0.4278\nEpoch 81: val_accuracy did not improve from 0.85663\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8379 - loss: 0.4279 - val_accuracy: 0.8495 - val_loss: 0.3662 - learning_rate: 1.0000e-04\nEpoch 82/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8418 - loss: 0.3936\nEpoch 82: val_accuracy improved from 0.85663 to 0.86380, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8416 - loss: 0.3939 - val_accuracy: 0.8638 - val_loss: 0.3649 - learning_rate: 1.0000e-04\nEpoch 83/300\n\u001b[1m94/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8455 - loss: 0.3932\nEpoch 83: val_accuracy did not improve from 0.86380\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8457 - loss: 0.3940 - val_accuracy: 0.8459 - val_loss: 0.3638 - learning_rate: 1.0000e-04\nEpoch 84/300\n\u001b[1m95/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8239 - loss: 0.4092\nEpoch 84: val_accuracy did not improve from 0.86380\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8237 - loss: 0.4099 - val_accuracy: 0.8459 - val_loss: 0.3610 - learning_rate: 1.0000e-04\nEpoch 85/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8235 - loss: 0.4375\nEpoch 85: val_accuracy did not improve from 0.86380\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8239 - loss: 0.4368 - val_accuracy: 0.8495 - val_loss: 0.3557 - learning_rate: 1.0000e-04\nEpoch 86/300\n\u001b[1m95/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8358 - loss: 0.4048\nEpoch 86: val_accuracy did not improve from 0.86380\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8364 - loss: 0.4038 - val_accuracy: 0.8638 - val_loss: 0.3539 - learning_rate: 1.0000e-04\nEpoch 87/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8306 - loss: 0.4287\nEpoch 87: val_accuracy did not improve from 0.86380\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8306 - loss: 0.4279 - val_accuracy: 0.8602 - val_loss: 0.3499 - learning_rate: 1.0000e-04\nEpoch 88/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8451 - loss: 0.3744\nEpoch 88: val_accuracy improved from 0.86380 to 0.87455, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8448 - loss: 0.3750 - val_accuracy: 0.8746 - val_loss: 0.3499 - learning_rate: 1.0000e-04\nEpoch 89/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8474 - loss: 0.3676\nEpoch 89: val_accuracy did not improve from 0.87455\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8479 - loss: 0.3670 - val_accuracy: 0.8710 - val_loss: 0.3469 - learning_rate: 1.0000e-04\nEpoch 90/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8553 - loss: 0.3655\nEpoch 90: val_accuracy did not improve from 0.87455\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8553 - loss: 0.3657 - val_accuracy: 0.8746 - val_loss: 0.3469 - learning_rate: 1.0000e-04\nEpoch 91/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8465 - loss: 0.3926\nEpoch 91: val_accuracy did not improve from 0.87455\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8466 - loss: 0.3926 - val_accuracy: 0.8674 - val_loss: 0.3395 - learning_rate: 1.0000e-04\nEpoch 92/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8600 - loss: 0.3519\nEpoch 92: val_accuracy did not improve from 0.87455\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8597 - loss: 0.3527 - val_accuracy: 0.8674 - val_loss: 0.3435 - learning_rate: 1.0000e-04\nEpoch 93/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8553 - loss: 0.3660\nEpoch 93: val_accuracy did not improve from 0.87455\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8551 - loss: 0.3663 - val_accuracy: 0.8746 - val_loss: 0.3414 - learning_rate: 1.0000e-04\nEpoch 94/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8550 - loss: 0.3613\nEpoch 94: val_accuracy did not improve from 0.87455\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8549 - loss: 0.3604 - val_accuracy: 0.8638 - val_loss: 0.3369 - learning_rate: 1.0000e-04\nEpoch 95/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8319 - loss: 0.3916\nEpoch 95: val_accuracy improved from 0.87455 to 0.88172, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8328 - loss: 0.3898 - val_accuracy: 0.8817 - val_loss: 0.3305 - learning_rate: 1.0000e-04\nEpoch 96/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8544 - loss: 0.3804\nEpoch 96: val_accuracy did not improve from 0.88172\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8536 - loss: 0.3803 - val_accuracy: 0.8602 - val_loss: 0.3341 - learning_rate: 1.0000e-04\nEpoch 97/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8567 - loss: 0.3379\nEpoch 97: val_accuracy did not improve from 0.88172\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8565 - loss: 0.3392 - val_accuracy: 0.8674 - val_loss: 0.3350 - learning_rate: 1.0000e-04\nEpoch 98/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8633 - loss: 0.3538\nEpoch 98: val_accuracy improved from 0.88172 to 0.88530, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8631 - loss: 0.3549 - val_accuracy: 0.8853 - val_loss: 0.3251 - learning_rate: 1.0000e-04\nEpoch 99/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8410 - loss: 0.3802\nEpoch 99: val_accuracy did not improve from 0.88530\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8424 - loss: 0.3800 - val_accuracy: 0.8710 - val_loss: 0.3237 - learning_rate: 1.0000e-04\nEpoch 100/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8469 - loss: 0.3718\nEpoch 100: val_accuracy did not improve from 0.88530\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8469 - loss: 0.3717 - val_accuracy: 0.8674 - val_loss: 0.3199 - learning_rate: 1.0000e-04\nEpoch 101/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8463 - loss: 0.3875\nEpoch 101: val_accuracy did not improve from 0.88530\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8469 - loss: 0.3857 - val_accuracy: 0.8746 - val_loss: 0.3206 - learning_rate: 1.0000e-04\nEpoch 102/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8387 - loss: 0.3965\nEpoch 102: val_accuracy did not improve from 0.88530\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8399 - loss: 0.3950 - val_accuracy: 0.8781 - val_loss: 0.3143 - learning_rate: 1.0000e-04\nEpoch 103/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8362 - loss: 0.3970\nEpoch 103: val_accuracy did not improve from 0.88530\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8374 - loss: 0.3933 - val_accuracy: 0.8817 - val_loss: 0.3146 - learning_rate: 1.0000e-04\nEpoch 104/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8845 - loss: 0.3192\nEpoch 104: val_accuracy did not improve from 0.88530\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8837 - loss: 0.3207 - val_accuracy: 0.8817 - val_loss: 0.3143 - learning_rate: 1.0000e-04\nEpoch 105/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8258 - loss: 0.3999\nEpoch 105: val_accuracy improved from 0.88530 to 0.88889, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8275 - loss: 0.3968 - val_accuracy: 0.8889 - val_loss: 0.3121 - learning_rate: 1.0000e-04\nEpoch 106/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8766 - loss: 0.3348\nEpoch 106: val_accuracy did not improve from 0.88889\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8752 - loss: 0.3359 - val_accuracy: 0.8817 - val_loss: 0.3138 - learning_rate: 1.0000e-04\nEpoch 107/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8625 - loss: 0.3501\nEpoch 107: val_accuracy did not improve from 0.88889\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8630 - loss: 0.3489 - val_accuracy: 0.8817 - val_loss: 0.3126 - learning_rate: 1.0000e-04\nEpoch 108/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8663 - loss: 0.3499\nEpoch 108: val_accuracy did not improve from 0.88889\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8667 - loss: 0.3499 - val_accuracy: 0.8746 - val_loss: 0.3110 - learning_rate: 1.0000e-04\nEpoch 109/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8660 - loss: 0.3385\nEpoch 109: val_accuracy did not improve from 0.88889\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8656 - loss: 0.3389 - val_accuracy: 0.8817 - val_loss: 0.3195 - learning_rate: 1.0000e-04\nEpoch 110/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8763 - loss: 0.3042\nEpoch 110: val_accuracy did not improve from 0.88889\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8761 - loss: 0.3045 - val_accuracy: 0.8853 - val_loss: 0.3095 - learning_rate: 1.0000e-04\nEpoch 111/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8719 - loss: 0.3077\nEpoch 111: val_accuracy improved from 0.88889 to 0.89606, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8707 - loss: 0.3113 - val_accuracy: 0.8961 - val_loss: 0.3009 - learning_rate: 1.0000e-04\nEpoch 112/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8703 - loss: 0.3215\nEpoch 112: val_accuracy did not improve from 0.89606\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8702 - loss: 0.3218 - val_accuracy: 0.8889 - val_loss: 0.3042 - learning_rate: 1.0000e-04\nEpoch 113/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8831 - loss: 0.2995\nEpoch 113: val_accuracy did not improve from 0.89606\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8827 - loss: 0.3006 - val_accuracy: 0.8925 - val_loss: 0.2921 - learning_rate: 1.0000e-04\nEpoch 114/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8749 - loss: 0.3028\nEpoch 114: val_accuracy did not improve from 0.89606\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8753 - loss: 0.3033 - val_accuracy: 0.8925 - val_loss: 0.3004 - learning_rate: 1.0000e-04\nEpoch 115/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8728 - loss: 0.3331\nEpoch 115: val_accuracy improved from 0.89606 to 0.89964, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8718 - loss: 0.3338 - val_accuracy: 0.8996 - val_loss: 0.2939 - learning_rate: 1.0000e-04\nEpoch 116/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8715 - loss: 0.2934\nEpoch 116: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8718 - loss: 0.2945 - val_accuracy: 0.8996 - val_loss: 0.2869 - learning_rate: 1.0000e-04\nEpoch 117/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8596 - loss: 0.3372\nEpoch 117: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8605 - loss: 0.3357 - val_accuracy: 0.8853 - val_loss: 0.3022 - learning_rate: 1.0000e-04\nEpoch 118/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8448 - loss: 0.4235\nEpoch 118: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8461 - loss: 0.4179 - val_accuracy: 0.8889 - val_loss: 0.2976 - learning_rate: 1.0000e-04\nEpoch 119/300\n\u001b[1m93/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9079 - loss: 0.2541\nEpoch 119: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9064 - loss: 0.2570 - val_accuracy: 0.8889 - val_loss: 0.2916 - learning_rate: 1.0000e-04\nEpoch 120/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8914 - loss: 0.3022\nEpoch 120: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8905 - loss: 0.3026 - val_accuracy: 0.8925 - val_loss: 0.3025 - learning_rate: 1.0000e-04\nEpoch 121/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8789 - loss: 0.2851\nEpoch 121: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8790 - loss: 0.2848 - val_accuracy: 0.8889 - val_loss: 0.3000 - learning_rate: 1.0000e-04\nEpoch 122/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8698 - loss: 0.3251\nEpoch 122: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8696 - loss: 0.3260 - val_accuracy: 0.8925 - val_loss: 0.3000 - learning_rate: 1.0000e-04\nEpoch 123/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8804 - loss: 0.3089\nEpoch 123: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8806 - loss: 0.3085 - val_accuracy: 0.8925 - val_loss: 0.3048 - learning_rate: 1.0000e-04\nEpoch 124/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8887 - loss: 0.2891\nEpoch 124: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8873 - loss: 0.2905 - val_accuracy: 0.8961 - val_loss: 0.2985 - learning_rate: 1.0000e-04\nEpoch 125/300\n\u001b[1m93/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8784 - loss: 0.3077\nEpoch 125: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8781 - loss: 0.3074 - val_accuracy: 0.8853 - val_loss: 0.3019 - learning_rate: 1.0000e-04\nEpoch 126/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8585 - loss: 0.3558\nEpoch 126: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8595 - loss: 0.3535 - val_accuracy: 0.8889 - val_loss: 0.3059 - learning_rate: 1.0000e-04\nEpoch 127/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8401 - loss: 0.3521\nEpoch 127: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8425 - loss: 0.3495 - val_accuracy: 0.8925 - val_loss: 0.3038 - learning_rate: 1.0000e-04\nEpoch 128/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8815 - loss: 0.2749\nEpoch 128: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8818 - loss: 0.2765 - val_accuracy: 0.8817 - val_loss: 0.3038 - learning_rate: 1.0000e-04\nEpoch 129/300\n\u001b[1m87/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8782 - loss: 0.3077\nEpoch 129: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8781 - loss: 0.3091 - val_accuracy: 0.8889 - val_loss: 0.2871 - learning_rate: 1.0000e-04\nEpoch 130/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8940 - loss: 0.2805\nEpoch 130: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8933 - loss: 0.2806 - val_accuracy: 0.8889 - val_loss: 0.2870 - learning_rate: 1.0000e-04\nEpoch 131/300\n\u001b[1m93/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8971 - loss: 0.2452\nEpoch 131: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8964 - loss: 0.2474 - val_accuracy: 0.8961 - val_loss: 0.2872 - learning_rate: 1.0000e-04\nEpoch 132/300\n\u001b[1m93/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8851 - loss: 0.2614\nEpoch 132: val_accuracy improved from 0.89964 to 0.90323, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8854 - loss: 0.2614 - val_accuracy: 0.9032 - val_loss: 0.2820 - learning_rate: 1.0000e-04\nEpoch 133/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8977 - loss: 0.2909\nEpoch 133: val_accuracy did not improve from 0.90323\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8972 - loss: 0.2916 - val_accuracy: 0.8996 - val_loss: 0.2797 - learning_rate: 1.0000e-04\nEpoch 134/300\n\u001b[1m90/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8701 - loss: 0.2978\nEpoch 134: val_accuracy improved from 0.90323 to 0.90681, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8708 - loss: 0.2972 - val_accuracy: 0.9068 - val_loss: 0.2795 - learning_rate: 1.0000e-04\nEpoch 135/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8906 - loss: 0.2907\nEpoch 135: val_accuracy did not improve from 0.90681\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8910 - loss: 0.2898 - val_accuracy: 0.8996 - val_loss: 0.2768 - learning_rate: 1.0000e-04\nEpoch 136/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9092 - loss: 0.2644\nEpoch 136: val_accuracy did not improve from 0.90681\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9074 - loss: 0.2673 - val_accuracy: 0.8996 - val_loss: 0.2699 - learning_rate: 1.0000e-04\nEpoch 137/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8918 - loss: 0.2611\nEpoch 137: val_accuracy did not improve from 0.90681\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8922 - loss: 0.2605 - val_accuracy: 0.9068 - val_loss: 0.2785 - learning_rate: 1.0000e-04\nEpoch 138/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8912 - loss: 0.2591\nEpoch 138: val_accuracy did not improve from 0.90681\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8905 - loss: 0.2611 - val_accuracy: 0.9032 - val_loss: 0.2743 - learning_rate: 1.0000e-04\nEpoch 139/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8910 - loss: 0.2521\nEpoch 139: val_accuracy improved from 0.90681 to 0.91039, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8910 - loss: 0.2537 - val_accuracy: 0.9104 - val_loss: 0.2643 - learning_rate: 1.0000e-04\nEpoch 140/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8962 - loss: 0.2692\nEpoch 140: val_accuracy did not improve from 0.91039\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8956 - loss: 0.2698 - val_accuracy: 0.9032 - val_loss: 0.2662 - learning_rate: 1.0000e-04\nEpoch 141/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8860 - loss: 0.2786\nEpoch 141: val_accuracy did not improve from 0.91039\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8864 - loss: 0.2777 - val_accuracy: 0.9032 - val_loss: 0.2679 - learning_rate: 1.0000e-04\nEpoch 142/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8808 - loss: 0.2799\nEpoch 142: val_accuracy did not improve from 0.91039\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8812 - loss: 0.2795 - val_accuracy: 0.9032 - val_loss: 0.2766 - learning_rate: 1.0000e-04\nEpoch 143/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8964 - loss: 0.2647\nEpoch 143: val_accuracy did not improve from 0.91039\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8966 - loss: 0.2631 - val_accuracy: 0.9068 - val_loss: 0.2717 - learning_rate: 1.0000e-04\nEpoch 144/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8954 - loss: 0.2399\nEpoch 144: val_accuracy did not improve from 0.91039\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8963 - loss: 0.2391 - val_accuracy: 0.8996 - val_loss: 0.2797 - learning_rate: 1.0000e-04\nEpoch 145/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9171 - loss: 0.2353\nEpoch 145: val_accuracy did not improve from 0.91039\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9164 - loss: 0.2364 - val_accuracy: 0.8996 - val_loss: 0.2837 - learning_rate: 1.0000e-04\nEpoch 146/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9043 - loss: 0.2323\nEpoch 146: val_accuracy did not improve from 0.91039\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9046 - loss: 0.2319 - val_accuracy: 0.9032 - val_loss: 0.2714 - learning_rate: 1.0000e-04\nEpoch 147/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9189 - loss: 0.2203\nEpoch 147: val_accuracy did not improve from 0.91039\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9171 - loss: 0.2244 - val_accuracy: 0.8961 - val_loss: 0.2757 - learning_rate: 1.0000e-04\nEpoch 148/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9035 - loss: 0.2375\nEpoch 148: val_accuracy did not improve from 0.91039\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9031 - loss: 0.2389 - val_accuracy: 0.9032 - val_loss: 0.2714 - learning_rate: 1.0000e-04\nEpoch 149/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8930 - loss: 0.2584\nEpoch 149: val_accuracy did not improve from 0.91039\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8932 - loss: 0.2587 - val_accuracy: 0.9104 - val_loss: 0.2694 - learning_rate: 1.0000e-04\nEpoch 150/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8875 - loss: 0.2693\nEpoch 150: val_accuracy did not improve from 0.91039\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8874 - loss: 0.2693 - val_accuracy: 0.9104 - val_loss: 0.2683 - learning_rate: 1.0000e-04\nEpoch 151/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9136 - loss: 0.2283\nEpoch 151: val_accuracy improved from 0.91039 to 0.91398, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9132 - loss: 0.2287 - val_accuracy: 0.9140 - val_loss: 0.2742 - learning_rate: 1.0000e-04\nEpoch 152/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9175 - loss: 0.2233\nEpoch 152: val_accuracy did not improve from 0.91398\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9170 - loss: 0.2249 - val_accuracy: 0.8925 - val_loss: 0.2758 - learning_rate: 1.0000e-04\nEpoch 153/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9047 - loss: 0.2306\nEpoch 153: val_accuracy did not improve from 0.91398\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9045 - loss: 0.2309 - val_accuracy: 0.9104 - val_loss: 0.2840 - learning_rate: 1.0000e-04\nEpoch 154/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9065 - loss: 0.2525\nEpoch 154: val_accuracy did not improve from 0.91398\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9071 - loss: 0.2505 - val_accuracy: 0.9032 - val_loss: 0.2911 - learning_rate: 1.0000e-04\nEpoch 155/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9020 - loss: 0.2455\nEpoch 155: val_accuracy did not improve from 0.91398\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9021 - loss: 0.2453 - val_accuracy: 0.8996 - val_loss: 0.2836 - learning_rate: 1.0000e-04\nEpoch 156/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9162 - loss: 0.2054\nEpoch 156: val_accuracy did not improve from 0.91398\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9153 - loss: 0.2076 - val_accuracy: 0.8996 - val_loss: 0.2848 - learning_rate: 1.0000e-04\nEpoch 157/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9211 - loss: 0.2040\nEpoch 157: val_accuracy did not improve from 0.91398\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9210 - loss: 0.2053 - val_accuracy: 0.9068 - val_loss: 0.2738 - learning_rate: 1.0000e-04\nEpoch 158/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9007 - loss: 0.2242\nEpoch 158: val_accuracy did not improve from 0.91398\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9010 - loss: 0.2239 - val_accuracy: 0.9032 - val_loss: 0.2747 - learning_rate: 1.0000e-04\nEpoch 159/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9084 - loss: 0.2393\nEpoch 159: val_accuracy did not improve from 0.91398\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9079 - loss: 0.2394 - val_accuracy: 0.9032 - val_loss: 0.2705 - learning_rate: 1.0000e-04\nEpoch 160/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8998 - loss: 0.2527\nEpoch 160: val_accuracy did not improve from 0.91398\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9003 - loss: 0.2515 - val_accuracy: 0.9068 - val_loss: 0.2709 - learning_rate: 1.0000e-04\nEpoch 161/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8951 - loss: 0.2335\nEpoch 161: val_accuracy did not improve from 0.91398\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8950 - loss: 0.2345 - val_accuracy: 0.9032 - val_loss: 0.2889 - learning_rate: 1.0000e-04\nEpoch 162/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8867 - loss: 0.2902\nEpoch 162: val_accuracy did not improve from 0.91398\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8882 - loss: 0.2871 - val_accuracy: 0.8996 - val_loss: 0.2791 - learning_rate: 1.0000e-04\nEpoch 163/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9046 - loss: 0.2269\nEpoch 163: val_accuracy did not improve from 0.91398\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9051 - loss: 0.2265 - val_accuracy: 0.9068 - val_loss: 0.2772 - learning_rate: 1.0000e-04\nEpoch 164/300\n\u001b[1m90/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9085 - loss: 0.2508\nEpoch 164: val_accuracy did not improve from 0.91398\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9086 - loss: 0.2500 - val_accuracy: 0.9104 - val_loss: 0.2778 - learning_rate: 1.0000e-04\nEpoch 165/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9150 - loss: 0.2190\nEpoch 165: val_accuracy did not improve from 0.91398\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9144 - loss: 0.2205 - val_accuracy: 0.9032 - val_loss: 0.2663 - learning_rate: 1.0000e-04\nEpoch 166/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9151 - loss: 0.2032\nEpoch 166: val_accuracy did not improve from 0.91398\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9147 - loss: 0.2045 - val_accuracy: 0.9140 - val_loss: 0.2750 - learning_rate: 1.0000e-04\nEpoch 167/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9025 - loss: 0.2388\nEpoch 167: val_accuracy did not improve from 0.91398\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9034 - loss: 0.2379 - val_accuracy: 0.9140 - val_loss: 0.2631 - learning_rate: 1.0000e-04\nEpoch 168/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9148 - loss: 0.1977\nEpoch 168: val_accuracy did not improve from 0.91398\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9144 - loss: 0.1994 - val_accuracy: 0.9104 - val_loss: 0.2694 - learning_rate: 1.0000e-04\nEpoch 169/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9216 - loss: 0.2176\nEpoch 169: val_accuracy did not improve from 0.91398\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9219 - loss: 0.2162 - val_accuracy: 0.9032 - val_loss: 0.2613 - learning_rate: 1.0000e-04\nEpoch 170/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9178 - loss: 0.2107\nEpoch 170: val_accuracy improved from 0.91398 to 0.92115, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9177 - loss: 0.2101 - val_accuracy: 0.9211 - val_loss: 0.2547 - learning_rate: 1.0000e-04\nEpoch 171/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9033 - loss: 0.2528\nEpoch 171: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9039 - loss: 0.2502 - val_accuracy: 0.9032 - val_loss: 0.2531 - learning_rate: 1.0000e-04\nEpoch 172/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9058 - loss: 0.2480\nEpoch 172: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9069 - loss: 0.2460 - val_accuracy: 0.9104 - val_loss: 0.2599 - learning_rate: 1.0000e-04\nEpoch 173/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9094 - loss: 0.2166\nEpoch 173: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9092 - loss: 0.2169 - val_accuracy: 0.9104 - val_loss: 0.2585 - learning_rate: 1.0000e-04\nEpoch 174/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9055 - loss: 0.2117\nEpoch 174: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9057 - loss: 0.2122 - val_accuracy: 0.9068 - val_loss: 0.2584 - learning_rate: 1.0000e-04\nEpoch 175/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9033 - loss: 0.2043\nEpoch 175: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9040 - loss: 0.2038 - val_accuracy: 0.9104 - val_loss: 0.2575 - learning_rate: 1.0000e-04\nEpoch 176/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9161 - loss: 0.2174\nEpoch 176: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9162 - loss: 0.2176 - val_accuracy: 0.9032 - val_loss: 0.2474 - learning_rate: 1.0000e-04\nEpoch 177/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9184 - loss: 0.2308\nEpoch 177: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9186 - loss: 0.2296 - val_accuracy: 0.9068 - val_loss: 0.2647 - learning_rate: 1.0000e-04\nEpoch 178/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9384 - loss: 0.1886\nEpoch 178: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9376 - loss: 0.1893 - val_accuracy: 0.9032 - val_loss: 0.2508 - learning_rate: 1.0000e-04\nEpoch 179/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9337 - loss: 0.1734\nEpoch 179: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9333 - loss: 0.1741 - val_accuracy: 0.9104 - val_loss: 0.2745 - learning_rate: 1.0000e-04\nEpoch 180/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9353 - loss: 0.1558\nEpoch 180: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9347 - loss: 0.1576 - val_accuracy: 0.9068 - val_loss: 0.2661 - learning_rate: 1.0000e-04\nEpoch 181/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9291 - loss: 0.1773\nEpoch 181: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9288 - loss: 0.1785 - val_accuracy: 0.9176 - val_loss: 0.2710 - learning_rate: 1.0000e-04\nEpoch 182/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8989 - loss: 0.1981\nEpoch 182: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9001 - loss: 0.1986 - val_accuracy: 0.9176 - val_loss: 0.2774 - learning_rate: 1.0000e-04\nEpoch 183/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9350 - loss: 0.1672\nEpoch 183: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9337 - loss: 0.1701 - val_accuracy: 0.9140 - val_loss: 0.2842 - learning_rate: 1.0000e-04\nEpoch 184/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9159 - loss: 0.1986\nEpoch 184: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9156 - loss: 0.1998 - val_accuracy: 0.9140 - val_loss: 0.2757 - learning_rate: 1.0000e-04\nEpoch 185/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9153 - loss: 0.2054\nEpoch 185: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9156 - loss: 0.2050 - val_accuracy: 0.9176 - val_loss: 0.2754 - learning_rate: 1.0000e-04\nEpoch 186/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9195 - loss: 0.2066\nEpoch 186: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9198 - loss: 0.2058 - val_accuracy: 0.9140 - val_loss: 0.2851 - learning_rate: 1.0000e-04\nEpoch 187/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9338 - loss: 0.1723\nEpoch 187: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9328 - loss: 0.1738 - val_accuracy: 0.9140 - val_loss: 0.2726 - learning_rate: 1.0000e-04\nEpoch 188/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9306 - loss: 0.2029\nEpoch 188: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9301 - loss: 0.2028 - val_accuracy: 0.9176 - val_loss: 0.2603 - learning_rate: 1.0000e-04\nEpoch 189/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9333 - loss: 0.1662\nEpoch 189: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9326 - loss: 0.1681 - val_accuracy: 0.9176 - val_loss: 0.2664 - learning_rate: 1.0000e-04\nEpoch 190/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9267 - loss: 0.2102\nEpoch 190: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\nEpoch 190: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9264 - loss: 0.2093 - val_accuracy: 0.9140 - val_loss: 0.2703 - learning_rate: 1.0000e-04\nEpoch 191/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9355 - loss: 0.1618\nEpoch 191: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9352 - loss: 0.1625 - val_accuracy: 0.9140 - val_loss: 0.2674 - learning_rate: 5.0000e-05\nEpoch 192/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9191 - loss: 0.2277\nEpoch 192: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9200 - loss: 0.2243 - val_accuracy: 0.9140 - val_loss: 0.2648 - learning_rate: 5.0000e-05\nEpoch 193/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9339 - loss: 0.1816\nEpoch 193: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9335 - loss: 0.1817 - val_accuracy: 0.9104 - val_loss: 0.2618 - learning_rate: 5.0000e-05\nEpoch 194/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9284 - loss: 0.1752\nEpoch 194: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9291 - loss: 0.1743 - val_accuracy: 0.9140 - val_loss: 0.2679 - learning_rate: 5.0000e-05\nEpoch 195/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9195 - loss: 0.1802\nEpoch 195: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9204 - loss: 0.1808 - val_accuracy: 0.9176 - val_loss: 0.2629 - learning_rate: 5.0000e-05\nEpoch 196/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9392 - loss: 0.1646\nEpoch 196: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9387 - loss: 0.1659 - val_accuracy: 0.9176 - val_loss: 0.2654 - learning_rate: 5.0000e-05\nEpoch 197/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9371 - loss: 0.1613\nEpoch 197: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9367 - loss: 0.1621 - val_accuracy: 0.9140 - val_loss: 0.2690 - learning_rate: 5.0000e-05\nEpoch 198/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9123 - loss: 0.2264\nEpoch 198: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9132 - loss: 0.2232 - val_accuracy: 0.9176 - val_loss: 0.2687 - learning_rate: 5.0000e-05\nEpoch 199/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9337 - loss: 0.1694\nEpoch 199: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9332 - loss: 0.1705 - val_accuracy: 0.9104 - val_loss: 0.2679 - learning_rate: 5.0000e-05\nEpoch 200/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9383 - loss: 0.1726\nEpoch 200: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9379 - loss: 0.1741 - val_accuracy: 0.9140 - val_loss: 0.2631 - learning_rate: 5.0000e-05\nEpoch 201/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9340 - loss: 0.1551\nEpoch 201: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9344 - loss: 0.1552 - val_accuracy: 0.9140 - val_loss: 0.2697 - learning_rate: 5.0000e-05\nEpoch 202/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9470 - loss: 0.1399\nEpoch 202: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9463 - loss: 0.1410 - val_accuracy: 0.9140 - val_loss: 0.2690 - learning_rate: 5.0000e-05\nEpoch 203/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9069 - loss: 0.2381\nEpoch 203: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9081 - loss: 0.2348 - val_accuracy: 0.9104 - val_loss: 0.2647 - learning_rate: 5.0000e-05\nEpoch 204/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9382 - loss: 0.1615\nEpoch 204: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9384 - loss: 0.1605 - val_accuracy: 0.9104 - val_loss: 0.2655 - learning_rate: 5.0000e-05\nEpoch 205/300\n\u001b[1m87/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9563 - loss: 0.1200\nEpoch 205: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9551 - loss: 0.1231 - val_accuracy: 0.9140 - val_loss: 0.2670 - learning_rate: 5.0000e-05\nEpoch 206/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9337 - loss: 0.1578\nEpoch 206: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9335 - loss: 0.1584 - val_accuracy: 0.9211 - val_loss: 0.2694 - learning_rate: 5.0000e-05\nEpoch 207/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9334 - loss: 0.1524\nEpoch 207: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9323 - loss: 0.1557 - val_accuracy: 0.9176 - val_loss: 0.2622 - learning_rate: 5.0000e-05\nEpoch 208/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9532 - loss: 0.1329\nEpoch 208: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9521 - loss: 0.1339 - val_accuracy: 0.9211 - val_loss: 0.2541 - learning_rate: 5.0000e-05\nEpoch 209/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9339 - loss: 0.1699\nEpoch 209: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9336 - loss: 0.1703 - val_accuracy: 0.9176 - val_loss: 0.2513 - learning_rate: 5.0000e-05\nEpoch 210/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9494 - loss: 0.1564\nEpoch 210: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\nEpoch 210: val_accuracy did not improve from 0.92115\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9484 - loss: 0.1567 - val_accuracy: 0.9176 - val_loss: 0.2591 - learning_rate: 5.0000e-05\nEpoch 210: early stopping\nRestoring model weights from the end of the best epoch: 170.\nâœ… Fixed super advanced training completed!\n\nğŸ¯ FIXED SUPER ADVANCED MODEL ACCURACY: 0.9211\nğŸ‰ ğŸ‰ ğŸ‰ UNBELIEVABLE! 90%+ ACHIEVED! ğŸ‰ ğŸ‰ ğŸ‰\nğŸš€ BREAKTHROUGH! +0.0431 improvement!\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"# ======================================\n# 3ï¸âƒ£7ï¸âƒ£ MODEL EVALUATION & METRICS\n# ======================================\n\n\nprint(\"ğŸ“Š Evaluating Super Advanced Model...\")\n\n# --- 1. Training history plots ---\nhistory = super_history.history\n\nplt.figure(figsize=(12,5))\n\n# Loss\nplt.subplot(1,2,1)\nplt.plot(history['loss'], label='Train Loss')\nplt.plot(history['val_loss'], label='Val Loss')\nplt.title('Loss over Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid(True)\n\n# Accuracy\nplt.subplot(1,2,2)\nplt.plot(history['accuracy'], label='Train Accuracy')\nplt.plot(history['val_accuracy'], label='Val Accuracy')\nplt.title('Accuracy over Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n\n# --- 2. Predictions on validation set ---\ny_val_pred_probs = super_model.predict([X_tab_aug_val, X_mel_aug_val_pca], verbose=0)\ny_val_pred = np.argmax(y_val_pred_probs, axis=1)\n\n# --- 3. Confusion Matrix ---\ncm = confusion_matrix(y_aug_val, y_val_pred)\nplt.figure(figsize=(8,6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\n# --- 4. Classification Report ---\nreport = classification_report(y_aug_val, y_val_pred, digits=4)\nprint(\"ğŸ“„ Classification Report:\\n\")\nprint(report)\n\n# --- 5. Overall accuracy ---\nfrom sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_aug_val, y_val_pred)\nprint(f\"\\nğŸ¯ Overall Validation Accuracy: {accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T11:46:19.653519Z","iopub.execute_input":"2025-12-01T11:46:19.653720Z","iopub.status.idle":"2025-12-01T11:46:20.251378Z","shell.execute_reply.started":"2025-12-01T11:46:19.653705Z","shell.execute_reply":"2025-12-01T11:46:20.250768Z"}},"outputs":[{"name":"stdout","text":"ğŸ“Š Evaluating Super Advanced Model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x500 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"ğŸ“„ Classification Report:\n\n              precision    recall  f1-score   support\n\n           0     0.8734    0.9583    0.9139        72\n           1     0.9402    0.9091    0.9244       121\n           2     0.9398    0.9070    0.9231        86\n\n    accuracy                         0.9211       279\n   macro avg     0.9178    0.9248    0.9205       279\nweighted avg     0.9228    0.9211    0.9213       279\n\n\nğŸ¯ Overall Validation Accuracy: 0.9211\n","output_type":"stream"}],"execution_count":45}]}