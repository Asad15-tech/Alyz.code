{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":87331,"databundleVersionId":10191418,"sourceType":"competition"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ======================================\n# Snippet 1: Data Loading + MFCC Features + Basic Missing Data Analysis\n# ======================================\n\n# -----------------------------\n# IMPORTS\n# -----------------------------\nimport os\nimport librosa\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nimport seaborn as sns\n\n\nprint(\"ğŸš€ Loading competition data... / Competition data load kar rahe hain...\")\n\n# -----------------------------\n# DATA LOADING\n# -----------------------------\ntrain_csv = \"/kaggle/input/airs-ai-in-respiratory-sounds/train.csv\"\naudio_path = \"/kaggle/input/airs-ai-in-respiratory-sounds/sounds/sounds\"\n\ntrain_df = pd.read_csv(train_csv)\nprint(f\"âœ… Training data loaded: {train_df.shape} / Training data ka size\")\n\n# -----------------------------\n# TABULAR FEATURES\n# -----------------------------\ntab_features = ['age', 'gender', 'tbContactHistory', 'wheezingHistory', 'phlegmCough',\n                'familyAsthmaHistory', 'feverHistory', 'coldPresent', 'packYears']\n\n# -----------------------------\n# AUDIO FILE MAPPING\n# -----------------------------\nfile_map = {}\nfor folder in os.listdir(audio_path):\n    fpath = os.path.join(audio_path, folder)\n    if os.path.isdir(fpath):\n        wavs = [f for f in os.listdir(fpath) if f.endswith(\".wav\")]\n        if wavs:\n            file_map[folder] = os.path.join(fpath, wavs[0])\n\nprint(f\"âœ… Audio files mapped: {len(file_map)} / Total audio files mapped\")\n\n# -----------------------------\n# MFCC FEATURE EXTRACTION FUNCTION\n# -----------------------------\ndef extract_mfcc_features(file_path, n_mfcc=40, duration=5, sr=22050):\n    \"\"\"Extract MFCC + chroma + mel features / MFCC aur extra features extract karte hain\"\"\"\n    try:\n        y, sr = librosa.load(file_path, sr=sr, duration=duration)\n        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n        mfcc_scaled = np.mean(mfcc.T, axis=0)\n\n        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n        chroma_scaled = np.mean(chroma.T, axis=0)\n\n        mel = librosa.feature.melspectrogram(y=y, sr=sr)\n        mel_scaled = np.mean(mel.T, axis=0)\n\n        features = np.hstack([mfcc_scaled, chroma_scaled, mel_scaled])\n        return features\n    except Exception as e:\n        print(f\"Error processing {file_path}: {e}\")\n        return np.zeros(n_mfcc + 12 + 128)  # Fallback\n\nprint(\"ğŸµ Extracting MFCC features for all audio files...\")\n\nX_audio = []\nvalid_ids = []\nfor i, cid in enumerate(train_df['candidateID']):\n    if cid in file_map:\n        features = extract_mfcc_features(file_map[cid])\n        X_audio.append(features)\n        valid_ids.append(cid)\n    if (i + 1) % 100 == 0:\n        print(f\"Processed {i + 1} files... / {i+1} files process ho chuki hain\")\n\nX_audio = np.array(X_audio)\n\n# -----------------------------\n# FILTER TABULAR & TARGET DATA\n# -----------------------------\ndf = train_df[train_df['candidateID'].isin(valid_ids)]\nX_tab = df[tab_features].values\ny = df['disease'].values\n\nprint(f\"âœ… MFCC features shape: {X_audio.shape}\")\nprint(f\"âœ… Dataset size after filtering: {len(df)}\")\nprint(f\"âœ… Unique classes: {len(np.unique(y))}\")\n\n# -----------------------------\n# BASIC MISSING DATA ANALYSIS\n# -----------------------------\nmissing_data = df[tab_features].isnull().sum()\nmissing_percent = (missing_data / len(df)) * 100\nmissing_summary = pd.DataFrame({\n    'Feature': tab_features,\n    'Missing_Count': missing_data,\n    'Missing_Percent': missing_percent\n})\nprint(\"\\nğŸ” Basic Missing Data Analysis / Missing data summary\")\nprint(missing_summary)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:22:43.584070Z","iopub.execute_input":"2025-12-01T21:22:43.584711Z","iopub.status.idle":"2025-12-01T21:23:38.376439Z","shell.execute_reply.started":"2025-12-01T21:22:43.584685Z","shell.execute_reply":"2025-12-01T21:23:38.375585Z"}},"outputs":[{"name":"stdout","text":"ğŸš€ Loading competition data... / Competition data load kar rahe hain...\nâœ… Training data loaded: (546, 11) / Training data ka size\nâœ… Audio files mapped: 882 / Total audio files mapped\nğŸµ Extracting MFCC features for all audio files...\nProcessed 100 files... / 100 files process ho chuki hain\nProcessed 200 files... / 200 files process ho chuki hain\nProcessed 300 files... / 300 files process ho chuki hain\nProcessed 400 files... / 400 files process ho chuki hain\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/librosa/core/pitch.py:103: UserWarning: Trying to estimate tuning from empty frequency set.\n  return pitch_tuning(\n","output_type":"stream"},{"name":"stdout","text":"Processed 500 files... / 500 files process ho chuki hain\nâœ… MFCC features shape: (546, 180)\nâœ… Dataset size after filtering: 546\nâœ… Unique classes: 3\n\nğŸ” Basic Missing Data Analysis / Missing data summary\n                                 Feature  Missing_Count  Missing_Percent\nage                                  age              0         0.000000\ngender                            gender              0         0.000000\ntbContactHistory        tbContactHistory              0         0.000000\nwheezingHistory          wheezingHistory              0         0.000000\nphlegmCough                  phlegmCough              0         0.000000\nfamilyAsthmaHistory  familyAsthmaHistory              0         0.000000\nfeverHistory                feverHistory              0         0.000000\ncoldPresent                  coldPresent            148        27.106227\npackYears                      packYears              0         0.000000\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ======================================\n# Snippet 2: Advanced Imputation (Iterative) + Tabular Preprocessing + Scaling\n# ======================================\n\nprint(\"ğŸ”„ Applying Iterative Imputation (MICE) / Iterative imputation apply kar rahe hain...\")\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\n# Original tabular data\nX_tab_original = X_tab.copy()\ny_original = y.copy()\n\n# -----------------------------\n# 1ï¸âƒ£ Iterative Imputation (MICE) for all missing values\n# -----------------------------\niterative_imputer = IterativeImputer(\n    max_iter=10,\n    random_state=42,\n    estimator=RandomForestClassifier(n_estimators=50, random_state=42)\n)\n\nX_tab_iterative = iterative_imputer.fit_transform(X_tab_original)\nprint(\"âœ… Iterative imputation applied / Iterative imputation complete\")\n\n# -----------------------------\n# 2ï¸âƒ£ Select Iterative Imputation as final dataset\n# -----------------------------\nX_tab_best = X_tab_iterative\nprint(\"âœ… Using Iterative Imputation for final dataset / Iterative imputation final dataset ke liye select kiya\")\n\n# -----------------------------\n# 3ï¸âƒ£ Scale Tabular Features\n# -----------------------------\nscaler_tab = StandardScaler()\nX_tab_scaled = scaler_tab.fit_transform(X_tab_best)\nprint(\"âœ… Tabular features scaled / Tabular features scaling complete\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:23:38.377938Z","iopub.execute_input":"2025-12-01T21:23:38.378406Z","iopub.status.idle":"2025-12-01T21:23:40.030747Z","shell.execute_reply.started":"2025-12-01T21:23:38.378386Z","shell.execute_reply":"2025-12-01T21:23:40.029911Z"}},"outputs":[{"name":"stdout","text":"ğŸ”„ Applying Iterative Imputation (MICE) / Iterative imputation apply kar rahe hain...\nâœ… Iterative imputation applied / Iterative imputation complete\nâœ… Using Iterative Imputation for final dataset / Iterative imputation final dataset ke liye select kiya\nâœ… Tabular features scaled / Tabular features scaling complete\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ======================================\n# Snippet 3: Train-Validation Split + MFCC reshaping + Class Weights\n# ======================================\n\nprint(\"ğŸš€ Creating train-validation split / Train-validation split bana rahe hain...\")\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\n\n# Filter to cases with available audio data\nvalid_indices = [i for i, cid in enumerate(train_df[\"candidateID\"]) if cid in file_map]\n\nX_tab_final_scaled = X_tab_scaled[valid_indices]  # Tabular features\nX_audio_final = X_audio[valid_indices]           # MFCC / Audio features\ny_final = y_original[valid_indices]              # Target labels\n\nprint(f\"âœ… Final dataset: {len(X_tab_final_scaled)} samples / Final dataset samples count\")\n\n# -----------------------------\n# 1ï¸âƒ£ Train-Validation Split\n# -----------------------------\nX_tab_train, X_tab_val, X_audio_train, X_audio_val, y_train, y_val = train_test_split(\n    X_tab_final_scaled, X_audio_final, y_final,\n    test_size=0.15,\n    stratify=y_final,\n    random_state=42\n)\n\nprint(\"âœ… Train-validation split done / Train-validation split complete\")\n\n# -----------------------------\n# 2ï¸âƒ£ Reshape Audio for CNN Input\n# -----------------------------\nX_audio_train = X_audio_train.reshape(X_audio_train.shape[0], X_audio_train.shape[1], 1)\nX_audio_val = X_audio_val.reshape(X_audio_val.shape[0], X_audio_val.shape[1], 1)\n\nprint(f\"Audio train shape: {X_audio_train.shape} / Audio validation shape: {X_audio_val.shape}\")\n\n# -----------------------------\n# 3ï¸âƒ£ Compute Class Weights for Imbalanced Data\n# -----------------------------\nclass_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(y_train),\n    y=y_train\n)\n\nclass_weight_dict = dict(enumerate(class_weights))\nprint(f\"âœ… Class weights computed / Class weights: {class_weight_dict}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:23:40.031694Z","iopub.execute_input":"2025-12-01T21:23:40.031976Z","iopub.status.idle":"2025-12-01T21:23:40.043190Z","shell.execute_reply.started":"2025-12-01T21:23:40.031957Z","shell.execute_reply":"2025-12-01T21:23:40.042613Z"}},"outputs":[{"name":"stdout","text":"ğŸš€ Creating train-validation split / Train-validation split bana rahe hain...\nâœ… Final dataset: 546 samples / Final dataset samples count\nâœ… Train-validation split done / Train-validation split complete\nAudio train shape: (464, 180, 1) / Audio validation shape: (82, 180, 1)\nâœ… Class weights computed / Class weights: {0: 1.2997198879551821, 1: 0.7656765676567657, 2: 1.0815850815850816}\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# --- Create flattened MFCC for augmentation ---\nX_mel_2d = X_audio_train.reshape(X_audio_train.shape[0], -1)\nX_tab_mel = X_tab_train\ny_mel = y_train\n\n# Advanced augmentation for 1D flattened MFCC/Mel\ndef advanced_flat_augmentation(feature_vector):\n    augmented = feature_vector.copy()\n    \n    # Random noise\n    if np.random.random() > 0.5:\n        noise = np.random.normal(0, 0.01, augmented.shape)\n        augmented += noise\n    \n    # Random shift\n    if np.random.random() > 0.5:\n        shift = np.random.randint(-5, 5)\n        augmented = np.roll(augmented, shift)\n    \n    return augmented\n\n# Augmented dataset\nX_mel_augmented = []\nX_tab_augmented = []\ny_augmented = []\n\n# Original data\nX_mel_augmented.extend(X_mel_2d)\nX_tab_augmented.extend(X_tab_mel)\ny_augmented.extend(y_mel)\n\n# Augmented data (3x)\nfor i in range(len(X_mel_2d)):\n    for _ in range(3):\n        aug_mel = advanced_flat_augmentation(X_mel_2d[i])\n        X_mel_augmented.append(aug_mel)\n        X_tab_augmented.append(X_tab_mel[i])\n        y_augmented.append(y_mel[i])\n\nX_mel_augmented = np.array(X_mel_augmented)\nX_tab_augmented = np.array(X_tab_augmented)\ny_augmented = np.array(y_augmented)\n\nprint(f\"âœ… Augmented dataset: {len(X_mel_augmented)} samples (original: {len(X_mel_2d)})\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:23:40.044125Z","iopub.execute_input":"2025-12-01T21:23:40.044430Z","iopub.status.idle":"2025-12-01T21:23:40.090757Z","shell.execute_reply.started":"2025-12-01T21:23:40.044405Z","shell.execute_reply":"2025-12-01T21:23:40.089973Z"}},"outputs":[{"name":"stdout","text":"âœ… Augmented dataset: 1856 samples (original: 464)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ======================================\n# 3ï¸âƒ£4.5ï¸âƒ£ SPLIT AUGMENTED DATA\n# ======================================\n\nprint(\"ğŸ“Š Splitting augmented dataset into train and validation / Train aur val split kar rahe hain...\")\n\nfrom sklearn.model_selection import train_test_split\n\nX_tab_aug_train, X_tab_aug_val, X_mel_aug_train, X_mel_aug_val, y_aug_train, y_aug_val = train_test_split(\n    X_tab_augmented, X_mel_augmented, y_augmented,\n    test_size=0.15, stratify=y_augmented, random_state=42\n)\n\nprint(f\"âœ… Train set: {len(X_tab_aug_train)} samples, Validation set: {len(X_tab_aug_val)} samples\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:23:40.092566Z","iopub.execute_input":"2025-12-01T21:23:40.092835Z","iopub.status.idle":"2025-12-01T21:23:40.101275Z","shell.execute_reply.started":"2025-12-01T21:23:40.092818Z","shell.execute_reply":"2025-12-01T21:23:40.100641Z"}},"outputs":[{"name":"stdout","text":"ğŸ“Š Splitting augmented dataset into train and validation / Train aur val split kar rahe hain...\nâœ… Train set: 1577 samples, Validation set: 279 samples\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ======================================\n# 3ï¸âƒ£5ï¸âƒ£ FIXED SUPER ADVANCED MODEL\n# ======================================\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, Model\n\nprint(\"ğŸ”„ Creating Fixed Super Advanced Model / Super advanced model create kar rahe hain...\")\nnum_classes = 3\n\ndef create_fixed_super_advanced_model(tabular_dim, pretrained_dim, num_classes):\n    \"\"\"Fixed super advanced model for 90%+ accuracy\"\"\"\n    \n    # Pre-trained features input\n    pretrained_input = tf.keras.Input(shape=(pretrained_dim,), name='pretrained_features')\n    \n    x_pretrained = layers.Dense(1024, activation='relu')(pretrained_input)\n    x_pretrained = layers.BatchNormalization()(x_pretrained)\n    x_pretrained = layers.Dropout(0.4)(x_pretrained)\n    \n    x_pretrained = layers.Dense(512, activation='relu')(x_pretrained)\n    x_pretrained = layers.BatchNormalization()(x_pretrained)\n    x_pretrained = layers.Dropout(0.3)(x_pretrained)\n    \n    x_pretrained = layers.Dense(256, activation='relu')(x_pretrained)\n    x_pretrained = layers.BatchNormalization()(x_pretrained)\n    x_pretrained = layers.Dropout(0.2)(x_pretrained)\n    \n    # Tabular input\n    tabular_input = tf.keras.Input(shape=(tabular_dim,), name='tabular_input')\n    \n    x_tab = layers.Dense(256, activation='relu')(tabular_input)\n    x_tab = layers.BatchNormalization()(x_tab)\n    x_tab = layers.Dropout(0.3)(x_tab)\n    \n    x_tab = layers.Dense(128, activation='relu')(x_tab)\n    x_tab = layers.BatchNormalization()(x_tab)\n    x_tab = layers.Dropout(0.2)(x_tab)\n    \n    x_tab = layers.Dense(64, activation='relu')(x_tab)\n    \n    # Combine\n    combined = layers.concatenate([x_pretrained, x_tab])\n    \n    # Advanced classification\n    x = layers.Dense(512, activation='relu')(combined)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.5)(x)\n    \n    # Residual block 1\n    residual1 = layers.Dense(512, activation='relu')(x)\n    residual1 = layers.BatchNormalization()(residual1)\n    x = layers.add([x, residual1])\n    x = layers.Dropout(0.4)(x)\n    \n    # Residual block 2\n    x = layers.Dense(256, activation='relu')(x)\n    x = layers.BatchNormalization()(x)\n    residual2 = layers.Dense(256, activation='relu')(x)\n    residual2 = layers.BatchNormalization()(residual2)\n    x = layers.add([x, residual2])\n    x = layers.Dropout(0.3)(x)\n    \n    x = layers.Dense(128, activation='relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.2)(x)\n    \n    x = layers.Dense(64, activation='relu')(x)\n    \n    output = layers.Dense(num_classes, activation='softmax')(x)\n    \n    model = Model(\n        inputs=[tabular_input, pretrained_input],\n        outputs=output,\n        name='fixed_super_advanced_model'\n    )\n    \n    return model\n\n# âœ… Create model\nsuper_model = create_fixed_super_advanced_model(\n    tabular_dim=X_tab_aug_train.shape[1],\n    pretrained_dim=X_mel_aug_train.shape[1],  # MFCC / flattened features\n    num_classes=num_classes\n)\n\nsuper_model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nprint(\"âœ… Fixed super advanced model created!\")\nsuper_model.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:23:40.101938Z","iopub.execute_input":"2025-12-01T21:23:40.102154Z","iopub.status.idle":"2025-12-01T21:23:57.677452Z","shell.execute_reply.started":"2025-12-01T21:23:40.102135Z","shell.execute_reply":"2025-12-01T21:23:57.676647Z"}},"outputs":[{"name":"stderr","text":"2025-12-01 21:23:41.482545: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764624221.652418      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764624221.705281      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"ğŸ”„ Creating Fixed Super Advanced Model / Super advanced model create kar rahe hain...\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1764624236.265340      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"âœ… Fixed super advanced model created!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"fixed_super_advanced_model\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"fixed_super_advanced_model\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ pretrained_features â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\nâ”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      â”‚    \u001b[38;5;34m185,344\u001b[0m â”‚ pretrained_featuâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalization â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      â”‚      \u001b[38;5;34m4,096\u001b[0m â”‚ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ tabular_input       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\nâ”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚      \u001b[38;5;34m2,560\u001b[0m â”‚ tabular_input[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚    \u001b[38;5;34m524,800\u001b[0m â”‚ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚     \u001b[38;5;34m32,896\u001b[0m â”‚ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚    \u001b[38;5;34m131,328\u001b[0m â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m512\u001b[0m â”‚ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m8,256\u001b[0m â”‚ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ concatenate         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\nâ”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚    \u001b[38;5;34m164,352\u001b[0m â”‚ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚    \u001b[38;5;34m262,656\u001b[0m â”‚ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add (\u001b[38;5;33mAdd\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\nâ”‚                     â”‚                   â”‚            â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_8 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚    \u001b[38;5;34m131,328\u001b[0m â”‚ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_9 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚     \u001b[38;5;34m65,792\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add_1 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_10 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚     \u001b[38;5;34m32,896\u001b[0m â”‚ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m512\u001b[0m â”‚ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_11 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m8,256\u001b[0m â”‚ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_12 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         â”‚        \u001b[38;5;34m195\u001b[0m â”‚ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ pretrained_features â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">185,344</span> â”‚ pretrained_featuâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalization â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ tabular_input       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560</span> â”‚ tabular_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> â”‚ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ concatenate         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> â”‚ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> â”‚ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\nâ”‚                     â”‚                   â”‚            â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> â”‚ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”‚                     â”‚                   â”‚            â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> â”‚ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,566,019\u001b[0m (5.97 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,566,019</span> (5.97 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,558,339\u001b[0m (5.94 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,558,339</span> (5.94 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,680\u001b[0m (30.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> (30.00 KB)\n</pre>\n"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# ======================================\n# 3ï¸âƒ£6ï¸âƒ£ FIXED SUPER ADVANCED MODEL TRAINING WITH PCA REDUCED MFCC\n# ======================================\n\nprint(\"ğŸ¯ Preparing data and training Fixed Super Advanced Model with PCA-reduced MFCC...\")\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.utils.class_weight import compute_class_weight\n\n# --- 1. Flatten MFCC / Mel-spectrograms ---\nX_mel_aug_train_flat = X_mel_aug_train.reshape(X_mel_aug_train.shape[0], -1)\nX_mel_aug_val_flat   = X_mel_aug_val.reshape(X_mel_aug_val.shape[0], -1)\n\n# --- 2. Reduce dimensionality to 128 features using PCA ---\npca = PCA(n_components=128, random_state=42)\nX_mel_aug_train_pca = pca.fit_transform(X_mel_aug_train_flat)\nX_mel_aug_val_pca   = pca.transform(X_mel_aug_val_flat)\n\nprint(f\"âœ… MFCC features reduced: Train {X_mel_aug_train_pca.shape}, Val {X_mel_aug_val_pca.shape}\")\n\n# --- 3. Create super advanced model ---\nsuper_model = create_fixed_super_advanced_model(\n    tabular_dim=X_tab_aug_train.shape[1],\n    pretrained_dim=128,  # Matches PCA output\n    num_classes=num_classes\n)\n\nsuper_model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nprint(\"âœ… Super advanced model created and compiled!\")\n\n# --- 4. Class weights ---\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_aug_train), y=y_aug_train)\nclass_weight_dict = dict(enumerate(class_weights))\nprint(f\"âœ… Class weights: {class_weight_dict}\")\n\n# --- 5. Callbacks ---\nenhanced_callbacks = [\n    tf.keras.callbacks.EarlyStopping(\n        monitor='val_accuracy',\n        patience=40,\n        restore_best_weights=True,\n        verbose=1\n    ),\n    tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_accuracy',\n        factor=0.5,\n        patience=20,\n        min_lr=1e-8,\n        verbose=1\n    ),\n    tf.keras.callbacks.ModelCheckpoint(\n        'fixed_super_advanced_model.h5',\n        monitor='val_accuracy',\n        save_best_only=True,\n        verbose=1\n    )\n]\n\n# --- 6. Train the model ---\nprint(\"ğŸš€ Training fixed super advanced model with PCA-reduced MFCC...\")\nsuper_history = super_model.fit(\n    [X_tab_aug_train, X_mel_aug_train_pca],\n    y_aug_train,\n    batch_size=16,\n    epochs=300,\n    validation_data=([X_tab_aug_val, X_mel_aug_val_pca], y_aug_val),\n    callbacks=enhanced_callbacks,\n    class_weight=class_weight_dict,\n    verbose=1\n)\n\nprint(\"âœ… Fixed super advanced training completed!\")\n\n# --- 7. Load best weights and evaluate ---\nsuper_model.load_weights('fixed_super_advanced_model.h5')\n\nsuper_pred = super_model.predict([X_tab_aug_val, X_mel_aug_val_pca], verbose=0)\nsuper_accuracy = accuracy_score(y_aug_val, np.argmax(super_pred, axis=1))\n\nprint(f\"\\nğŸ¯ FIXED SUPER ADVANCED MODEL ACCURACY: {super_accuracy:.4f}\")\n\n# --- 8. Performance check ---\nprevious_best = 0.8780\nimprovement = super_accuracy - previous_best\n\nif super_accuracy >= 0.90:\n    print(f\"ğŸ‰ ğŸ‰ ğŸ‰ UNBELIEVABLE! 90%+ ACHIEVED! ğŸ‰ ğŸ‰ ğŸ‰\")\n    print(f\"ğŸš€ BREAKTHROUGH! +{improvement:.4f} improvement!\")\nelif super_accuracy >= 0.88:\n    print(f\"ğŸ”¥ EXCELLENT! {super_accuracy:.4f} accuracy!\")\n    print(f\"ğŸ’ª Very close to 90%!\")\nelse:\n    print(f\"ğŸ’ª Good progress: {super_accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:23:57.678247Z","iopub.execute_input":"2025-12-01T21:23:57.678856Z","iopub.status.idle":"2025-12-01T21:26:38.851989Z","shell.execute_reply.started":"2025-12-01T21:23:57.678834Z","shell.execute_reply":"2025-12-01T21:26:38.851061Z"}},"outputs":[{"name":"stdout","text":"ğŸ¯ Preparing data and training Fixed Super Advanced Model with PCA-reduced MFCC...\nâœ… MFCC features reduced: Train (1577, 128), Val (279, 128)\nâœ… Super advanced model created and compiled!\nâœ… Class weights: {0: 1.301155115511551, 1: 0.7651625424551188, 2: 1.0816186556927299}\nğŸš€ Training fixed super advanced model with PCA-reduced MFCC...\nEpoch 1/300\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1764624245.014861     115 service.cc:148] XLA service 0x794188002fc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1764624245.015399     115 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1764624246.042718     115 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m38/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3196 - loss: 1.4260","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1764624252.065757     115 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3194 - loss: 1.4057\nEpoch 1: val_accuracy improved from -inf to 0.29032, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - accuracy: 0.3196 - loss: 1.4052 - val_accuracy: 0.2903 - val_loss: 1.1483 - learning_rate: 1.0000e-04\nEpoch 2/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3428 - loss: 1.3185\nEpoch 2: val_accuracy improved from 0.29032 to 0.31541, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3429 - loss: 1.3186 - val_accuracy: 0.3154 - val_loss: 1.1377 - learning_rate: 1.0000e-04\nEpoch 3/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3978 - loss: 1.2293\nEpoch 3: val_accuracy did not improve from 0.31541\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3969 - loss: 1.2302 - val_accuracy: 0.3154 - val_loss: 1.1284 - learning_rate: 1.0000e-04\nEpoch 4/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3814 - loss: 1.2177\nEpoch 4: val_accuracy improved from 0.31541 to 0.34409, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3814 - loss: 1.2178 - val_accuracy: 0.3441 - val_loss: 1.1141 - learning_rate: 1.0000e-04\nEpoch 5/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3901 - loss: 1.1984\nEpoch 5: val_accuracy improved from 0.34409 to 0.43011, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3903 - loss: 1.1982 - val_accuracy: 0.4301 - val_loss: 1.0725 - learning_rate: 1.0000e-04\nEpoch 6/300\n\u001b[1m95/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4174 - loss: 1.1835\nEpoch 6: val_accuracy improved from 0.43011 to 0.43728, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4184 - loss: 1.1817 - val_accuracy: 0.4373 - val_loss: 1.0399 - learning_rate: 1.0000e-04\nEpoch 7/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4384 - loss: 1.1428\nEpoch 7: val_accuracy improved from 0.43728 to 0.49104, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4387 - loss: 1.1417 - val_accuracy: 0.4910 - val_loss: 0.9967 - learning_rate: 1.0000e-04\nEpoch 8/300\n\u001b[1m93/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4528 - loss: 1.0825\nEpoch 8: val_accuracy improved from 0.49104 to 0.60932, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4534 - loss: 1.0828 - val_accuracy: 0.6093 - val_loss: 0.9300 - learning_rate: 1.0000e-04\nEpoch 9/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4892 - loss: 1.0220\nEpoch 9: val_accuracy improved from 0.60932 to 0.64516, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4890 - loss: 1.0224 - val_accuracy: 0.6452 - val_loss: 0.8700 - learning_rate: 1.0000e-04\nEpoch 10/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5035 - loss: 0.9911\nEpoch 10: val_accuracy improved from 0.64516 to 0.67384, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5036 - loss: 0.9909 - val_accuracy: 0.6738 - val_loss: 0.8100 - learning_rate: 1.0000e-04\nEpoch 11/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5531 - loss: 0.9207\nEpoch 11: val_accuracy improved from 0.67384 to 0.68817, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5535 - loss: 0.9209 - val_accuracy: 0.6882 - val_loss: 0.7786 - learning_rate: 1.0000e-04\nEpoch 12/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5788 - loss: 0.8912\nEpoch 12: val_accuracy improved from 0.68817 to 0.71326, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5795 - loss: 0.8903 - val_accuracy: 0.7133 - val_loss: 0.7284 - learning_rate: 1.0000e-04\nEpoch 13/300\n\u001b[1m89/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6215 - loss: 0.8279\nEpoch 13: val_accuracy improved from 0.71326 to 0.74910, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6208 - loss: 0.8311 - val_accuracy: 0.7491 - val_loss: 0.6943 - learning_rate: 1.0000e-04\nEpoch 14/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6760 - loss: 0.7648\nEpoch 14: val_accuracy did not improve from 0.74910\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6759 - loss: 0.7648 - val_accuracy: 0.7419 - val_loss: 0.6696 - learning_rate: 1.0000e-04\nEpoch 15/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6739 - loss: 0.7573\nEpoch 15: val_accuracy improved from 0.74910 to 0.75627, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6739 - loss: 0.7572 - val_accuracy: 0.7563 - val_loss: 0.6307 - learning_rate: 1.0000e-04\nEpoch 16/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6909 - loss: 0.7471\nEpoch 16: val_accuracy improved from 0.75627 to 0.77061, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6912 - loss: 0.7460 - val_accuracy: 0.7706 - val_loss: 0.6238 - learning_rate: 1.0000e-04\nEpoch 17/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7169 - loss: 0.6919\nEpoch 17: val_accuracy improved from 0.77061 to 0.78495, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7153 - loss: 0.6943 - val_accuracy: 0.7849 - val_loss: 0.6209 - learning_rate: 1.0000e-04\nEpoch 18/300\n\u001b[1m89/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7218 - loss: 0.7088\nEpoch 18: val_accuracy improved from 0.78495 to 0.78853, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7218 - loss: 0.7075 - val_accuracy: 0.7885 - val_loss: 0.6119 - learning_rate: 1.0000e-04\nEpoch 19/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7134 - loss: 0.7044\nEpoch 19: val_accuracy improved from 0.78853 to 0.79211, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7135 - loss: 0.7042 - val_accuracy: 0.7921 - val_loss: 0.5964 - learning_rate: 1.0000e-04\nEpoch 20/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7246 - loss: 0.6866\nEpoch 20: val_accuracy improved from 0.79211 to 0.79928, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7249 - loss: 0.6863 - val_accuracy: 0.7993 - val_loss: 0.5931 - learning_rate: 1.0000e-04\nEpoch 21/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7176 - loss: 0.6719\nEpoch 21: val_accuracy did not improve from 0.79928\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7178 - loss: 0.6719 - val_accuracy: 0.7957 - val_loss: 0.5933 - learning_rate: 1.0000e-04\nEpoch 22/300\n\u001b[1m90/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7537 - loss: 0.6219\nEpoch 22: val_accuracy did not improve from 0.79928\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7542 - loss: 0.6221 - val_accuracy: 0.7885 - val_loss: 0.6006 - learning_rate: 1.0000e-04\nEpoch 23/300\n\u001b[1m89/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7511 - loss: 0.6458\nEpoch 23: val_accuracy did not improve from 0.79928\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7508 - loss: 0.6465 - val_accuracy: 0.7778 - val_loss: 0.5891 - learning_rate: 1.0000e-04\nEpoch 24/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7319 - loss: 0.6303\nEpoch 24: val_accuracy did not improve from 0.79928\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7320 - loss: 0.6306 - val_accuracy: 0.7814 - val_loss: 0.5818 - learning_rate: 1.0000e-04\nEpoch 25/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7377 - loss: 0.6597\nEpoch 25: val_accuracy did not improve from 0.79928\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7385 - loss: 0.6594 - val_accuracy: 0.7957 - val_loss: 0.5704 - learning_rate: 1.0000e-04\nEpoch 26/300\n\u001b[1m90/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7296 - loss: 0.6785\nEpoch 26: val_accuracy did not improve from 0.79928\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7320 - loss: 0.6739 - val_accuracy: 0.7921 - val_loss: 0.5785 - learning_rate: 1.0000e-04\nEpoch 27/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7840 - loss: 0.5938\nEpoch 27: val_accuracy did not improve from 0.79928\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7838 - loss: 0.5939 - val_accuracy: 0.7957 - val_loss: 0.5790 - learning_rate: 1.0000e-04\nEpoch 28/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7825 - loss: 0.5739\nEpoch 28: val_accuracy did not improve from 0.79928\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7824 - loss: 0.5743 - val_accuracy: 0.7957 - val_loss: 0.5702 - learning_rate: 1.0000e-04\nEpoch 29/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7561 - loss: 0.6063\nEpoch 29: val_accuracy improved from 0.79928 to 0.80287, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7562 - loss: 0.6062 - val_accuracy: 0.8029 - val_loss: 0.5565 - learning_rate: 1.0000e-04\nEpoch 30/300\n\u001b[1m89/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7779 - loss: 0.5915\nEpoch 30: val_accuracy improved from 0.80287 to 0.81720, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7776 - loss: 0.5909 - val_accuracy: 0.8172 - val_loss: 0.5488 - learning_rate: 1.0000e-04\nEpoch 31/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7713 - loss: 0.6033\nEpoch 31: val_accuracy did not improve from 0.81720\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7714 - loss: 0.6023 - val_accuracy: 0.8029 - val_loss: 0.5438 - learning_rate: 1.0000e-04\nEpoch 32/300\n\u001b[1m90/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7977 - loss: 0.5580\nEpoch 32: val_accuracy did not improve from 0.81720\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7965 - loss: 0.5620 - val_accuracy: 0.8029 - val_loss: 0.5423 - learning_rate: 1.0000e-04\nEpoch 33/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7963 - loss: 0.5640\nEpoch 33: val_accuracy did not improve from 0.81720\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7944 - loss: 0.5658 - val_accuracy: 0.7993 - val_loss: 0.5386 - learning_rate: 1.0000e-04\nEpoch 34/300\n\u001b[1m89/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7649 - loss: 0.6263\nEpoch 34: val_accuracy did not improve from 0.81720\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7662 - loss: 0.6232 - val_accuracy: 0.8065 - val_loss: 0.5373 - learning_rate: 1.0000e-04\nEpoch 35/300\n\u001b[1m89/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7894 - loss: 0.5636\nEpoch 35: val_accuracy did not improve from 0.81720\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7894 - loss: 0.5620 - val_accuracy: 0.8029 - val_loss: 0.5307 - learning_rate: 1.0000e-04\nEpoch 36/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7956 - loss: 0.5388\nEpoch 36: val_accuracy did not improve from 0.81720\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7939 - loss: 0.5436 - val_accuracy: 0.8065 - val_loss: 0.5321 - learning_rate: 1.0000e-04\nEpoch 37/300\n\u001b[1m89/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7770 - loss: 0.5890\nEpoch 37: val_accuracy did not improve from 0.81720\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7784 - loss: 0.5859 - val_accuracy: 0.8100 - val_loss: 0.5213 - learning_rate: 1.0000e-04\nEpoch 38/300\n\u001b[1m89/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7910 - loss: 0.5577\nEpoch 38: val_accuracy did not improve from 0.81720\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7912 - loss: 0.5561 - val_accuracy: 0.8100 - val_loss: 0.5221 - learning_rate: 1.0000e-04\nEpoch 39/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7860 - loss: 0.5488\nEpoch 39: val_accuracy did not improve from 0.81720\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7857 - loss: 0.5498 - val_accuracy: 0.8029 - val_loss: 0.5231 - learning_rate: 1.0000e-04\nEpoch 40/300\n\u001b[1m87/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8106 - loss: 0.5278\nEpoch 40: val_accuracy did not improve from 0.81720\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8102 - loss: 0.5290 - val_accuracy: 0.8100 - val_loss: 0.5256 - learning_rate: 1.0000e-04\nEpoch 41/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8034 - loss: 0.5157\nEpoch 41: val_accuracy did not improve from 0.81720\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8034 - loss: 0.5157 - val_accuracy: 0.8065 - val_loss: 0.5237 - learning_rate: 1.0000e-04\nEpoch 42/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8040 - loss: 0.5196\nEpoch 42: val_accuracy did not improve from 0.81720\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8043 - loss: 0.5203 - val_accuracy: 0.8065 - val_loss: 0.5112 - learning_rate: 1.0000e-04\nEpoch 43/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7932 - loss: 0.5242\nEpoch 43: val_accuracy did not improve from 0.81720\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7933 - loss: 0.5243 - val_accuracy: 0.8065 - val_loss: 0.5073 - learning_rate: 1.0000e-04\nEpoch 44/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7973 - loss: 0.5292\nEpoch 44: val_accuracy did not improve from 0.81720\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7973 - loss: 0.5293 - val_accuracy: 0.8100 - val_loss: 0.5034 - learning_rate: 1.0000e-04\nEpoch 45/300\n\u001b[1m89/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7988 - loss: 0.5213\nEpoch 45: val_accuracy improved from 0.81720 to 0.82079, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7995 - loss: 0.5212 - val_accuracy: 0.8208 - val_loss: 0.4952 - learning_rate: 1.0000e-04\nEpoch 46/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8221 - loss: 0.4576\nEpoch 46: val_accuracy improved from 0.82079 to 0.82437, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8204 - loss: 0.4630 - val_accuracy: 0.8244 - val_loss: 0.4906 - learning_rate: 1.0000e-04\nEpoch 47/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7979 - loss: 0.5331\nEpoch 47: val_accuracy did not improve from 0.82437\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7979 - loss: 0.5331 - val_accuracy: 0.8136 - val_loss: 0.4846 - learning_rate: 1.0000e-04\nEpoch 48/300\n\u001b[1m90/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8067 - loss: 0.4943\nEpoch 48: val_accuracy did not improve from 0.82437\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8062 - loss: 0.4959 - val_accuracy: 0.8244 - val_loss: 0.4781 - learning_rate: 1.0000e-04\nEpoch 49/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8148 - loss: 0.5276\nEpoch 49: val_accuracy improved from 0.82437 to 0.82796, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8145 - loss: 0.5276 - val_accuracy: 0.8280 - val_loss: 0.4677 - learning_rate: 1.0000e-04\nEpoch 50/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8027 - loss: 0.4961\nEpoch 50: val_accuracy did not improve from 0.82796\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8043 - loss: 0.4951 - val_accuracy: 0.8244 - val_loss: 0.4725 - learning_rate: 1.0000e-04\nEpoch 51/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8178 - loss: 0.4998\nEpoch 51: val_accuracy did not improve from 0.82796\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8178 - loss: 0.4998 - val_accuracy: 0.8244 - val_loss: 0.4729 - learning_rate: 1.0000e-04\nEpoch 52/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8284 - loss: 0.4612\nEpoch 52: val_accuracy did not improve from 0.82796\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8282 - loss: 0.4620 - val_accuracy: 0.8172 - val_loss: 0.4684 - learning_rate: 1.0000e-04\nEpoch 53/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8140 - loss: 0.4851\nEpoch 53: val_accuracy did not improve from 0.82796\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8141 - loss: 0.4863 - val_accuracy: 0.8172 - val_loss: 0.4640 - learning_rate: 1.0000e-04\nEpoch 54/300\n\u001b[1m89/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8299 - loss: 0.4337\nEpoch 54: val_accuracy did not improve from 0.82796\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8278 - loss: 0.4388 - val_accuracy: 0.8136 - val_loss: 0.4643 - learning_rate: 1.0000e-04\nEpoch 55/300\n\u001b[1m89/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8266 - loss: 0.4741\nEpoch 55: val_accuracy did not improve from 0.82796\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8261 - loss: 0.4755 - val_accuracy: 0.8136 - val_loss: 0.4680 - learning_rate: 1.0000e-04\nEpoch 56/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8222 - loss: 0.4904\nEpoch 56: val_accuracy did not improve from 0.82796\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8213 - loss: 0.4925 - val_accuracy: 0.8172 - val_loss: 0.4631 - learning_rate: 1.0000e-04\nEpoch 57/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8090 - loss: 0.5040\nEpoch 57: val_accuracy did not improve from 0.82796\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8090 - loss: 0.5040 - val_accuracy: 0.8172 - val_loss: 0.4565 - learning_rate: 1.0000e-04\nEpoch 58/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7936 - loss: 0.5239\nEpoch 58: val_accuracy did not improve from 0.82796\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7938 - loss: 0.5237 - val_accuracy: 0.8136 - val_loss: 0.4590 - learning_rate: 1.0000e-04\nEpoch 59/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8214 - loss: 0.4529\nEpoch 59: val_accuracy did not improve from 0.82796\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8211 - loss: 0.4537 - val_accuracy: 0.8244 - val_loss: 0.4565 - learning_rate: 1.0000e-04\nEpoch 60/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8226 - loss: 0.4836\nEpoch 60: val_accuracy did not improve from 0.82796\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8226 - loss: 0.4836 - val_accuracy: 0.8244 - val_loss: 0.4560 - learning_rate: 1.0000e-04\nEpoch 61/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8280 - loss: 0.4288\nEpoch 61: val_accuracy did not improve from 0.82796\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8272 - loss: 0.4323 - val_accuracy: 0.8172 - val_loss: 0.4571 - learning_rate: 1.0000e-04\nEpoch 62/300\n\u001b[1m89/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8219 - loss: 0.4742\nEpoch 62: val_accuracy did not improve from 0.82796\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8226 - loss: 0.4709 - val_accuracy: 0.8208 - val_loss: 0.4546 - learning_rate: 1.0000e-04\nEpoch 63/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8069 - loss: 0.5113\nEpoch 63: val_accuracy did not improve from 0.82796\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8072 - loss: 0.5106 - val_accuracy: 0.8244 - val_loss: 0.4491 - learning_rate: 1.0000e-04\nEpoch 64/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8285 - loss: 0.4367\nEpoch 64: val_accuracy did not improve from 0.82796\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8277 - loss: 0.4379 - val_accuracy: 0.8208 - val_loss: 0.4519 - learning_rate: 1.0000e-04\nEpoch 65/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8055 - loss: 0.4727\nEpoch 65: val_accuracy did not improve from 0.82796\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8055 - loss: 0.4726 - val_accuracy: 0.8280 - val_loss: 0.4496 - learning_rate: 1.0000e-04\nEpoch 66/300\n\u001b[1m89/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8241 - loss: 0.4619\nEpoch 66: val_accuracy did not improve from 0.82796\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8233 - loss: 0.4625 - val_accuracy: 0.8208 - val_loss: 0.4524 - learning_rate: 1.0000e-04\nEpoch 67/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8160 - loss: 0.4418\nEpoch 67: val_accuracy did not improve from 0.82796\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8163 - loss: 0.4417 - val_accuracy: 0.8280 - val_loss: 0.4441 - learning_rate: 1.0000e-04\nEpoch 68/300\n\u001b[1m87/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8290 - loss: 0.4505\nEpoch 68: val_accuracy did not improve from 0.82796\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8291 - loss: 0.4511 - val_accuracy: 0.8280 - val_loss: 0.4447 - learning_rate: 1.0000e-04\nEpoch 69/300\n\u001b[1m89/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8332 - loss: 0.4475\nEpoch 69: val_accuracy improved from 0.82796 to 0.83871, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8328 - loss: 0.4489 - val_accuracy: 0.8387 - val_loss: 0.4421 - learning_rate: 1.0000e-04\nEpoch 70/300\n\u001b[1m95/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8199 - loss: 0.4487\nEpoch 70: val_accuracy did not improve from 0.83871\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8201 - loss: 0.4491 - val_accuracy: 0.8387 - val_loss: 0.4346 - learning_rate: 1.0000e-04\nEpoch 71/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8102 - loss: 0.4571\nEpoch 71: val_accuracy improved from 0.83871 to 0.84946, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8103 - loss: 0.4570 - val_accuracy: 0.8495 - val_loss: 0.4303 - learning_rate: 1.0000e-04\nEpoch 72/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8432 - loss: 0.4245\nEpoch 72: val_accuracy did not improve from 0.84946\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8431 - loss: 0.4246 - val_accuracy: 0.8495 - val_loss: 0.4344 - learning_rate: 1.0000e-04\nEpoch 73/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8335 - loss: 0.4393\nEpoch 73: val_accuracy did not improve from 0.84946\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8335 - loss: 0.4395 - val_accuracy: 0.8459 - val_loss: 0.4292 - learning_rate: 1.0000e-04\nEpoch 74/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8375 - loss: 0.3947\nEpoch 74: val_accuracy did not improve from 0.84946\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8373 - loss: 0.3951 - val_accuracy: 0.8351 - val_loss: 0.4324 - learning_rate: 1.0000e-04\nEpoch 75/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8524 - loss: 0.3929\nEpoch 75: val_accuracy did not improve from 0.84946\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8500 - loss: 0.3977 - val_accuracy: 0.8423 - val_loss: 0.4341 - learning_rate: 1.0000e-04\nEpoch 76/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8323 - loss: 0.4349\nEpoch 76: val_accuracy did not improve from 0.84946\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8323 - loss: 0.4350 - val_accuracy: 0.8423 - val_loss: 0.4251 - learning_rate: 1.0000e-04\nEpoch 77/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8518 - loss: 0.4355\nEpoch 77: val_accuracy did not improve from 0.84946\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8517 - loss: 0.4354 - val_accuracy: 0.8495 - val_loss: 0.4220 - learning_rate: 1.0000e-04\nEpoch 78/300\n\u001b[1m87/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8576 - loss: 0.3975\nEpoch 78: val_accuracy improved from 0.84946 to 0.85663, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8563 - loss: 0.4011 - val_accuracy: 0.8566 - val_loss: 0.4165 - learning_rate: 1.0000e-04\nEpoch 79/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8491 - loss: 0.4129\nEpoch 79: val_accuracy did not improve from 0.85663\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8486 - loss: 0.4131 - val_accuracy: 0.8423 - val_loss: 0.4174 - learning_rate: 1.0000e-04\nEpoch 80/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7999 - loss: 0.4753\nEpoch 80: val_accuracy did not improve from 0.85663\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8000 - loss: 0.4750 - val_accuracy: 0.8495 - val_loss: 0.4090 - learning_rate: 1.0000e-04\nEpoch 81/300\n\u001b[1m94/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8277 - loss: 0.3907\nEpoch 81: val_accuracy improved from 0.85663 to 0.86380, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8285 - loss: 0.3909 - val_accuracy: 0.8638 - val_loss: 0.4101 - learning_rate: 1.0000e-04\nEpoch 82/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8179 - loss: 0.4177\nEpoch 82: val_accuracy did not improve from 0.86380\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8180 - loss: 0.4176 - val_accuracy: 0.8530 - val_loss: 0.4092 - learning_rate: 1.0000e-04\nEpoch 83/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8473 - loss: 0.4074\nEpoch 83: val_accuracy did not improve from 0.86380\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8475 - loss: 0.4067 - val_accuracy: 0.8495 - val_loss: 0.4140 - learning_rate: 1.0000e-04\nEpoch 84/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8432 - loss: 0.4124\nEpoch 84: val_accuracy did not improve from 0.86380\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8433 - loss: 0.4121 - val_accuracy: 0.8638 - val_loss: 0.3993 - learning_rate: 1.0000e-04\nEpoch 85/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8353 - loss: 0.4265\nEpoch 85: val_accuracy improved from 0.86380 to 0.87097, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8355 - loss: 0.4262 - val_accuracy: 0.8710 - val_loss: 0.4008 - learning_rate: 1.0000e-04\nEpoch 86/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8672 - loss: 0.3624\nEpoch 86: val_accuracy did not improve from 0.87097\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8668 - loss: 0.3631 - val_accuracy: 0.8566 - val_loss: 0.4001 - learning_rate: 1.0000e-04\nEpoch 87/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8453 - loss: 0.4216\nEpoch 87: val_accuracy did not improve from 0.87097\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8459 - loss: 0.4178 - val_accuracy: 0.8638 - val_loss: 0.4021 - learning_rate: 1.0000e-04\nEpoch 88/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8192 - loss: 0.4223\nEpoch 88: val_accuracy did not improve from 0.87097\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8206 - loss: 0.4205 - val_accuracy: 0.8530 - val_loss: 0.4163 - learning_rate: 1.0000e-04\nEpoch 89/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8629 - loss: 0.3948\nEpoch 89: val_accuracy did not improve from 0.87097\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8626 - loss: 0.3948 - val_accuracy: 0.8566 - val_loss: 0.4060 - learning_rate: 1.0000e-04\nEpoch 90/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8356 - loss: 0.4008\nEpoch 90: val_accuracy did not improve from 0.87097\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8372 - loss: 0.3976 - val_accuracy: 0.8566 - val_loss: 0.4103 - learning_rate: 1.0000e-04\nEpoch 91/300\n\u001b[1m87/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8545 - loss: 0.3779\nEpoch 91: val_accuracy did not improve from 0.87097\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8538 - loss: 0.3786 - val_accuracy: 0.8674 - val_loss: 0.4029 - learning_rate: 1.0000e-04\nEpoch 92/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8516 - loss: 0.3604\nEpoch 92: val_accuracy did not improve from 0.87097\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8507 - loss: 0.3640 - val_accuracy: 0.8674 - val_loss: 0.3956 - learning_rate: 1.0000e-04\nEpoch 93/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8463 - loss: 0.4017\nEpoch 93: val_accuracy did not improve from 0.87097\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8472 - loss: 0.3987 - val_accuracy: 0.8674 - val_loss: 0.3860 - learning_rate: 1.0000e-04\nEpoch 94/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8685 - loss: 0.3741\nEpoch 94: val_accuracy did not improve from 0.87097\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8670 - loss: 0.3764 - val_accuracy: 0.8602 - val_loss: 0.3866 - learning_rate: 1.0000e-04\nEpoch 95/300\n\u001b[1m90/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8331 - loss: 0.3820\nEpoch 95: val_accuracy did not improve from 0.87097\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8334 - loss: 0.3834 - val_accuracy: 0.8602 - val_loss: 0.3952 - learning_rate: 1.0000e-04\nEpoch 96/300\n\u001b[1m90/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8449 - loss: 0.3633\nEpoch 96: val_accuracy did not improve from 0.87097\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8454 - loss: 0.3629 - val_accuracy: 0.8602 - val_loss: 0.3944 - learning_rate: 1.0000e-04\nEpoch 97/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8371 - loss: 0.3914\nEpoch 97: val_accuracy improved from 0.87097 to 0.87455, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8373 - loss: 0.3908 - val_accuracy: 0.8746 - val_loss: 0.3880 - learning_rate: 1.0000e-04\nEpoch 98/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8721 - loss: 0.3396\nEpoch 98: val_accuracy did not improve from 0.87455\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8719 - loss: 0.3397 - val_accuracy: 0.8746 - val_loss: 0.3900 - learning_rate: 1.0000e-04\nEpoch 99/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8210 - loss: 0.4163\nEpoch 99: val_accuracy did not improve from 0.87455\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8243 - loss: 0.4107 - val_accuracy: 0.8746 - val_loss: 0.3879 - learning_rate: 1.0000e-04\nEpoch 100/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8740 - loss: 0.3258\nEpoch 100: val_accuracy improved from 0.87455 to 0.87814, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8738 - loss: 0.3260 - val_accuracy: 0.8781 - val_loss: 0.3833 - learning_rate: 1.0000e-04\nEpoch 101/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8329 - loss: 0.4175\nEpoch 101: val_accuracy did not improve from 0.87814\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8332 - loss: 0.4168 - val_accuracy: 0.8674 - val_loss: 0.3849 - learning_rate: 1.0000e-04\nEpoch 102/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8683 - loss: 0.3312\nEpoch 102: val_accuracy did not improve from 0.87814\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8683 - loss: 0.3312 - val_accuracy: 0.8746 - val_loss: 0.3852 - learning_rate: 1.0000e-04\nEpoch 103/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8871 - loss: 0.3021\nEpoch 103: val_accuracy did not improve from 0.87814\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8869 - loss: 0.3024 - val_accuracy: 0.8781 - val_loss: 0.3762 - learning_rate: 1.0000e-04\nEpoch 104/300\n\u001b[1m87/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8575 - loss: 0.3751\nEpoch 104: val_accuracy improved from 0.87814 to 0.88889, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8577 - loss: 0.3706 - val_accuracy: 0.8889 - val_loss: 0.3738 - learning_rate: 1.0000e-04\nEpoch 105/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8658 - loss: 0.3424\nEpoch 105: val_accuracy did not improve from 0.88889\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8658 - loss: 0.3424 - val_accuracy: 0.8674 - val_loss: 0.3806 - learning_rate: 1.0000e-04\nEpoch 106/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8688 - loss: 0.3358\nEpoch 106: val_accuracy did not improve from 0.88889\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8691 - loss: 0.3371 - val_accuracy: 0.8781 - val_loss: 0.3678 - learning_rate: 1.0000e-04\nEpoch 107/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8734 - loss: 0.3397\nEpoch 107: val_accuracy did not improve from 0.88889\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8736 - loss: 0.3390 - val_accuracy: 0.8781 - val_loss: 0.3710 - learning_rate: 1.0000e-04\nEpoch 108/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8472 - loss: 0.3591\nEpoch 108: val_accuracy did not improve from 0.88889\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8473 - loss: 0.3590 - val_accuracy: 0.8638 - val_loss: 0.3875 - learning_rate: 1.0000e-04\nEpoch 109/300\n\u001b[1m89/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8804 - loss: 0.2971\nEpoch 109: val_accuracy did not improve from 0.88889\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8798 - loss: 0.2989 - val_accuracy: 0.8746 - val_loss: 0.3808 - learning_rate: 1.0000e-04\nEpoch 110/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8722 - loss: 0.3146\nEpoch 110: val_accuracy did not improve from 0.88889\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8722 - loss: 0.3147 - val_accuracy: 0.8853 - val_loss: 0.3667 - learning_rate: 1.0000e-04\nEpoch 111/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8786 - loss: 0.3146\nEpoch 111: val_accuracy did not improve from 0.88889\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8784 - loss: 0.3150 - val_accuracy: 0.8781 - val_loss: 0.3809 - learning_rate: 1.0000e-04\nEpoch 112/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8863 - loss: 0.2954\nEpoch 112: val_accuracy did not improve from 0.88889\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8849 - loss: 0.2983 - val_accuracy: 0.8781 - val_loss: 0.3814 - learning_rate: 1.0000e-04\nEpoch 113/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8815 - loss: 0.2899\nEpoch 113: val_accuracy did not improve from 0.88889\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8817 - loss: 0.2898 - val_accuracy: 0.8710 - val_loss: 0.3815 - learning_rate: 1.0000e-04\nEpoch 114/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8620 - loss: 0.3340\nEpoch 114: val_accuracy did not improve from 0.88889\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8619 - loss: 0.3339 - val_accuracy: 0.8746 - val_loss: 0.3774 - learning_rate: 1.0000e-04\nEpoch 115/300\n\u001b[1m94/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8739 - loss: 0.3454\nEpoch 115: val_accuracy did not improve from 0.88889\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8741 - loss: 0.3445 - val_accuracy: 0.8853 - val_loss: 0.3681 - learning_rate: 1.0000e-04\nEpoch 116/300\n\u001b[1m95/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8647 - loss: 0.3411\nEpoch 116: val_accuracy did not improve from 0.88889\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8650 - loss: 0.3405 - val_accuracy: 0.8889 - val_loss: 0.3644 - learning_rate: 1.0000e-04\nEpoch 117/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8703 - loss: 0.3370\nEpoch 117: val_accuracy did not improve from 0.88889\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8703 - loss: 0.3371 - val_accuracy: 0.8853 - val_loss: 0.3635 - learning_rate: 1.0000e-04\nEpoch 118/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8985 - loss: 0.2714\nEpoch 118: val_accuracy improved from 0.88889 to 0.89247, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8973 - loss: 0.2724 - val_accuracy: 0.8925 - val_loss: 0.3625 - learning_rate: 1.0000e-04\nEpoch 119/300\n\u001b[1m89/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8741 - loss: 0.3177\nEpoch 119: val_accuracy did not improve from 0.89247\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8741 - loss: 0.3169 - val_accuracy: 0.8925 - val_loss: 0.3655 - learning_rate: 1.0000e-04\nEpoch 120/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8756 - loss: 0.3156\nEpoch 120: val_accuracy did not improve from 0.89247\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8758 - loss: 0.3152 - val_accuracy: 0.8889 - val_loss: 0.3550 - learning_rate: 1.0000e-04\nEpoch 121/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8829 - loss: 0.3168\nEpoch 121: val_accuracy did not improve from 0.89247\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8829 - loss: 0.3166 - val_accuracy: 0.8746 - val_loss: 0.3725 - learning_rate: 1.0000e-04\nEpoch 122/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8819 - loss: 0.3008\nEpoch 122: val_accuracy did not improve from 0.89247\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8819 - loss: 0.3007 - val_accuracy: 0.8853 - val_loss: 0.3638 - learning_rate: 1.0000e-04\nEpoch 123/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8597 - loss: 0.3719\nEpoch 123: val_accuracy did not improve from 0.89247\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8600 - loss: 0.3705 - val_accuracy: 0.8925 - val_loss: 0.3629 - learning_rate: 1.0000e-04\nEpoch 124/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8897 - loss: 0.2815\nEpoch 124: val_accuracy did not improve from 0.89247\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8896 - loss: 0.2818 - val_accuracy: 0.8925 - val_loss: 0.3808 - learning_rate: 1.0000e-04\nEpoch 125/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8797 - loss: 0.2862\nEpoch 125: val_accuracy did not improve from 0.89247\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8797 - loss: 0.2863 - val_accuracy: 0.8853 - val_loss: 0.3792 - learning_rate: 1.0000e-04\nEpoch 126/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8730 - loss: 0.2978\nEpoch 126: val_accuracy did not improve from 0.89247\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8730 - loss: 0.2976 - val_accuracy: 0.8853 - val_loss: 0.3838 - learning_rate: 1.0000e-04\nEpoch 127/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8783 - loss: 0.2844\nEpoch 127: val_accuracy did not improve from 0.89247\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8781 - loss: 0.2848 - val_accuracy: 0.8925 - val_loss: 0.3707 - learning_rate: 1.0000e-04\nEpoch 128/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8835 - loss: 0.2960\nEpoch 128: val_accuracy did not improve from 0.89247\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8834 - loss: 0.2960 - val_accuracy: 0.8853 - val_loss: 0.3706 - learning_rate: 1.0000e-04\nEpoch 129/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8802 - loss: 0.3096\nEpoch 129: val_accuracy did not improve from 0.89247\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8803 - loss: 0.3093 - val_accuracy: 0.8925 - val_loss: 0.3642 - learning_rate: 1.0000e-04\nEpoch 130/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9037 - loss: 0.2433\nEpoch 130: val_accuracy did not improve from 0.89247\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9038 - loss: 0.2433 - val_accuracy: 0.8889 - val_loss: 0.3738 - learning_rate: 1.0000e-04\nEpoch 131/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8921 - loss: 0.2553\nEpoch 131: val_accuracy improved from 0.89247 to 0.89964, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8923 - loss: 0.2557 - val_accuracy: 0.8996 - val_loss: 0.3647 - learning_rate: 1.0000e-04\nEpoch 132/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8911 - loss: 0.2776\nEpoch 132: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8909 - loss: 0.2776 - val_accuracy: 0.8996 - val_loss: 0.3558 - learning_rate: 1.0000e-04\nEpoch 133/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8905 - loss: 0.2848\nEpoch 133: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8901 - loss: 0.2854 - val_accuracy: 0.8925 - val_loss: 0.3704 - learning_rate: 1.0000e-04\nEpoch 134/300\n\u001b[1m90/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8946 - loss: 0.2695\nEpoch 134: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8949 - loss: 0.2688 - val_accuracy: 0.8889 - val_loss: 0.3680 - learning_rate: 1.0000e-04\nEpoch 135/300\n\u001b[1m87/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9040 - loss: 0.2788\nEpoch 135: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9029 - loss: 0.2773 - val_accuracy: 0.8889 - val_loss: 0.3744 - learning_rate: 1.0000e-04\nEpoch 136/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9171 - loss: 0.2274\nEpoch 136: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9168 - loss: 0.2279 - val_accuracy: 0.8889 - val_loss: 0.3749 - learning_rate: 1.0000e-04\nEpoch 137/300\n\u001b[1m89/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9005 - loss: 0.2336\nEpoch 137: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9008 - loss: 0.2336 - val_accuracy: 0.8889 - val_loss: 0.3656 - learning_rate: 1.0000e-04\nEpoch 138/300\n\u001b[1m94/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9045 - loss: 0.2360\nEpoch 138: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9040 - loss: 0.2376 - val_accuracy: 0.8817 - val_loss: 0.3746 - learning_rate: 1.0000e-04\nEpoch 139/300\n\u001b[1m89/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8928 - loss: 0.2759\nEpoch 139: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8939 - loss: 0.2732 - val_accuracy: 0.8925 - val_loss: 0.3571 - learning_rate: 1.0000e-04\nEpoch 140/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8906 - loss: 0.2827\nEpoch 140: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8906 - loss: 0.2827 - val_accuracy: 0.8853 - val_loss: 0.3609 - learning_rate: 1.0000e-04\nEpoch 141/300\n\u001b[1m89/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8910 - loss: 0.2604\nEpoch 141: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8917 - loss: 0.2602 - val_accuracy: 0.8817 - val_loss: 0.3687 - learning_rate: 1.0000e-04\nEpoch 142/300\n\u001b[1m89/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9171 - loss: 0.2157\nEpoch 142: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9159 - loss: 0.2189 - val_accuracy: 0.8996 - val_loss: 0.3566 - learning_rate: 1.0000e-04\nEpoch 143/300\n\u001b[1m91/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8690 - loss: 0.2896\nEpoch 143: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8702 - loss: 0.2881 - val_accuracy: 0.8853 - val_loss: 0.3651 - learning_rate: 1.0000e-04\nEpoch 144/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9137 - loss: 0.2328\nEpoch 144: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9137 - loss: 0.2329 - val_accuracy: 0.8889 - val_loss: 0.3669 - learning_rate: 1.0000e-04\nEpoch 145/300\n\u001b[1m90/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9002 - loss: 0.2460\nEpoch 145: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9002 - loss: 0.2468 - val_accuracy: 0.8961 - val_loss: 0.3643 - learning_rate: 1.0000e-04\nEpoch 146/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8799 - loss: 0.2669\nEpoch 146: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8823 - loss: 0.2655 - val_accuracy: 0.8996 - val_loss: 0.3606 - learning_rate: 1.0000e-04\nEpoch 147/300\n\u001b[1m90/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8948 - loss: 0.2510\nEpoch 147: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8961 - loss: 0.2501 - val_accuracy: 0.8781 - val_loss: 0.3611 - learning_rate: 1.0000e-04\nEpoch 148/300\n\u001b[1m87/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9034 - loss: 0.2545\nEpoch 148: val_accuracy did not improve from 0.89964\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9028 - loss: 0.2563 - val_accuracy: 0.8889 - val_loss: 0.3697 - learning_rate: 1.0000e-04\nEpoch 149/300\n\u001b[1m89/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9082 - loss: 0.2473\nEpoch 149: val_accuracy improved from 0.89964 to 0.90323, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9085 - loss: 0.2457 - val_accuracy: 0.9032 - val_loss: 0.3546 - learning_rate: 1.0000e-04\nEpoch 150/300\n\u001b[1m90/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9182 - loss: 0.2253\nEpoch 150: val_accuracy did not improve from 0.90323\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9164 - loss: 0.2290 - val_accuracy: 0.8853 - val_loss: 0.3750 - learning_rate: 1.0000e-04\nEpoch 151/300\n\u001b[1m95/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9109 - loss: 0.2528\nEpoch 151: val_accuracy did not improve from 0.90323\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9111 - loss: 0.2520 - val_accuracy: 0.8996 - val_loss: 0.3714 - learning_rate: 1.0000e-04\nEpoch 152/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8938 - loss: 0.2474\nEpoch 152: val_accuracy improved from 0.90323 to 0.90681, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8939 - loss: 0.2479 - val_accuracy: 0.9068 - val_loss: 0.3752 - learning_rate: 1.0000e-04\nEpoch 153/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8959 - loss: 0.2482\nEpoch 153: val_accuracy did not improve from 0.90681\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8963 - loss: 0.2476 - val_accuracy: 0.8853 - val_loss: 0.3706 - learning_rate: 1.0000e-04\nEpoch 154/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9101 - loss: 0.2288\nEpoch 154: val_accuracy did not improve from 0.90681\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9102 - loss: 0.2285 - val_accuracy: 0.8889 - val_loss: 0.3866 - learning_rate: 1.0000e-04\nEpoch 155/300\n\u001b[1m94/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9081 - loss: 0.2247\nEpoch 155: val_accuracy did not improve from 0.90681\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9080 - loss: 0.2250 - val_accuracy: 0.8925 - val_loss: 0.3774 - learning_rate: 1.0000e-04\nEpoch 156/300\n\u001b[1m95/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9111 - loss: 0.2369\nEpoch 156: val_accuracy did not improve from 0.90681\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9109 - loss: 0.2365 - val_accuracy: 0.8925 - val_loss: 0.3996 - learning_rate: 1.0000e-04\nEpoch 157/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8860 - loss: 0.2982\nEpoch 157: val_accuracy did not improve from 0.90681\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8868 - loss: 0.2932 - val_accuracy: 0.8961 - val_loss: 0.3906 - learning_rate: 1.0000e-04\nEpoch 158/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8997 - loss: 0.2426\nEpoch 158: val_accuracy did not improve from 0.90681\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8998 - loss: 0.2425 - val_accuracy: 0.8889 - val_loss: 0.3856 - learning_rate: 1.0000e-04\nEpoch 159/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9118 - loss: 0.2247\nEpoch 159: val_accuracy did not improve from 0.90681\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9121 - loss: 0.2235 - val_accuracy: 0.8961 - val_loss: 0.3856 - learning_rate: 1.0000e-04\nEpoch 160/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8933 - loss: 0.2575\nEpoch 160: val_accuracy did not improve from 0.90681\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8935 - loss: 0.2568 - val_accuracy: 0.9068 - val_loss: 0.3764 - learning_rate: 1.0000e-04\nEpoch 161/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9110 - loss: 0.2185\nEpoch 161: val_accuracy did not improve from 0.90681\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9108 - loss: 0.2191 - val_accuracy: 0.8925 - val_loss: 0.3778 - learning_rate: 1.0000e-04\nEpoch 162/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9208 - loss: 0.2212\nEpoch 162: val_accuracy did not improve from 0.90681\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9206 - loss: 0.2214 - val_accuracy: 0.9068 - val_loss: 0.3775 - learning_rate: 1.0000e-04\nEpoch 163/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9102 - loss: 0.2385\nEpoch 163: val_accuracy did not improve from 0.90681\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9103 - loss: 0.2382 - val_accuracy: 0.8961 - val_loss: 0.3684 - learning_rate: 1.0000e-04\nEpoch 164/300\n\u001b[1m95/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9064 - loss: 0.2360\nEpoch 164: val_accuracy did not improve from 0.90681\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9064 - loss: 0.2362 - val_accuracy: 0.9068 - val_loss: 0.3574 - learning_rate: 1.0000e-04\nEpoch 165/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9138 - loss: 0.2117\nEpoch 165: val_accuracy improved from 0.90681 to 0.91398, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9138 - loss: 0.2117 - val_accuracy: 0.9140 - val_loss: 0.3534 - learning_rate: 1.0000e-04\nEpoch 166/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9261 - loss: 0.1953\nEpoch 166: val_accuracy did not improve from 0.91398\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9260 - loss: 0.1955 - val_accuracy: 0.9068 - val_loss: 0.3486 - learning_rate: 1.0000e-04\nEpoch 167/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9162 - loss: 0.2041\nEpoch 167: val_accuracy did not improve from 0.91398\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9162 - loss: 0.2041 - val_accuracy: 0.9104 - val_loss: 0.3532 - learning_rate: 1.0000e-04\nEpoch 168/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9280 - loss: 0.1920\nEpoch 168: val_accuracy did not improve from 0.91398\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9278 - loss: 0.1925 - val_accuracy: 0.8996 - val_loss: 0.3524 - learning_rate: 1.0000e-04\nEpoch 169/300\n\u001b[1m93/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9206 - loss: 0.2020\nEpoch 169: val_accuracy did not improve from 0.91398\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9210 - loss: 0.2014 - val_accuracy: 0.8996 - val_loss: 0.3656 - learning_rate: 1.0000e-04\nEpoch 170/300\n\u001b[1m95/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9091 - loss: 0.2330\nEpoch 170: val_accuracy improved from 0.91398 to 0.92473, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9092 - loss: 0.2330 - val_accuracy: 0.9247 - val_loss: 0.3414 - learning_rate: 1.0000e-04\nEpoch 171/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9096 - loss: 0.2145\nEpoch 171: val_accuracy did not improve from 0.92473\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9095 - loss: 0.2146 - val_accuracy: 0.9068 - val_loss: 0.3527 - learning_rate: 1.0000e-04\nEpoch 172/300\n\u001b[1m87/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9201 - loss: 0.1948\nEpoch 172: val_accuracy did not improve from 0.92473\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9195 - loss: 0.1977 - val_accuracy: 0.9068 - val_loss: 0.3562 - learning_rate: 1.0000e-04\nEpoch 173/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9203 - loss: 0.1946\nEpoch 173: val_accuracy did not improve from 0.92473\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9200 - loss: 0.1952 - val_accuracy: 0.8925 - val_loss: 0.3765 - learning_rate: 1.0000e-04\nEpoch 174/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9396 - loss: 0.1755\nEpoch 174: val_accuracy did not improve from 0.92473\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9378 - loss: 0.1791 - val_accuracy: 0.9032 - val_loss: 0.3560 - learning_rate: 1.0000e-04\nEpoch 175/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9188 - loss: 0.1988\nEpoch 175: val_accuracy did not improve from 0.92473\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9190 - loss: 0.1977 - val_accuracy: 0.9068 - val_loss: 0.3548 - learning_rate: 1.0000e-04\nEpoch 176/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9248 - loss: 0.1853\nEpoch 176: val_accuracy did not improve from 0.92473\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9240 - loss: 0.1871 - val_accuracy: 0.9068 - val_loss: 0.3678 - learning_rate: 1.0000e-04\nEpoch 177/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9239 - loss: 0.1987\nEpoch 177: val_accuracy did not improve from 0.92473\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9239 - loss: 0.1987 - val_accuracy: 0.9140 - val_loss: 0.3714 - learning_rate: 1.0000e-04\nEpoch 178/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9330 - loss: 0.1976\nEpoch 178: val_accuracy did not improve from 0.92473\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9327 - loss: 0.1979 - val_accuracy: 0.8961 - val_loss: 0.3837 - learning_rate: 1.0000e-04\nEpoch 179/300\n\u001b[1m95/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9203 - loss: 0.1954\nEpoch 179: val_accuracy did not improve from 0.92473\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9200 - loss: 0.1956 - val_accuracy: 0.9032 - val_loss: 0.3860 - learning_rate: 1.0000e-04\nEpoch 180/300\n\u001b[1m94/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9434 - loss: 0.1712\nEpoch 180: val_accuracy did not improve from 0.92473\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9426 - loss: 0.1719 - val_accuracy: 0.9068 - val_loss: 0.3852 - learning_rate: 1.0000e-04\nEpoch 181/300\n\u001b[1m94/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9167 - loss: 0.2067\nEpoch 181: val_accuracy did not improve from 0.92473\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9166 - loss: 0.2072 - val_accuracy: 0.9068 - val_loss: 0.3950 - learning_rate: 1.0000e-04\nEpoch 182/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9270 - loss: 0.2123\nEpoch 182: val_accuracy did not improve from 0.92473\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9267 - loss: 0.2125 - val_accuracy: 0.8853 - val_loss: 0.3994 - learning_rate: 1.0000e-04\nEpoch 183/300\n\u001b[1m95/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9233 - loss: 0.1793\nEpoch 183: val_accuracy did not improve from 0.92473\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9235 - loss: 0.1799 - val_accuracy: 0.9068 - val_loss: 0.3910 - learning_rate: 1.0000e-04\nEpoch 184/300\n\u001b[1m94/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9170 - loss: 0.2010\nEpoch 184: val_accuracy did not improve from 0.92473\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9177 - loss: 0.1998 - val_accuracy: 0.9140 - val_loss: 0.3796 - learning_rate: 1.0000e-04\nEpoch 185/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9256 - loss: 0.1995\nEpoch 185: val_accuracy did not improve from 0.92473\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9253 - loss: 0.1996 - val_accuracy: 0.9140 - val_loss: 0.3799 - learning_rate: 1.0000e-04\nEpoch 186/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9345 - loss: 0.1792\nEpoch 186: val_accuracy did not improve from 0.92473\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9344 - loss: 0.1793 - val_accuracy: 0.9247 - val_loss: 0.3730 - learning_rate: 1.0000e-04\nEpoch 187/300\n\u001b[1m95/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9196 - loss: 0.1937\nEpoch 187: val_accuracy did not improve from 0.92473\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9196 - loss: 0.1940 - val_accuracy: 0.9211 - val_loss: 0.3684 - learning_rate: 1.0000e-04\nEpoch 188/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9237 - loss: 0.1884\nEpoch 188: val_accuracy improved from 0.92473 to 0.92832, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9239 - loss: 0.1879 - val_accuracy: 0.9283 - val_loss: 0.3723 - learning_rate: 1.0000e-04\nEpoch 189/300\n\u001b[1m92/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9363 - loss: 0.1532\nEpoch 189: val_accuracy did not improve from 0.92832\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9358 - loss: 0.1541 - val_accuracy: 0.9104 - val_loss: 0.3898 - learning_rate: 1.0000e-04\nEpoch 190/300\n\u001b[1m94/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9495 - loss: 0.1426\nEpoch 190: val_accuracy did not improve from 0.92832\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9490 - loss: 0.1430 - val_accuracy: 0.9211 - val_loss: 0.3928 - learning_rate: 1.0000e-04\nEpoch 191/300\n\u001b[1m95/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9289 - loss: 0.1940\nEpoch 191: val_accuracy did not improve from 0.92832\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9291 - loss: 0.1935 - val_accuracy: 0.9032 - val_loss: 0.3978 - learning_rate: 1.0000e-04\nEpoch 192/300\n\u001b[1m94/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9227 - loss: 0.1991\nEpoch 192: val_accuracy did not improve from 0.92832\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9224 - loss: 0.1995 - val_accuracy: 0.9211 - val_loss: 0.3914 - learning_rate: 1.0000e-04\nEpoch 193/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9261 - loss: 0.2219\nEpoch 193: val_accuracy did not improve from 0.92832\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9263 - loss: 0.2210 - val_accuracy: 0.9247 - val_loss: 0.3730 - learning_rate: 1.0000e-04\nEpoch 194/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9471 - loss: 0.1738\nEpoch 194: val_accuracy did not improve from 0.92832\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9470 - loss: 0.1739 - val_accuracy: 0.9283 - val_loss: 0.4005 - learning_rate: 1.0000e-04\nEpoch 195/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9038 - loss: 0.1876\nEpoch 195: val_accuracy did not improve from 0.92832\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9041 - loss: 0.1878 - val_accuracy: 0.9283 - val_loss: 0.3826 - learning_rate: 1.0000e-04\nEpoch 196/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9408 - loss: 0.1667\nEpoch 196: val_accuracy improved from 0.92832 to 0.93548, saving model to fixed_super_advanced_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9403 - loss: 0.1673 - val_accuracy: 0.9355 - val_loss: 0.3837 - learning_rate: 1.0000e-04\nEpoch 197/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9269 - loss: 0.1730\nEpoch 197: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9268 - loss: 0.1737 - val_accuracy: 0.9283 - val_loss: 0.3680 - learning_rate: 1.0000e-04\nEpoch 198/300\n\u001b[1m95/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9343 - loss: 0.1718\nEpoch 198: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9342 - loss: 0.1722 - val_accuracy: 0.9176 - val_loss: 0.3821 - learning_rate: 1.0000e-04\nEpoch 199/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9391 - loss: 0.1692\nEpoch 199: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9388 - loss: 0.1697 - val_accuracy: 0.9283 - val_loss: 0.3682 - learning_rate: 1.0000e-04\nEpoch 200/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9311 - loss: 0.1782\nEpoch 200: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9312 - loss: 0.1780 - val_accuracy: 0.9140 - val_loss: 0.3952 - learning_rate: 1.0000e-04\nEpoch 201/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9462 - loss: 0.1331\nEpoch 201: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9460 - loss: 0.1337 - val_accuracy: 0.9068 - val_loss: 0.3898 - learning_rate: 1.0000e-04\nEpoch 202/300\n\u001b[1m89/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9232 - loss: 0.1659\nEpoch 202: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9233 - loss: 0.1665 - val_accuracy: 0.9176 - val_loss: 0.3741 - learning_rate: 1.0000e-04\nEpoch 203/300\n\u001b[1m95/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9453 - loss: 0.1306\nEpoch 203: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9451 - loss: 0.1318 - val_accuracy: 0.9247 - val_loss: 0.3823 - learning_rate: 1.0000e-04\nEpoch 204/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9242 - loss: 0.1640\nEpoch 204: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9243 - loss: 0.1639 - val_accuracy: 0.9355 - val_loss: 0.3748 - learning_rate: 1.0000e-04\nEpoch 205/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9262 - loss: 0.1981\nEpoch 205: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9271 - loss: 0.1946 - val_accuracy: 0.9283 - val_loss: 0.3943 - learning_rate: 1.0000e-04\nEpoch 206/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9358 - loss: 0.1863\nEpoch 206: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9362 - loss: 0.1842 - val_accuracy: 0.9068 - val_loss: 0.4035 - learning_rate: 1.0000e-04\nEpoch 207/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9438 - loss: 0.1507\nEpoch 207: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9437 - loss: 0.1508 - val_accuracy: 0.9319 - val_loss: 0.3994 - learning_rate: 1.0000e-04\nEpoch 208/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9299 - loss: 0.1933\nEpoch 208: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9305 - loss: 0.1911 - val_accuracy: 0.9247 - val_loss: 0.3997 - learning_rate: 1.0000e-04\nEpoch 209/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9380 - loss: 0.1489\nEpoch 209: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9378 - loss: 0.1495 - val_accuracy: 0.9104 - val_loss: 0.4080 - learning_rate: 1.0000e-04\nEpoch 210/300\n\u001b[1m88/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9398 - loss: 0.1707\nEpoch 210: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9405 - loss: 0.1684 - val_accuracy: 0.9211 - val_loss: 0.4036 - learning_rate: 1.0000e-04\nEpoch 211/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9352 - loss: 0.1560\nEpoch 211: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9352 - loss: 0.1561 - val_accuracy: 0.9104 - val_loss: 0.4085 - learning_rate: 1.0000e-04\nEpoch 212/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9257 - loss: 0.1817\nEpoch 212: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9258 - loss: 0.1815 - val_accuracy: 0.9211 - val_loss: 0.4068 - learning_rate: 1.0000e-04\nEpoch 213/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9424 - loss: 0.1631\nEpoch 213: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9424 - loss: 0.1628 - val_accuracy: 0.9247 - val_loss: 0.3913 - learning_rate: 1.0000e-04\nEpoch 214/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9394 - loss: 0.1646\nEpoch 214: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9393 - loss: 0.1648 - val_accuracy: 0.9211 - val_loss: 0.4043 - learning_rate: 1.0000e-04\nEpoch 215/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9393 - loss: 0.1470\nEpoch 215: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9393 - loss: 0.1471 - val_accuracy: 0.9211 - val_loss: 0.4062 - learning_rate: 1.0000e-04\nEpoch 216/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9378 - loss: 0.1764\nEpoch 216: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\nEpoch 216: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9379 - loss: 0.1761 - val_accuracy: 0.9104 - val_loss: 0.4162 - learning_rate: 1.0000e-04\nEpoch 217/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9421 - loss: 0.1449\nEpoch 217: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9421 - loss: 0.1451 - val_accuracy: 0.9140 - val_loss: 0.4227 - learning_rate: 5.0000e-05\nEpoch 218/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9401 - loss: 0.1518\nEpoch 218: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9403 - loss: 0.1519 - val_accuracy: 0.9247 - val_loss: 0.4051 - learning_rate: 5.0000e-05\nEpoch 219/300\n\u001b[1m95/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9318 - loss: 0.1737\nEpoch 219: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9323 - loss: 0.1726 - val_accuracy: 0.9176 - val_loss: 0.4103 - learning_rate: 5.0000e-05\nEpoch 220/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9372 - loss: 0.1626\nEpoch 220: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9374 - loss: 0.1624 - val_accuracy: 0.9211 - val_loss: 0.4116 - learning_rate: 5.0000e-05\nEpoch 221/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9393 - loss: 0.1572\nEpoch 221: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9394 - loss: 0.1568 - val_accuracy: 0.9247 - val_loss: 0.4192 - learning_rate: 5.0000e-05\nEpoch 222/300\n\u001b[1m97/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9542 - loss: 0.1213\nEpoch 222: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9542 - loss: 0.1211 - val_accuracy: 0.9176 - val_loss: 0.4180 - learning_rate: 5.0000e-05\nEpoch 223/300\n\u001b[1m94/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9527 - loss: 0.1156\nEpoch 223: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9525 - loss: 0.1164 - val_accuracy: 0.9247 - val_loss: 0.4294 - learning_rate: 5.0000e-05\nEpoch 224/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9372 - loss: 0.1588\nEpoch 224: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9371 - loss: 0.1589 - val_accuracy: 0.9176 - val_loss: 0.4141 - learning_rate: 5.0000e-05\nEpoch 225/300\n\u001b[1m95/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9405 - loss: 0.1628\nEpoch 225: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9406 - loss: 0.1626 - val_accuracy: 0.9176 - val_loss: 0.4072 - learning_rate: 5.0000e-05\nEpoch 226/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9368 - loss: 0.1574\nEpoch 226: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9370 - loss: 0.1569 - val_accuracy: 0.9211 - val_loss: 0.4116 - learning_rate: 5.0000e-05\nEpoch 227/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9554 - loss: 0.1169\nEpoch 227: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9554 - loss: 0.1170 - val_accuracy: 0.9140 - val_loss: 0.4080 - learning_rate: 5.0000e-05\nEpoch 228/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9363 - loss: 0.1477\nEpoch 228: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9363 - loss: 0.1477 - val_accuracy: 0.9140 - val_loss: 0.4010 - learning_rate: 5.0000e-05\nEpoch 229/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9498 - loss: 0.1257\nEpoch 229: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9498 - loss: 0.1259 - val_accuracy: 0.9176 - val_loss: 0.3986 - learning_rate: 5.0000e-05\nEpoch 230/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9535 - loss: 0.1209\nEpoch 230: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9534 - loss: 0.1212 - val_accuracy: 0.9211 - val_loss: 0.3949 - learning_rate: 5.0000e-05\nEpoch 231/300\n\u001b[1m96/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9312 - loss: 0.1739\nEpoch 231: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9316 - loss: 0.1728 - val_accuracy: 0.9211 - val_loss: 0.4011 - learning_rate: 5.0000e-05\nEpoch 232/300\n\u001b[1m87/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9508 - loss: 0.1258\nEpoch 232: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9506 - loss: 0.1266 - val_accuracy: 0.9283 - val_loss: 0.3926 - learning_rate: 5.0000e-05\nEpoch 233/300\n\u001b[1m90/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9558 - loss: 0.1239\nEpoch 233: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9546 - loss: 0.1260 - val_accuracy: 0.9319 - val_loss: 0.3953 - learning_rate: 5.0000e-05\nEpoch 234/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9450 - loss: 0.1368\nEpoch 234: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9451 - loss: 0.1364 - val_accuracy: 0.9247 - val_loss: 0.3930 - learning_rate: 5.0000e-05\nEpoch 235/300\n\u001b[1m98/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9553 - loss: 0.1220\nEpoch 235: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9552 - loss: 0.1220 - val_accuracy: 0.9247 - val_loss: 0.4028 - learning_rate: 5.0000e-05\nEpoch 236/300\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9585 - loss: 0.1091\nEpoch 236: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\nEpoch 236: val_accuracy did not improve from 0.93548\n\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9585 - loss: 0.1093 - val_accuracy: 0.9283 - val_loss: 0.3993 - learning_rate: 5.0000e-05\nEpoch 236: early stopping\nRestoring model weights from the end of the best epoch: 196.\nâœ… Fixed super advanced training completed!\n\nğŸ¯ FIXED SUPER ADVANCED MODEL ACCURACY: 0.9355\nğŸ‰ ğŸ‰ ğŸ‰ UNBELIEVABLE! 90%+ ACHIEVED! ğŸ‰ ğŸ‰ ğŸ‰\nğŸš€ BREAKTHROUGH! +0.0575 improvement!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ======================================\n# 3ï¸âƒ£7ï¸âƒ£ MODEL EVALUATION & METRICS\n# ======================================\n\n\nprint(\"ğŸ“Š Evaluating Super Advanced Model...\")\n\n# --- 1. Training history plots ---\nhistory = super_history.history\n\nplt.figure(figsize=(12,5))\n\n# Loss\nplt.subplot(1,2,1)\nplt.plot(history['loss'], label='Train Loss')\nplt.plot(history['val_loss'], label='Val Loss')\nplt.title('Loss over Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid(True)\n\n# Accuracy\nplt.subplot(1,2,2)\nplt.plot(history['accuracy'], label='Train Accuracy')\nplt.plot(history['val_accuracy'], label='Val Accuracy')\nplt.title('Accuracy over Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n\n# --- 2. Predictions on validation set ---\ny_val_pred_probs = super_model.predict([X_tab_aug_val, X_mel_aug_val_pca], verbose=0)\ny_val_pred = np.argmax(y_val_pred_probs, axis=1)\n\n# --- 3. Confusion Matrix ---\ncm = confusion_matrix(y_aug_val, y_val_pred)\nplt.figure(figsize=(8,6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\n# --- 4. Classification Report ---\nreport = classification_report(y_aug_val, y_val_pred, digits=4)\nprint(\"ğŸ“„ Classification Report:\\n\")\nprint(report)\n\n# --- 5. Overall accuracy ---\nfrom sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_aug_val, y_val_pred)\nprint(f\"\\nğŸ¯ Overall Validation Accuracy: {accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:26:38.853094Z","iopub.execute_input":"2025-12-01T21:26:38.853390Z","iopub.status.idle":"2025-12-01T21:26:39.564757Z","shell.execute_reply.started":"2025-12-01T21:26:38.853357Z","shell.execute_reply":"2025-12-01T21:26:39.564122Z"}},"outputs":[{"name":"stdout","text":"ğŸ“Š Evaluating Super Advanced Model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x500 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAokAAAIjCAYAAABvUIGpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/PklEQVR4nO3deZyNdf/H8feZYc6MMYvBbGUZS5aUPWmsmZIkoqLcGUpahmIkTXeyhIm7kH3JWkgqiqIYIbclKWXLlqKYscUww8HM+f3h59wdXzSjM85wvZ49zuPRXNd1rutzriZ9en+/1/fYnE6nUwAAAMBf+Hi7AAAAAOQ/NIkAAAAw0CQCAADAQJMIAAAAA00iAAAADDSJAAAAMNAkAgAAwECTCAAAAANNIgAAAAw0iQCuaOfOnbr33nsVEhIim82m+fPne/T8v/76q2w2m6ZNm+bR817PGjVqpEaNGnm7DAAWR5MIXAd2796tZ555RmXKlJG/v7+Cg4MVGxurd955R6dOncrTa8fHx2vTpk0aNGiQ3nvvPdWqVStPr3ctdezYUTabTcHBwZe8jzt37pTNZpPNZtNbb72V6/Pv379f/fr108aNGz1QLQBcWwW8XQCAK/v888/1yCOPyG63q0OHDqpSpYrOnDmjVatWqVevXtqyZYsmTpyYJ9c+deqU1qxZo3//+9/q2rVrnlyjVKlSOnXqlAoWLJgn5/87BQoUUGZmphYsWKBHH33Ubd/MmTPl7++v06dPX9W59+/fr/79+6t06dKqVq1ajt/31VdfXdX1AMCTaBKBfGzPnj1q166dSpUqpWXLlikqKsq1LyEhQbt27dLnn3+eZ9c/dOiQJCk0NDTPrmGz2eTv759n5/87drtdsbGxmj17ttEkzpo1S82bN9fHH398TWrJzMxUoUKF5Ofnd02uBwBXwnAzkI8NHTpUJ0+e1OTJk90axAvKlSunF1980fXzuXPn9MYbb6hs2bKy2+0qXbq0Xn31VTkcDrf3lS5dWg888IBWrVqlO+64Q/7+/ipTpoxmzJjhOqZfv34qVaqUJKlXr16y2WwqXbq0pPPDtBf+/q/69esnm83mtm3JkiWqV6+eQkNDVbhwYVWoUEGvvvqqa//l5iQuW7ZM9evXV2BgoEJDQ9WyZUtt27btktfbtWuXOnbsqNDQUIWEhKhTp07KzMy8/I29yOOPP65Fixbp2LFjrm3r16/Xzp079fjjjxvHHz16VC+99JJuu+02FS5cWMHBwWrWrJl+/PFH1zHLly9X7dq1JUmdOnVyDVtf+JyNGjVSlSpVtGHDBjVo0ECFChVy3ZeL5yTGx8fL39/f+PxNmzZVkSJFtH///hx/VgDIKZpEIB9bsGCBypQpo7vuuitHx3fu3Fmvv/66atSooeHDh6thw4ZKTk5Wu3btjGN37dqlhx9+WPfcc4/efvttFSlSRB07dtSWLVskSa1bt9bw4cMlSY899pjee+89jRgxIlf1b9myRQ888IAcDocGDBigt99+Ww8++KD++9//XvF9S5cuVdOmTXXw4EH169dPiYmJWr16tWJjY/Xrr78axz/66KM6ceKEkpOT9eijj2ratGnq379/juts3bq1bDabPvnkE9e2WbNmqWLFiqpRo4Zx/C+//KL58+frgQce0LBhw9SrVy9t2rRJDRs2dDVslSpV0oABAyRJXbp00Xvvvaf33ntPDRo0cJ3nyJEjatasmapVq6YRI0aocePGl6zvnXfeUfHixRUfH6+srCxJ0oQJE/TVV19p1KhRio6OzvFnBYAccwLIl44fP+6U5GzZsmWOjt+4caNTkrNz585u21966SWnJOeyZctc20qVKuWU5Fy5cqVr28GDB512u93Zs2dP17Y9e/Y4JTn/85//uJ0zPj7eWapUKaOGvn37Ov/6x8rw4cOdkpyHDh26bN0XrjF16lTXtmrVqjnDw8OdR44ccW378ccfnT4+Ps4OHToY13vyySfdzvnQQw85ixYtetlr/vVzBAYGOp1Op/Phhx92NmnSxOl0Op1ZWVnOyMhIZ//+/S95D06fPu3MysoyPofdbncOGDDAtW39+vXGZ7ugYcOGTknO8ePHX3Jfw4YN3bZ9+eWXTknOgQMHOn/55Rdn4cKFna1atfrbzwgAV4skEcin0tPTJUlBQUE5Ov6LL76QJCUmJrpt79mzpyQZcxcrV66s+vXru34uXry4KlSooF9++eWqa77YhbmMn376qbKzs3P0ngMHDmjjxo3q2LGjwsLCXNtvv/123XPPPa7P+VfPPvus28/169fXkSNHXPcwJx5//HEtX75cqampWrZsmVJTUy851Cydn8fo43P+j8+srCwdOXLENZT+/fff5/iadrtdnTp1ytGx9957r5555hkNGDBArVu3lr+/vyZMmJDjawFAbtEkAvlUcHCwJOnEiRM5Ov63336Tj4+PypUr57Y9MjJSoaGh+u2339y2lyxZ0jhHkSJF9Oeff15lxaa2bdsqNjZWnTt3VkREhNq1a6cPP/zwig3jhTorVKhg7KtUqZIOHz6sjIwMt+0Xf5YiRYpIUq4+y/3336+goCDNmTNHM2fOVO3atY17eUF2draGDx+u8uXLy263q1ixYipevLh++uknHT9+PMfXvOmmm3L1kMpbb72lsLAwbdy4USNHjlR4eHiO3wsAuUWTCORTwcHBio6O1ubNm3P1vosfHLkcX1/fS253Op1XfY0L8+UuCAgI0MqVK7V06VI98cQT+umnn9S2bVvdc889xrH/xD/5LBfY7Xa1bt1a06dP17x58y6bIkrS4MGDlZiYqAYNGuj999/Xl19+qSVLlujWW2/NcWIqnb8/ufHDDz/o4MGDkqRNmzbl6r0AkFs0iUA+9sADD2j37t1as2bN3x5bqlQpZWdna+fOnW7b09LSdOzYMdeTyp5QpEgRtyeBL7g4rZQkHx8fNWnSRMOGDdPWrVs1aNAgLVu2TF9//fUlz32hzu3btxv7fv75ZxUrVkyBgYH/7ANcxuOPP64ffvhBJ06cuOTDPhd89NFHaty4sSZPnqx27drp3nvvVVxcnHFPctqw50RGRoY6deqkypUrq0uXLho6dKjWr1/vsfMDwMVoEoF87OWXX1ZgYKA6d+6stLQ0Y//u3bv1zjvvSDo/XCrJeAJ52LBhkqTmzZt7rK6yZcvq+PHj+umnn1zbDhw4oHnz5rkdd/ToUeO9FxaVvnhZnguioqJUrVo1TZ8+3a3p2rx5s7766ivX58wLjRs31htvvKHRo0crMjLyssf5+voaKeXcuXP1xx9/uG270MxeqqHOrd69e2vv3r2aPn26hg0bptKlSys+Pv6y9xEA/ikW0wbysbJly2rWrFlq27atKlWq5PaNK6tXr9bcuXPVsWNHSVLVqlUVHx+viRMn6tixY2rYsKG+/fZbTZ8+Xa1atbrs8ipXo127durdu7ceeughvfDCC8rMzNS4ceN0yy23uD24MWDAAK1cuVLNmzdXqVKldPDgQY0dO1Y333yz6tWrd9nz/+c//1GzZs1Ut25dPfXUUzp16pRGjRqlkJAQ9evXz2Of42I+Pj567bXX/va4Bx54QAMGDFCnTp101113adOmTZo5c6bKlCnjdlzZsmUVGhqq8ePHKygoSIGBgapTp45iYmJyVdeyZcs0duxY9e3b17Ukz9SpU9WoUSP16dNHQ4cOzdX5ACBHvPx0NYAc2LFjh/Ppp592li5d2unn5+cMCgpyxsbGOkeNGuU8ffq067izZ886+/fv74yJiXEWLFjQWaJECWdSUpLbMU7n+SVwmjdvblzn4qVXLrcEjtPpdH711VfOKlWqOP38/JwVKlRwvv/++8YSOCkpKc6WLVs6o6OjnX5+fs7o6GjnY4895tyxY4dxjYuXiVm6dKkzNjbWGRAQ4AwODna2aNHCuXXrVrdjLlzv4iV2pk6d6pTk3LNnz2XvqdPpvgTO5VxuCZyePXs6o6KinAEBAc7Y2FjnmjVrLrl0zaeffuqsXLmys0CBAm6fs2HDhs5bb731ktf863nS09OdpUqVctaoUcN59uxZt+N69Ojh9PHxca5Zs+aKnwEArobN6czFzG4AAABYAnMSAQAAYKBJBAAAgIEmEQAAAAaaRAAAABhoEgEAAGCgSQQAAICBJhEAAACGG/IbV5qOXeftEgDDp13qeLsEwE02y+QinylU0HPfd55bAdW75tm5T/0wOs/OnZdIEgEAAGC4IZNEAACAXLGRm12MJhEAAMDmvaHu/Iq2GQAAAAaSRAAAAIabDdwRAAAAGEgSAQAAmJNoIEkEAACAgSQRAACAOYkG7ggAAAAMJIkAAADMSTTQJAIAADDcbOCOAAAAwECSCAAAwHCzgSQRAAAABpJEAAAA5iQauCMAAAAwkCQCAAAwJ9FAkggAAAADSSIAAABzEg00iQAAAAw3G2ibAQAAYCBJBAAAYLjZwB0BAACAgSQRAACAJNHAHQEAAICBJBEAAMCHp5svRpIIAAAAA0kiAAAAcxINNIkAAAAspm2gbQYAAICBJBEAAIDhZgN3BAAAAAaSRAAAAOYkGkgSAQAAYCBJBAAAYE6igTsCAAAAA0kiAAAAcxINNIkAAAAMNxu4IwAAADCQJAIAADDcbCBJBAAAgIEkEQAAgDmJBu4IAAAADCSJAAAAzEk0kCQCAADkIytXrlSLFi0UHR0tm82m+fPnu+13Op16/fXXFRUVpYCAAMXFxWnnzp1uxxw9elTt27dXcHCwQkND9dRTT+nkyZO5qoMmEQAAwOaTd69cysjIUNWqVTVmzJhL7h86dKhGjhyp8ePHa926dQoMDFTTpk11+vRp1zHt27fXli1btGTJEi1cuFArV65Uly5dclUHw80AAAD56MGVZs2aqVmzZpfc53Q6NWLECL322mtq2bKlJGnGjBmKiIjQ/Pnz1a5dO23btk2LFy/W+vXrVatWLUnSqFGjdP/99+utt95SdHR0jurIP3cEAADgBuRwOJSenu72cjgcV3WuPXv2KDU1VXFxca5tISEhqlOnjtasWSNJWrNmjUJDQ10NoiTFxcXJx8dH69aty/G1aBIBAABstjx7JScnKyQkxO2VnJx8VWWmpqZKkiIiIty2R0REuPalpqYqPDzcbX+BAgUUFhbmOiYnGG4GAADIQ0lJSUpMTHTbZrfbvVRNztEkAgAA5OGcRLvd7rGmMDIyUpKUlpamqKgo1/a0tDRVq1bNdczBgwfd3nfu3DkdPXrU9f6cYLgZAADgOhETE6PIyEilpKS4tqWnp2vdunWqW7euJKlu3bo6duyYNmzY4Dpm2bJlys7OVp06dXJ8LZJEAACAfLSY9smTJ7Vr1y7Xz3v27NHGjRsVFhamkiVLqnv37ho4cKDKly+vmJgY9enTR9HR0WrVqpUkqVKlSrrvvvv09NNPa/z48Tp79qy6du2qdu3a5fjJZokmEQAAIF/57rvv1LhxY9fPF+YzxsfHa9q0aXr55ZeVkZGhLl266NixY6pXr54WL14sf39/13tmzpyprl27qkmTJvLx8VGbNm00cuTIXNVhczqdTs98pPyj6dicP94NXCufdsl5xA9cC9k33h//uM4VKui9NC/goXfz7Nyn5nXOs3PnJZJEAACAfDTcnF/w4AoAAAAMJIkAAMDybCSJBpJEAAAAGEgSAQCA5ZEkmkgSAQAAYCBJBAAAIEg0kCQCAADAQJIIAAAsjzmJJppEAABgeTSJJoabAQAAYCBJBAAAlkeSaCJJBAAAgIEkEQAAWB5JookmESoaWFBP1S2p2iVDZC/gq/3HT+vtZb9o56EMSVJoQAE9VbekapYIUaCfrzYfOKEx3/yq/ccdXq4cVrHhu/WaNmWytm3drEOHDmn4yDG6u0mct8uChU2eNEHLli7Rr3t+kd3fX1WrVdeLPXqqdEwZb5cGeAzDzRZX2O6rYQ/dqqwsp15buF1Pz/5JE1fv1UnHOdcxfZvdoqhgu/ot2qGEuZuVdsKhNx+sJHsBfn1wbZw6lakKFSoo6bW+3i4FkCR9/916tX3scc2YNUfjJk7RubPn9FyXzjqVment0nC1bHn4uk6RJFrco9WjdfikQ29//YtrW9qJ/yWEN4X4q3JkkLrM/km//XlKkjRqxa/6oGMNNS5fVIu3HbrmNcN66tVvqHr1G3q7DMBlzIR33X7uPyhZTRrcpa1bt6hmrdpeqgrwLJpEi7uzdBFt2HdM/763nG6PDtbhjDNauDlNi/6/+Svoe/5/gc5kZbve45R0Njtbt0YF0SQCgKSTJ09IkkJCQrxcCa4WcxJNXm0SDx8+rClTpmjNmjVKTU2VJEVGRuquu+5Sx44dVbx4cW+WZwlRwXY9cGuEPvnxgD74fr9uCQ/Uc/VL62y2U0u3H9a+Y6eVdsKhJ+8soXdW7NHps9lqXTVSxQvbFVaooLfLBwCvy87O1ltvDla16jVUrvwt3i4H8BivNYnr169X06ZNVahQIcXFxemWW87/i5WWlqaRI0fqzTff1JdffqlatWpd8TwOh0MOh/sDFNlnz8inoF+e1X4jsdmknYcyNHXd75Kk3YczVTqskJrfGq6l2w8rK9upAYt3KLFxGX38VC1lZTv1w+/H9e1vx67naRYA4DHJAwdo166dmjpjlrdLwT9AkmjyWpPYrVs3PfLIIxo/frzxD8bpdOrZZ59Vt27dtGbNmiueJzk5Wf3793fbVub+p1Su+dMer/lGdDTzrH47espt274/T6lemTDXz7sOZer5DzerkJ+vCvrYdPz0Ob3T5lbtOJhxrcsFgHzlzUED9M2K5Zo8/X1FREZ6uxz8AzSJJq89nvrjjz+qR48el/yHYrPZ1KNHD23cuPFvz5OUlKTjx4+7vcrcG58HFd+Yth44oRKh/m7bbgr118GT5vI2mWeydPz0OUWH2FW+eKDW/PrntSoTAPIVp9OpNwcN0LKUpZowZZpuuvlmb5cEeJzXksTIyEh9++23qlix4iX3f/vtt4qIiPjb89jtdtntdrdtDDXn3Cc/pWr4Q5XVrka0Vu46ogoRhXV/5XCNWL7HdUz9smE6fuqsDp48o5iwQnq2Ximt2fOnvt933IuVw0oyMzK0d+9e189//P67ft62TSEhIYqKjvZiZbCq5IEDtOiLhRo+cowCAwN1+PD5h/gKFw6Sv7//37wb+RFJoslrTeJLL72kLl26aMOGDWrSpImrIUxLS1NKSoomTZqkt956y1vlWcaOgxkasHinOt1ZQu1r3aTUEw6NX/Wbvt55xHVMWKGCeia2pEIDCupo5lkt3X5Ys777w4tVw2q2bNmszp06uH5+a2iyJOnBlg/pjcFveqssWNjcObMlSU//5fdSkvoPHKwHW7X2RkmAx9mcTqfTWxefM2eOhg8frg0bNigrK0uS5Ovrq5o1ayoxMVGPPvroVZ236dh1niwT8IhPu9TxdgmAm2zv/fEPXFKhgt5L84rGz86zcx+Z/lienTsveXUJnLZt26pt27Y6e/asDh8+LEkqVqyYChZkaRUAAABvyheLaRcsWFBRUVHeLgMAAFgUcxJNfPkuAAAADPkiSQQAAPAmkkQTTSIAALA8mkQTw80AAAAwkCQCAAAQJBpIEgEAAGAgSQQAAJbHnEQTSSIAAAAMJIkAAMDySBJNJIkAAAAwkCQCAADLI0k00SQCAADLo0k0MdwMAAAAA0kiAAAAQaKBJBEAAAAGkkQAAGB5zEk0kSQCAADAQJIIAAAsjyTRRJIIAAAAA0kiAACwPJJEE00iAAAAPaKB4WYAAAAYSBIBAIDlMdxsIkkEAACAgSQRAABYHkmiiSQRAAAABpJEAABgeSSJJpJEAAAAGEgSAQCA5ZEkmmgSAQAA6BENDDcDAADAQJIIAAAsj+FmE0kiAAAADCSJAADA8kgSTSSJAAAAMJAkAgAAyyNINJEkAgAAwECSCAAALI85iSaaRAAAYHn0iCaGmwEAAGAgSQQAAJbHcLOJJBEAAAAGkkQAAGB5BIkmkkQAAAAYSBIBAIDl+fgQJV6MJBEAACCfyMrKUp8+fRQTE6OAgACVLVtWb7zxhpxOp+sYp9Op119/XVFRUQoICFBcXJx27tzp8VpoEgEAgOXZbHn3yo0hQ4Zo3LhxGj16tLZt26YhQ4Zo6NChGjVqlOuYoUOHauTIkRo/frzWrVunwMBANW3aVKdPn/boPWG4GQAAWF5+WQJn9erVatmypZo3by5JKl26tGbPnq1vv/1W0vkUccSIEXrttdfUsmVLSdKMGTMUERGh+fPnq127dh6rhSQRAAAgDzkcDqWnp7u9HA7HJY+96667lJKSoh07dkiSfvzxR61atUrNmjWTJO3Zs0epqamKi4tzvSckJER16tTRmjVrPFo3TSIAALC8vBxuTk5OVkhIiNsrOTn5knW88sorateunSpWrKiCBQuqevXq6t69u9q3by9JSk1NlSRFRES4vS8iIsK1z1MYbgYAAMhDSUlJSkxMdNtmt9sveeyHH36omTNnatasWbr11lu1ceNGde/eXdHR0YqPj78W5brQJAIAAMvLyzmJdrv9sk3hxXr16uVKEyXptttu02+//abk5GTFx8crMjJSkpSWlqaoqCjX+9LS0lStWjWP1s1wMwAAQD6RmZkpHx/39szX11fZ2dmSpJiYGEVGRiolJcW1Pz09XevWrVPdunU9WgtJIgAAsLz88nRzixYtNGjQIJUsWVK33nqrfvjhBw0bNkxPPvmkpPN1du/eXQMHDlT58uUVExOjPn36KDo6Wq1atfJoLTSJAAAA+cSoUaPUp08fPf/88zp48KCio6P1zDPP6PXXX3cd8/LLLysjI0NdunTRsWPHVK9ePS1evFj+/v4ercXm/OsS3jeIpmPXebsEwPBplzreLgFwk33j/fGP61yhgt5L86r1S/n7g67Sxn5N8uzceYkkEQAAWF5+GW7OT3hwBQAAAAaSRAAAYHkEiSaSRAAAABhIEgEAgOUxJ9FEkggAAAADSSIAALA8gkQTSSIAAAAMJIkAAMDymJNoIkkEAACAgSQRAABYHkGiiSYRAABYHsPNJoabAQAAYCBJBAAAlkeQaLohm8SPnqrt7RIAQ5HaXb1dAuAmdfVIb5cAuCtIp5af3JBNIgAAQG4wJ9HEnEQAAAAYSBIBAIDlESSaSBIBAABgIEkEAACWx5xEE00iAACwPHpEE8PNAAAAMJAkAgAAy2O42USSCAAAAANJIgAAsDySRBNJIgAAAAwkiQAAwPIIEk0kiQAAADCQJAIAAMtjTqKJJhEAAFgePaKJ4WYAAAAYSBIBAIDlMdxsIkkEAACAgSQRAABYHkGiiSQRAAAABpJEAABgeT5EiQaSRAAAABhIEgEAgOURJJpoEgEAgOWxBI6J4WYAAAAYSBIBAIDl+RAkGkgSAQAAYCBJBAAAlsecRBNJIgAAAAwkiQAAwPIIEk0kiQAAADCQJAIAAMuziSjxYjSJAADA8lgCx8RwMwAAAAwkiQAAwPJYAsdEkggAAAADSSIAALA8gkQTSSIAAAAMJIkAAMDyfIgSDSSJAAAAMJAkAgAAyyNINNEkAgAAy2MJHBPDzQAAADCQJAIAAMsjSDSRJAIAAMBAkggAACyPJXBMJIkAAAAwkCQCAADLI0c0kSQCAADAQJIIAAAsj3USTTSJAADA8nzoEQ0MNwMAAMBAkggAACyP4WYTSSIAAAAMJIkAAMDyCBJNJIkAAAAwkCQCAADLY06iKUdN4meffZbjEz744INXXQwAAIDV/fHHH+rdu7cWLVqkzMxMlStXTlOnTlWtWrUkSU6nU3379tWkSZN07NgxxcbGaty4cSpfvrxH68hRk9iqVascncxmsykrK+uf1AMAAHDN5Zd1Ev/880/FxsaqcePGWrRokYoXL66dO3eqSJEirmOGDh2qkSNHavr06YqJiVGfPn3UtGlTbd26Vf7+/h6rJUdNYnZ2tscuCAAAkN/kl+HmIUOGqESJEpo6daprW0xMjOvvnU6nRowYoddee00tW7aUJM2YMUMRERGaP3++2rVr57FaeHAFAAAgDzkcDqWnp7u9HA7HJY/97LPPVKtWLT3yyCMKDw9X9erVNWnSJNf+PXv2KDU1VXFxca5tISEhqlOnjtasWePRuq/qwZWMjAytWLFCe/fu1ZkzZ9z2vfDCCx4pDAAA4FrJyxwxOTlZ/fv3d9vWt29f9evXzzj2l19+0bhx45SYmKhXX31V69ev1wsvvCA/Pz/Fx8crNTVVkhQREeH2voiICNc+T8l1k/jDDz/o/vvvV2ZmpjIyMhQWFqbDhw+rUKFCCg8Pp0kEAAD4i6SkJCUmJrpts9vtlzw2OztbtWrV0uDBgyVJ1atX1+bNmzV+/HjFx8fnea1/levh5h49eqhFixb6888/FRAQoLVr1+q3335TzZo19dZbb+VFjQAAAHnKx2bLs5fdbldwcLDb63JNYlRUlCpXruy2rVKlStq7d68kKTIyUpKUlpbmdkxaWpprn8fuSW7fsHHjRvXs2VM+Pj7y9fWVw+FQiRIlNHToUL366qseLQ4AAMBKYmNjtX37drdtO3bsUKlSpSSdf4glMjJSKSkprv3p6elat26d6tat69Fact0kFixYUD4+598WHh7u6mxDQkK0b98+jxYHAABwLdhseffKjR49emjt2rUaPHiwdu3apVmzZmnixIlKSEj4/zpt6t69uwYOHKjPPvtMmzZtUocOHRQdHZ3jJQtzKtdzEqtXr67169erfPnyatiwoV5//XUdPnxY7733nqpUqeLR4gAAAKykdu3amjdvnpKSkjRgwADFxMRoxIgRat++veuYl19+WRkZGerSpYuOHTumevXqafHixR5dI1GSbE6n05mbN3z33Xc6ceKEGjdurIMHD6pDhw5avXq1ypcvrylTpqhq1aoeLfBqnHCwriPyn/A7eagL+Uvq6pHeLgFwExLgvZX5uszdkmfnnvjIrXl27ryU6yTxwlfCSOeHmxcvXuzRggAAAOB9V7VOIgAAwI0kn3zhSr6S6yYxJibmil9d88svv/yjgpC/TJs8SaPfGabH2j+hnr15eh15I7ZGWfXoEKcalUsqqniIHu0xUQuW/+Ta3/Luqur8cD1Vr1RSRUMDVadtsn7a8Ydrf5HgQurzXHM1ubOiSkQW0eE/T2rB8p/Uf+xCpZ887Y2PhBvcxHGj9e6EMW7bSpWO0dz5X3ipIvxTPnSJhlw3id27d3f7+ezZs/rhhx+0ePFi9erVy1N1IR/YsnmTPpk7R+VvqeDtUnCDCwywa9OOPzTj0zWaM6yLsb9QgJ9Wb9ytj5d8r3Gvtzf2RxUPUVTxECUNn6dtv6SqZFSYRv27naKKh+jxXpOvxUeABZUpW06jJ0xx/VzAl8E53Fhy/Rv94osvXnL7mDFj9N133/3jgpA/ZGZmqE9SL/273wBNnjje2+XgBvfVf7fqq/9uvez+2Z+vlySVjAq75P6tuw/osZfedf285/fD6jd6gaYM6iBfXx9lZfEwGzzP17eAihUr7u0y4CEEiSaPPUbUrFkzffzxx546HbxsyKA3FFu/oerceZe3SwGuSnCQv9IzTtMgIs/s2/ub7r+ngVo1v0d9knop9cB+b5cEeJTHsvGPPvpIYWGX/r98XF++XPS5ft62VTNmz/V2KcBVKRoaqKSnm2nKx6u9XQpuUFVuu12vDxisUqVjdPjwIb07foy6PPkvzf5ogQIDA71dHq7ClZ63sKqrWkz7rzfS6XQqNTVVhw4d0tixYz1a3L59+9S3b19NmTLlssc4HA45HA63bWdU8LLfiYgrS009oLeHJGvMxMncQ1yXggL9NW/kc9r2ywENnPC5t8vBDequeg1cf1/+lgqqUuV2PXh/Ey39apFaPvSwFysDPCfXTWLLli3dmkQfHx8VL15cjRo1UsWKFT1a3NGjRzV9+vQrNonJycnq37+/27ZX/v26Xu3T16O1WMXPW7fo6NEj+lfbNq5tWVlZ+mHDd/rwg1la/d2P8vX19WKFwOUVLmTXZ2Oe14nM02qbOEnnzjHUjGsjKDhYJUuW1u/79nq7FFwl7y3jnX/lukns16+fxy7+2WefXXF/TpbTSUpKUmJiotu2Myr4j+qystp16uqDjz912zbg9X+rVEyM4jt1pkFEvhUU6K8FYxPkOHNOD3efIMeZc94uCRaSmZmhP37fp2LFHvR2KYDH5LpJ9PX11YEDBxQeHu62/ciRIwoPD1dWVlaOz9WqVSvZbDZd6ZsB/26OgN1uN4ZF+Vq+qxcYGKhy5W9x2+YfEKDQkFBjO+ApgQF+Klvif0+Jlr6pqG6/5Sb9mZ6pfal/qkhwIZWILKKo8BBJ0i2lIyRJaUfSlXbkhIIC/bVwbIIC/P3U6d/TFRzor+DA899heujPk8rOztW3jwJ/651hQ1W/QSNFRt2kw4cOauK4UfLx9dG99zX3dmm4SsxJNOW6SbxcQ+dwOOTn55erc0VFRWns2LFq2bLlJfdv3LhRNWvWzG2JAK4zNSqX0lfv/m95raEvnZ/u8N5na9Wl7/tq3vA2TRrwhGv/e0OelCQNHP+FBk34QtUqltAdt8dIkrYu6Od27gr3v669B47m8SeA1RxMS9VrSS/p+LFjKlIkTFWr19CUGR+oCA9wXrd86BENOW4SR448/0XwNptN7777rgoXLuzal5WVpZUrV+Z6TmLNmjW1YcOGyzaJf5cy4tqYOGWGt0vADe6bDTsVUL3rZfe/v2Cd3l+w7qrfD3jaoCHDvF0CkOdy3CQOHz5c0vkkcfz48W5z0/z8/FS6dGmNH5+7RZd79eqljIyMy+4vV66cvv7661ydEwAAILdIEk05bhL37NkjSWrcuLE++eQTFSlS5B9fvH79+lfcHxgYqIYNG/7j6wAAACB3cj0nkWQPAADcaHhwxZTrZYHatGmjIUOGGNuHDh2qRx55xCNFAQAAwLty3SSuXLlS999/v7G9WbNmWrlypUeKAgAAuJZ8bHn3ul7lukk8efLkJZe6KViwoNLT0z1SFAAAALwr103ibbfdpjlz5hjbP/jgA1WuXNkjRQEAAFxLNlveva5XuX5wpU+fPmrdurV2796tu+++W5KUkpKiWbNm6aOPPvJ4gQAAAHnN53ru5vJIrpvEFi1aaP78+Ro8eLA++ugjBQQEqGrVqlq2bJnCWGkeAADghpDrJlGSmjdvrubNz38/ZXp6umbPnq2XXnpJGzZsyNV3NwMAAOQHuZ5/ZwFXfU9Wrlyp+Ph4RUdH6+2339bdd9+ttWvXerI2AAAAeEmuksTU1FRNmzZNkydPVnp6uh599FE5HA7Nnz+fh1YAAMB1iymJphwniS1atFCFChX0008/acSIEdq/f79GjRqVl7UBAADAS3KcJC5atEgvvPCCnnvuOZUvXz4vawIAALimeLrZlOMkcdWqVTpx4oRq1qypOnXqaPTo0Tp8+HBe1gYAAAAvyXGTeOedd2rSpEk6cOCAnnnmGX3wwQeKjo5Wdna2lixZohMnTuRlnQAAAHmGxbRNuX66OTAwUE8++aRWrVqlTZs2qWfPnnrzzTcVHh6uBx98MC9qBAAAyFN8d7PpHy0LVKFCBQ0dOlS///67Zs+e7amaAAAA4GVXtZj2xXx9fdWqVSu1atXKE6cDAAC4pnhwxcQC4wAAADB4JEkEAAC4nhEkmkgSAQAAYCBJBAAAlnc9P4WcV0gSAQAAYCBJBAAAlmcTUeLFaBIBAIDlMdxsYrgZAAAABpJEAABgeSSJJpJEAAAAGEgSAQCA5dlYTdtAkggAAAADSSIAALA85iSaSBIBAABgIEkEAACWx5REE00iAACwPB+6RAPDzQAAADCQJAIAAMvjwRUTSSIAAAAMJIkAAMDymJJoIkkEAACAgSQRAABYno+IEi9GkggAAAADSSIAALA85iSaaBIBAIDlsQSOieFmAAAAGEgSAQCA5fG1fCaSRAAAABhIEgEAgOURJJpIEgEAAGAgSQQAAJbHnEQTSSIAAAAMJIkAAMDyCBJNNIkAAMDyGFo1cU8AAABgIEkEAACWZ2O82UCSCAAAAANJIgAAsDxyRBNJIgAAAAwkiQAAwPJYTNtEkggAAAADTSIAALA8Wx6+/ok333xTNptN3bt3d207ffq0EhISVLRoURUuXFht2rRRWlraP7ySiSYRAABYns2Wd6+rtX79ek2YMEG333672/YePXpowYIFmjt3rlasWKH9+/erdevW//AOmGgSAQAA8pDD4VB6errby+FwXPE9J0+eVPv27TVp0iQVKVLEtf348eOaPHmyhg0bprvvvls1a9bU1KlTtXr1aq1du9ajddMkAgAAy7PZbHn2Sk5OVkhIiNsrOTn5ivUkJCSoefPmiouLc9u+YcMGnT171m17xYoVVbJkSa1Zs8aj94SnmwEAAPJQUlKSEhMT3bbZ7fbLHv/BBx/o+++/1/r16419qamp8vPzU2hoqNv2iIgIpaameqTeC2gSAQCA5eXl0Krdbr9iU/hX+/bt04svvqglS5bI398/D6v6eww3AwAA5BMbNmzQwYMHVaNGDRUoUEAFChTQihUrNHLkSBUoUEARERE6c+aMjh075va+tLQ0RUZGerQWkkQAAGB5tnyymHaTJk20adMmt22dOnVSxYoV1bt3b5UoUUIFCxZUSkqK2rRpI0navn279u7dq7p163q0FppEAACAfCIoKEhVqlRx2xYYGKiiRYu6tj/11FNKTExUWFiYgoOD1a1bN9WtW1d33nmnR2uhSQQAAJaXP3LEnBk+fLh8fHzUpk0bORwONW3aVGPHjvX4dWxOp9Pp8bN62QlHtrdLAAzhd77g7RIAN6mrR3q7BMBNSID3HpWYu3F/np37kWrReXbuvESSCAAALC+/zEnMT27IJtHXh3/QyH8OriW1Qf5S940Ub5cAuNk88B6vXZvlXkzcEwAAABhuyCQRAAAgNxhuNpEkAgAAwECSCAAALI8c0USSCAAAAANJIgAAsDymJJpIEgEAAGAgSQQAAJbnw6xEA00iAACwPIabTQw3AwAAwECSCAAALM/GcLOBJBEAAAAGkkQAAGB5zEk0kSQCAADAQJIIAAAsjyVwTCSJAAAAMJAkAgAAy2NOookmEQAAWB5NoonhZgAAABhIEgEAgOWxmLaJJBEAAAAGkkQAAGB5PgSJBpJEAAAAGEgSAQCA5TEn0USSCAAAAANJIgAAsDzWSTTRJAIAAMtjuNnEcDMAAAAMJIkAAMDyWALHRJIIAAAAA0kiAACwPOYkmkgSAQAAYCBJBAAAlscSOCaSRAAAABhIEgEAgOURJJpoEgEAgOX5MN5sYLgZAAAABpJEAABgeeSIJpJEAAAAGEgSAQAAiBINJIkAAAAwkCQCAADL42v5TCSJAAAAMJAkAgAAy2OZRBNNIgAAsDx6RBPDzQAAADCQJAIAABAlGkgSAQAAYCBJBAAAlscSOCaSRAAAABhIEgEAgOWxBI6JJBEAAAAGkkQAAGB5BIkmmkQAAAC6RAPDzQAAADCQJAIAAMtjCRwTSSIAAAAMJIkAAMDyWALHRJIIAAAAA0kiAACwPIJEE0kiAAAADCSJAAAARIkGmkQAAGB5LIFjYrgZAAAABpJEAABgeSyBYyJJBAAAgIEkEQAAWB5BookkEQAAAAaSRAAAAKJEA0kiAAAADDSJMEyeNEHt2z6s2Dtq6O4Gd6nHCwn6dc8v3i4LcJk2eZJq3V5Jbw8Z7O1SYBE+Nqlrk7Ja3LOevut7txYlxuqZRjHGcQlNyurr3g30Xd+7NalTDZUsWsgL1eJq2PLwr9xITk5W7dq1FRQUpPDwcLVq1Urbt293O+b06dNKSEhQ0aJFVbhwYbVp00ZpaWmevB2SaBJxCd9/t15tH3tcM2bN0biJU3Tu7Dk916WzTmVmers0QFs2b9Inc+eo/C0VvF0KLOSpBqXV9o6bNXjBz3rwndUa9uVOPVm/tNrfWcJ1zIWfB3y6TY+P/1anzmRpQnx1+RXgP7XIuRUrVighIUFr167VkiVLdPbsWd17773KyMhwHdOjRw8tWLBAc+fO1YoVK7R//361bt3a47UwJxGGMRPedfu5/6BkNWlwl7Zu3aKatWp7qSpAyszMUJ+kXvp3vwGaPHG8t8uBhVQrEaqvfz6klTsOS5L2Hzut+2+P1G03h0jaJ0l64q6Smrh8j77++ZAk6dWPtmjFKw3UpFJxLdrk+ZQHnpVf1klcvHix28/Tpk1TeHi4NmzYoAYNGuj48eOaPHmyZs2apbvvvluSNHXqVFWqVElr167VnXfe6bFa+N8b/K2TJ09IkkJCQrxcCaxuyKA3FFu/oerceZe3S4HFbNx3THXKhKnU/w8fV4gsrBqlQvXNzvNN481FAlQ8yK41u4+43nPScU4//Z6uqiVCvVEycsmWhy+Hw6H09HS3l8PhyFFdx48flySFhYVJkjZs2KCzZ88qLi7OdUzFihVVsmRJrVmz5h/cARNJIq4oOztbb705WNWq11C58rd4uxxY2JeLPtfP27Zqxuy53i4FFvTuyl8VaC+gBS/epSynU742m0Yu3aXPf0yVJBUr7CdJOnLyjNv7jpx0qFiQ3zWvF/lLcnKy+vfv77atb9++6tev3xXfl52dre7duys2NlZVqlSRJKWmpsrPz0+hoaFux0ZERCg1NdWTZXu/STx16pQ2bNigsLAwVa5c2W3f6dOn9eGHH6pDhw6Xfb/D4TC68SwfP9nt9jyp12qSBw7Qrl07NXXGLG+XAgtLTT2gt4cka8zEyfy7Da+4r0qEHqgapd5zN2nXwQxVjApS7/tv0cETDn32wwFvlwdPyMPh5qSkJCUmJrpty8mfZQkJCdq8ebNWrVqVV6VdkVeHm3fs2KFKlSqpQYMGuu2229SwYUMdOPC/f9mOHz+uTp06XfEcycnJCgkJcXu9NSQ5r0u3hDcHDdA3K5Zr0pQZioiM9HY5sLCft27R0aNH9K+2bVSnehXVqV5F33+3Xh/Mel91qldRVlaWt0vEDa7nfbfo3ZV7tGhTmnamndSCjQc0Y/VedW5w/gnnw/+fIBYt7J4aFi1s1+ETZ4zzwVrsdruCg4PdXn/XJHbt2lULFy7U119/rZtvvtm1PTIyUmfOnNGxY8fcjk9LS1Okh/9b7dUmsXfv3qpSpYoOHjyo7du3KygoSLGxsdq7d2+Oz5GUlKTjx4+7vV7qnZSHVd/4nE6n3hw0QMtSlmrClGm66S+/nIA31K5TVx98/KlmfviJ61X51iq6r/kDmvnhJ/L19fV2ibjB+Rf0kdPpvi072ymf/0+ffv/zlA6dcOjOskVd+wPtvrr95mD9uO/YtSsUVy2/LIHjdDrVtWtXzZs3T8uWLVNMjPtSSzVr1lTBggWVkpLi2rZ9+3bt3btXdevW9ci9uMCrw82rV6/W0qVLVaxYMRUrVkwLFizQ888/r/r16+vrr79WYGDg357Dbrcb3XjmWedljkZOJA8coEVfLNTwkWMUGBiow4fPP6lXuHCQ/P39vVwdrCgwMNCYE+sfEKDQkFDmyuKaWP7zYT3dMEYHjp3WroMnVSkqSB1iS2nehj9cx7y3eq+6NIrRb0cy9cefp9S1SVkdPOFQyrZDXqwc15uEhATNmjVLn376qYKCglzzDENCQhQQEKCQkBA99dRTSkxMVFhYmIKDg9WtWzfVrVvXo082S15uEk+dOqUCBf5Xgs1m07hx49S1a1c1bNhQs2YxD84b5s6ZLUl6upP7XND+AwfrwVaeX4cJAPK7wQt/Vre4snrtwYoKC/TToRMOzV3/u8Z9/b8vGpjyza8K8PNVv5aVFORfQN/vPaZnp/+gM+eyvVg5ciq/LIEzbtw4SVKjRo3ctk+dOlUdO3aUJA0fPlw+Pj5q06aNHA6HmjZtqrFjx3q8FpvTeXGAfu3ccccd6tatm5544gljX9euXTVz5kylp6fner4RSSLyo6xsfi+Rv9R9I+XvDwKuoc0D7/Hatben5t0XRlSIvD6/ecercxIfeughzZ49+5L7Ro8erccee0xe7GEBAIBF5OU6idcrryaJeYUkEfkRSSLyG5JE5DfeTBJ3pOVdknhLBEkiAAAAbhBeX0wbAADA23K7VI0VkCQCAADAQJIIAAAsL78sgZOfkCQCAADAQJIIAAAsjyDRRJIIAAAAA0kiAAAAUaKBJhEAAFgeS+CYGG4GAACAgSQRAABYHkvgmEgSAQAAYCBJBAAAlkeQaCJJBAAAgIEkEQAAgCjRQJIIAAAAA0kiAACwPNZJNNEkAgAAy2MJHBPDzQAAADCQJAIAAMsjSDSRJAIAAMBAkggAACyPOYkmkkQAAAAYSBIBAACYlWggSQQAAICBJBEAAFgecxJNNIkAAMDy6BFNDDcDAADAQJIIAAAsj+FmE0kiAAAADCSJAADA8mzMSjSQJAIAAMBAkggAAECQaCBJBAAAgIEkEQAAWB5BookmEQAAWB5L4JgYbgYAAICBJBEAAFgeS+CYSBIBAABgIEkEAAAgSDSQJAIAAMBAkggAACyPINFEkggAAAADSSIAALA81kk00SQCAADLYwkcE8PNAAAAMJAkAgAAy2O42USSCAAAAANNIgAAAAw0iQAAADAwJxEAAFgecxJNJIkAAAAwkCQCAADLY51EE00iAACwPIabTQw3AwAAwECSCAAALI8g0USSCAAAAANJIgAAAFGigSQRAAAABpJEAABgeSyBYyJJBAAAgIEkEQAAWB7rJJpIEgEAAGAgSQQAAJZHkGiiSQQAAKBLNDDcDAAAAANJIgAAsDyWwDGRJAIAAMBAkggAACyPJXBMJIkAAAAw2JxOp9PbRSB/cjgcSk5OVlJSkux2u7fLAfidRL7E7yVuVDSJuKz09HSFhITo+PHjCg4O9nY5AL+TyJf4vcSNiuFmAAAAGGgSAQAAYKBJBAAAgIEmEZdlt9vVt29fJmIj3+B3EvkRv5e4UfHgCgAAAAwkiQAAADDQJAIAAMBAkwgAAAADTSIAAAAMNIm4pDFjxqh06dLy9/dXnTp19O2333q7JFjYypUr1aJFC0VHR8tms2n+/PneLgkWl5ycrNq1aysoKEjh4eFq1aqVtm/f7u2yAI+iSYRhzpw5SkxMVN++ffX999+ratWqatq0qQ4ePOjt0mBRGRkZqlq1qsaMGePtUgBJ0ooVK5SQkKC1a9dqyZIlOnv2rO69915lZGR4uzTAY1gCB4Y6deqodu3aGj16tCQpOztbJUqUULdu3fTKK694uTpYnc1m07x589SqVStvlwK4HDp0SOHh4VqxYoUaNGjg7XIAjyBJhJszZ85ow4YNiouLc23z8fFRXFyc1qxZ48XKACD/On78uCQpLCzMy5UAnkOTCDeHDx9WVlaWIiIi3LZHREQoNTXVS1UBQP6VnZ2t7t27KzY2VlWqVPF2OYDHFPB2AQAAXM8SEhK0efNmrVq1ytulAB5Fkwg3xYoVk6+vr9LS0ty2p6WlKTIy0ktVAUD+1LVrVy1cuFArV67UzTff7O1yAI9iuBlu/Pz8VLNmTaWkpLi2ZWdnKyUlRXXr1vViZQCQfzidTnXt2lXz5s3TsmXLFBMT4+2SAI8jSYQhMTFR8fHxqlWrlu644w6NGDFCGRkZ6tSpk7dLg0WdPHlSu3btcv28Z88ebdy4UWFhYSpZsqQXK4NVJSQkaNasWfr0008VFBTkmrMdEhKigIAAL1cHeAZL4OCSRo8erf/85z9KTU1VtWrVNHLkSNWpU8fbZcGili9frsaNGxvb4+PjNW3atGtfECzPZrNdcvvUqVPVsWPHa1sMkEdoEgEAAGBgTiIAAAAMNIkAAAAw0CQCAADAQJMIAAAAA00iAAAADDSJAAAAMNAkAgAAwECTCAAAAANNIoB8q2PHjmrVqpXr50aNGql79+7XvI7ly5fLZrPp2LFj1/zaAOAtNIkAcq1jx46y2Wyy2Wzy8/NTuXLlNGDAAJ07dy5Pr/vJJ5/ojTfeyNGxNHYA8M8U8HYBAK5P9913n6ZOnSqHw6EvvvhCCQkJKliwoJKSktyOO3PmjPz8/DxyzbCwMI+cBwDw90gSAVwVu92uyMhIlSpVSs8995zi4uL02WefuYaIBw0apOjoaFWoUEGStG/fPj366KMKDQ1VWFiYWrZsqV9//dV1vqysLCUmJio0NFRFixbVyy+/rIu/Wv7i4WaHw6HevXurRIkSstvtKleunCZPnqxff/1VjRs3liQVKVJENptNHTt2lCRlZ2crOTlZMTExCggIUNWqVfXRRx+5XeeLL77QLbfcooCAADVu3NitTgCwCppEAB4REBCgM2fOSJJSUlK0fft2LVmyRAsXLtTZs2fVtGlTBQUF6ZtvvtF///tfFS5cWPfdd5/rPW+//bamTZumKVOmaNWqVTp69KjmzZt3xWt26NBBs2fP1siRI7Vt2zZNmDBBhQsXVokSJfTxxx9LkrZv364DBw7onXfekSQlJydrxowZGj9+vLZs2aIePXroX//6l1asWCHpfDPbunVrtWjRQhs3blTnzp31yiuv5NVtA4B8i+FmAP+I0+lUSkqKvvzyS3Xr1k2HDh1SYGCg3n33Xdcw8/vvv6/s7Gy9++67stlskqSpU6cqNDRUy5cv17333qsRI0YoKSlJrVu3liSNHz9eX3755WWvu2PHDn344YdasmSJ4uLiJEllypRx7b8wNB0eHq7Q0FBJ55PHwYMHa+nSpapbt67rPatWrdKECRPUsGFDjRs3TmXLltXbb78tSapQoYI2bdqkIUOGePCuAUD+R5MI4KosXLhQhQsX1tmzZ5Wdna3HH39c/fr1U0JCgm677Ta3eYg//vijdu3apaCgILdznD59Wrt379bx48d14MAB1alTx7WvQIECqlWrljHkfMHGjRvl6+urhg0b5rjmXbt2KTMzU/fcc4/b9jNnzqh69eqSpG3btrnVIcnVUAKAldAkArgqjRs31rhx4+Tn56fo6GgVKPC/P04CAwPdjj158qRq1qypmTNnGucpXrz4VV0/ICAg1+85efKkJOnzzz/XTTfd5LbPbrdfVR0AcKOiSQRwVQIDA1WuXLkcHVujRg3NmTNH4eHhCg4OvuQxUVFRWrdunRo0aCBJOnfunDZs2KAaNWpc8vjbbrtN2dnZWrFihWu4+a8uJJlZWVmubZUrV5bdbtfevXsvm0BWqlRJn332mdu2tWvX/v2HBIAbDA+uAMhz7du3V7FixdSyZUt988032rNnj5YvX64XXnhBv//+uyTpxRdf1Jtvvqn58+fr559/1vPPP3/FNQ5Lly6t+Ph4Pfnkk5o/f77rnB9++KEkqVSpUrLZbFq4cKEOHTqkkydPKigoSC+99JJ69Oih6dOna/fu3fr+++81atQoTZ8+XZL07LPPaufOnerVq5e2b9+uWbNmadq0aXl9iwAg36FJBJDnChUqpJUrV6pkyZJq3bq1KlWqpKeeekqnT592JYs9e/bUE088ofj4eNWtW1dBQUF66KGHrnjecePG6eGHH9bzzz+vihUr6umnn1ZGRoYk6aabblL//v31yiuvKCIiQl27dpUkvfHGG+rTp4+Sk5NVqVIl3Xffffr8888VExMjSSpZsqQ+/vhjzZ8/X1WrVtX48eM1ePDgPLw7AJA/2ZyXmxUOAAAAyyJJBAAAgIEmEQAAAAaaRAAAABhoEgEAAGCgSQQAAICBJhEAAAAGmkQAAAAYaBIBAABgoEkEAACAgSYRAAAABppEAAAAGP4PjgfDDy/9fEEAAAAASUVORK5CYII=\n"},"metadata":{}},{"name":"stdout","text":"ğŸ“„ Classification Report:\n\n              precision    recall  f1-score   support\n\n           0     0.9200    0.9583    0.9388        72\n           1     0.9573    0.9256    0.9412       121\n           2     0.9195    0.9302    0.9249        86\n\n    accuracy                         0.9355       279\n   macro avg     0.9323    0.9381    0.9349       279\nweighted avg     0.9360    0.9355    0.9355       279\n\n\nğŸ¯ Overall Validation Accuracy: 0.9355\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"\"\"\"\nCOMPLETE TEST PIPELINE FOR RESPIRATORY SOUNDS CLASSIFICATION\nThis script processes test data exactly like training data and makes predictions.\n\"\"\"\n\nimport os\nimport librosa\nimport numpy as np\nimport pandas as pd\nimport pickle\nfrom sklearn.decomposition import PCA\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\nimport warnings\nwarnings.filterwarnings('ignore')\n\nclass TestDataProcessor:\n    def __init__(self, model_path='fixed_super_advanced_model.h5'):\n        \"\"\"Initialize the test data processor\"\"\"\n        self.model_path = model_path\n        self.tab_features = ['age', 'gender', 'tbContactHistory', 'wheezingHistory', \n                            'phlegmCough', 'familyAsthmaHistory', 'feverHistory', \n                            'coldPresent', 'packYears']\n        self.model = None\n        self.pca = None\n        self.scaler = None\n        self.imputer = None\n        \n    def load_model_and_preprocessors(self):\n        \"\"\"Load trained model and preprocessing objects\"\"\"\n        print(\"ğŸ“¥ Loading model and preprocessing objects...\")\n        \n        # Load model\n        self.model = load_model(self.model_path)\n        print(\"âœ… Model loaded\")\n        \n        # Note: In production, you should save and load these from training\n        # For now, we'll create them with same parameters\n        self.pca = PCA(n_components=128, random_state=42)\n        self.scaler = StandardScaler()\n        self.imputer = IterativeImputer(max_iter=10, random_state=42)\n        \n        return True\n    \n    def extract_audio_features(self, audio_path, test_csv_path):\n        \"\"\"Extract MFCC features from test audio files\"\"\"\n        print(\"ğŸµ Processing audio files...\")\n        \n        # Load test data\n        test_df = pd.read_csv(test_csv_path)\n        \n        # Map audio files\n        file_map = {}\n        for folder in os.listdir(audio_path):\n            fpath = os.path.join(audio_path, folder)\n            if os.path.isdir(fpath):\n                wavs = [f for f in os.listdir(fpath) if f.endswith(\".wav\")]\n                if wavs:\n                    file_map[folder] = os.path.join(fpath, wavs[0])\n        \n        # Extract features\n        X_audio = []\n        valid_ids = []\n        \n        for i, cid in enumerate(test_df['candidateID']):\n            if cid in file_map:\n                try:\n                    features = self._extract_single_audio(file_map[cid])\n                    X_audio.append(features)\n                    valid_ids.append(cid)\n                except Exception as e:\n                    print(f\"Error processing {cid}: {e}\")\n                    continue\n        \n        X_audio = np.array(X_audio)\n        test_df_filtered = test_df[test_df['candidateID'].isin(valid_ids)]\n        \n        print(f\"âœ… Audio features extracted: {X_audio.shape}\")\n        print(f\"âœ… Valid test samples: {len(test_df_filtered)}\")\n        \n        return X_audio, test_df_filtered, valid_ids\n    \n    def _extract_single_audio(self, file_path, n_mfcc=40, duration=5, sr=22050):\n        \"\"\"Extract features from single audio file\"\"\"\n        y, sr = librosa.load(file_path, sr=sr, duration=duration)\n        \n        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n        mfcc_scaled = np.mean(mfcc.T, axis=0)\n        \n        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n        chroma_scaled = np.mean(chroma.T, axis=0)\n        \n        mel = librosa.feature.melspectrogram(y=y, sr=sr)\n        mel_scaled = np.mean(mel.T, axis=0)\n        \n        return np.hstack([mfcc_scaled, chroma_scaled, mel_scaled])\n    \n    def process_tabular_data(self, test_df):\n        \"\"\"Process tabular data (imputation + scaling)\"\"\"\n        print(\"ğŸ“Š Processing tabular data...\")\n        \n        X_tab = test_df[self.tab_features].values\n        \n        # Impute missing values\n        X_tab_imputed = self.imputer.fit_transform(X_tab)\n        \n        # Scale features\n        X_tab_scaled = self.scaler.fit_transform(X_tab_imputed)\n        \n        print(f\"âœ… Tabular data processed: {X_tab_scaled.shape}\")\n        return X_tab_scaled\n    \n    def reduce_audio_features(self, X_audio):\n        \"\"\"Apply PCA to reduce audio features\"\"\"\n        print(\"ğŸ”§ Reducing audio features with PCA...\")\n        \n        X_audio_flat = X_audio.reshape(X_audio.shape[0], -1)\n        X_audio_pca = self.pca.fit_transform(X_audio_flat)\n        \n        print(f\"âœ… Audio features reduced: {X_audio_pca.shape}\")\n        return X_audio_pca\n    \n    def make_predictions(self, X_tab, X_audio_pca):\n        \"\"\"Make predictions using the trained model\"\"\"\n        print(\"ğŸ”® Making predictions...\")\n        \n        predictions = self.model.predict(\n            [X_tab, X_audio_pca],\n            batch_size=16,\n            verbose=1\n        )\n        \n        predicted_classes = np.argmax(predictions, axis=1)\n        \n        print(f\"âœ… Predictions made: {len(predicted_classes)} samples\")\n        return predictions, predicted_classes\n    \n    def create_submission(self, candidate_ids, predictions, predicted_classes):\n        \"\"\"Create submission file with predictions\"\"\"\n        print(\"ğŸ’¾ Creating submission file...\")\n        \n        # Create results DataFrame\n        results_df = pd.DataFrame({\n            'candidateID': candidate_ids,\n            'predicted_class': predicted_classes,\n            'confidence_0': predictions[:, 0],\n            'confidence_1': predictions[:, 1],\n            'confidence_2': predictions[:, 2],\n            'max_confidence': predictions.max(axis=1)\n        })\n        \n        # Save to CSV\n        results_df.to_csv('test_predictions_detailed.csv', index=False)\n        \n        # Create simple submission (just IDs and predictions)\n        simple_submission = pd.DataFrame({\n            'candidateID': candidate_ids,\n            'predicted_disease': predicted_classes\n        })\n        simple_submission.to_csv('submission.csv', index=False)\n        \n        print(\"âœ… Submission files created:\")\n        print(\"   - test_predictions_detailed.csv (with confidence scores)\")\n        print(\"   - submission.csv (simple format)\")\n        \n        return results_df\n    \n    def run_pipeline(self, audio_path, test_csv_path):\n        \"\"\"Run complete test pipeline\"\"\"\n        print(\"=\" * 60)\n        print(\"ğŸš€ STARTING TEST DATA PROCESSING PIPELINE\")\n        print(\"=\" * 60)\n        \n        # Step 1: Load model\n        self.load_model_and_preprocessors()\n        \n        # Step 2: Extract audio features\n        X_audio, test_df_filtered, valid_ids = self.extract_audio_features(\n            audio_path, test_csv_path\n        )\n        \n        # Step 3: Process tabular data\n        X_tab = self.process_tabular_data(test_df_filtered)\n        \n        # Step 4: Reduce audio features\n        X_audio_pca = self.reduce_audio_features(X_audio)\n        \n        # Step 5: Make predictions\n        predictions, predicted_classes = self.make_predictions(X_tab, X_audio_pca)\n        \n        # Step 6: Create submission\n        results_df = self.create_submission(valid_ids, predictions, predicted_classes)\n        \n        # Step 7: Print summary\n        self.print_summary(predictions, predicted_classes)\n        \n        print(\"=\" * 60)\n        print(\"ğŸ‰ PIPELINE COMPLETED SUCCESSFULLY!\")\n        print(\"=\" * 60)\n        \n        return results_df\n    \n    def print_summary(self, predictions, predicted_classes):\n        \"\"\"Print prediction summary\"\"\"\n        print(\"\\nğŸ“ˆ PREDICTION SUMMARY:\")\n        print(\"-\" * 40)\n        \n        # Class distribution\n        unique, counts = np.unique(predicted_classes, return_counts=True)\n        for cls, count in zip(unique, counts):\n            percentage = (count / len(predicted_classes)) * 100\n            print(f\"Class {cls}: {count} samples ({percentage:.1f}%)\")\n        \n        # Confidence analysis\n        max_confidences = predictions.max(axis=1)\n        print(f\"\\nğŸ¯ Confidence Analysis:\")\n        print(f\"Average confidence: {max_confidences.mean():.3f}\")\n        print(f\"Minimum confidence: {max_confidences.min():.3f}\")\n        print(f\"Maximum confidence: {max_confidences.max():.3f}\")\n        print(f\"Confidence < 0.5: {(max_confidences < 0.5).sum()} samples\")\n        print(f\"Confidence > 0.9: {(max_confidences > 0.9).sum()} samples\")\n\n# Main execution\nif __name__ == \"__main__\":\n    # Initialize processor\n    processor = TestDataProcessor(model_path='fixed_super_advanced_model.h5')\n    \n    # Define paths\n    TEST_CSV_PATH = \"/kaggle/input/airs-ai-in-respiratory-sounds/test.csv\"\n    AUDIO_PATH = \"/kaggle/input/airs-ai-in-respiratory-sounds/sounds/sounds\"\n    \n    # Run pipeline\n    results = processor.run_pipeline(AUDIO_PATH, TEST_CSV_PATH)\n    \n    # Show sample predictions\n    print(\"\\nğŸ” SAMPLE PREDICTIONS:\")\n    print(results.head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:26:39.565610Z","iopub.execute_input":"2025-12-01T21:26:39.565819Z","iopub.status.idle":"2025-12-01T21:26:59.982356Z","shell.execute_reply.started":"2025-12-01T21:26:39.565802Z","shell.execute_reply":"2025-12-01T21:26:59.981575Z"}},"outputs":[{"name":"stdout","text":"============================================================\nğŸš€ STARTING TEST DATA PROCESSING PIPELINE\n============================================================\nğŸ“¥ Loading model and preprocessing objects...\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","output_type":"stream"},{"name":"stdout","text":"âœ… Model loaded\nğŸµ Processing audio files...\nâœ… Audio features extracted: (338, 180)\nâœ… Valid test samples: 338\nğŸ“Š Processing tabular data...\nâœ… Tabular data processed: (338, 9)\nğŸ”§ Reducing audio features with PCA...\nâœ… Audio features reduced: (338, 128)\nğŸ”® Making predictions...\n\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step \nâœ… Predictions made: 338 samples\nğŸ’¾ Creating submission file...\nâœ… Submission files created:\n   - test_predictions_detailed.csv (with confidence scores)\n   - submission.csv (simple format)\n\nğŸ“ˆ PREDICTION SUMMARY:\n----------------------------------------\nClass 0: 90 samples (26.6%)\nClass 1: 109 samples (32.2%)\nClass 2: 139 samples (41.1%)\n\nğŸ¯ Confidence Analysis:\nAverage confidence: 0.884\nMinimum confidence: 0.401\nMaximum confidence: 1.000\nConfidence < 0.5: 6 samples\nConfidence > 0.9: 214 samples\n============================================================\nğŸ‰ PIPELINE COMPLETED SUCCESSFULLY!\n============================================================\n\nğŸ” SAMPLE PREDICTIONS:\n     candidateID  predicted_class  confidence_0  confidence_1  confidence_2  \\\n0  136bac9a3e081                0      0.929277      0.069277      0.001447   \n1  b121e45942a46                1      0.005614      0.906123      0.088263   \n2  6b6853c07e4fb                1      0.429982      0.564565      0.005452   \n3  71de185eac888                2      0.008144      0.001531      0.990325   \n4  25deed742f133                1      0.005521      0.994330      0.000149   \n5  1de4591779d31                2      0.001809      0.002803      0.995389   \n6  102efeabb10a5                1      0.000608      0.723720      0.275672   \n7  522d1f8600a13                2      0.000636      0.008068      0.991296   \n8  e41530046a74e                1      0.228087      0.771612      0.000301   \n9  6337b96a160eb                1      0.122367      0.519589      0.358043   \n\n   max_confidence  \n0        0.929277  \n1        0.906123  \n2        0.564565  \n3        0.990325  \n4        0.994330  \n5        0.995389  \n6        0.723720  \n7        0.991296  \n8        0.771612  \n9        0.519589  \n","output_type":"stream"}],"execution_count":9}]}